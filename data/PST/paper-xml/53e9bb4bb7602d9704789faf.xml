<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MAXIMIZING A MONOTONE SUBMODULAR FUNCTION SUBJECT TO A MATROID CONSTRAINT *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Gruia</forename><surname>Calinescu</surname></persName>
							<email>calinescu@iit.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Illinois Institute of Technology</orgName>
								<address>
									<postCode>60616</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chandra</forename><surname>Chekuri</surname></persName>
							<email>chekuri@cs.illinois.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<postCode>61801</postCode>
									<settlement>Urbana</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martin</forename><forename type="middle">P</forename><surname>Ál</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Google Inc</orgName>
								<address>
									<postCode>1440, 10018</postCode>
									<settlement>Broadway, New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>AND</roleName><forename type="first">Jan</forename><surname>Vondr Ák</surname></persName>
							<email>jvondrak@us.ibm.com</email>
							<affiliation key="aff3">
								<orgName type="institution">IBM Almaden Research Center</orgName>
								<address>
									<postCode>95120</postCode>
									<settlement>San Jose</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">MAXIMIZING A MONOTONE SUBMODULAR FUNCTION SUBJECT TO A MATROID CONSTRAINT *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EABC83417088B304774A785716368A76</idno>
					<idno type="DOI">10.1137/080733991</idno>
					<note type="submission">* Received by the editors September 2, 2008; accepted for publication (in revised form) October 15, 2009;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>monotone submodular set function</term>
					<term>matroid</term>
					<term>social welfare</term>
					<term>generalized assignment problem</term>
					<term>approximation algorithm AMS subject classifications. 68W20</term>
					<term>68W25</term>
					<term>52B40</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Let f : 2 X → R + be a monotone submodular set function, and let (X, I) be a matroid. We consider the problem max S∈I f (S). It is known that the greedy algorithm yields a 1/2-approximation [M. L. Fisher, G. L. Nemhauser, and L. A. Wolsey, Math. Programming Stud.,  no. 8 (1978), pp. 73-87]  for this problem. For certain special cases, e.g., max |S|≤k f (S), the greedy algorithm yields a (1 -1/e)-approximation. It is known that this is optimal both in the value oracle model (where the only access to f is through a black box returning f (S) for a given set S)</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For computational purposes we will assume that f and I are specified as oracles, although in specific settings of interest, an explicit description is often available.</p><p>Submodular maximization subject to a matroid. The problem (or, rather, class of problems) of interest in this paper is the problem of maximizing f (S) over the independent sets S ∈ I; in other words we wish to find max S∈I f (S). We denote by SUB-M the problem where f is monotone submodular and M = (X, I) is a matroid.</p><p>The problem of maximizing a submodular set function subject to independence constraints has been studied extensively-we discuss prior work at the end of the section. A number of interesting and useful combinatorial optimization problems, including NP-hard problems, are special cases. Some notable examples are maximum independent set in a matroid, maximum matroid intersection, and max-k-cover. Below we describe some candidates for f and I that arise frequently in applications.</p><p>Modular functions. A function f : 2</p><formula xml:id="formula_0">X → R + is modular iff f (A) + f (B) = f (A ∪ B) + f (A ∩ B) for all A, B.</formula><p>If f is modular, then there is a weight function w : X → R + such that f (A) = w(A) = e∈A w(e). Such functions are also referred to as additive or linear.</p><p>Set systems and coverage. Given a universe U and n subsets A 1 , A 2 , . . . , A n ⊂ U , we obtain several natural submodular functions on the set X = {1, 2, . . . , n}. First, the coverage function f given by f (S) = | ∪ i∈S A i | is submodular. This naturally extends to the weighted coverage function; given a nonnegative weight function w : U → R + , f (S) = w(∪ i∈S A i ). We obtain a multicover version as follows. For x ∈ U let k(x) be an integer. For each x ∈ U and A i let c(A i , x) = 1 if x ∈ A i and 0 if x / ∈ A i . Given S ⊆ X, let c (S, x), the coverage of x under S, be defined as c (S, x) = min{k(x), i∈S c(A i , x)}. The function f (S) = x∈U c (S, x) is submodular. A related function defined by f (S) = x∈U max i∈S w(A i , x) is also submodular, where w(A i , x) is a nonnegative weight for A i covering x.</p><p>Weighted rank functions of matroids and their sums. The rank function of a matroid M = (X, I), r M (A) = max{|S| : S ⊆ A, S ∈ I}, is submodular. Given w : X → R + , the weighted rank function defined by r M,w (A) = max{w(S) : S ⊆ A, S ∈ I} is a submodular function <ref type="bibr" target="#b39">[39]</ref>. Submodularity is preserved by taking a sum, and hence a sum of weighted rank functions is also submodular. The functions of coverage type mentioned above are captured by this class. However, the class does not include all monotone submodular functions.</p><p>Matroid constraint. An independence family of particular interest is one induced by a matroid M = (X, I). A simple matroid constraint that is of much importance in applications <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b19">19]</ref> is the partition matroid: X is partitioned into sets X 1 , X 2 , . . . , X with associated integers k 1 , k 2 , . . . , k , and a set A ⊆ X is independent iff |A ∩ X i | ≤ k i . In fact even the case of = 1 (the uniform matroid) is of interest.</p><p>Intersection of matroids. A natural generalization of the single matroid case is obtained when we consider intersections of different matroids M 1 = (X, I 1 ), M 2 = (X, I 2 ), . . . , M p = (X, I p ) on the same ground set X. That is, I = {A ⊆ X | A ∈ I i , 1 ≤ i ≤ p}. A simple example is the family of hypergraph matchings in a p-partite hypergraph (p = 2 is simply the family of matchings in a bipartite graph).</p><p>p-systems. More general independence families parametrized by an integer p can be defined. We follow the definition of <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b28">28]</ref>. Given an independence family I and a set Y ⊆ X, let B(Y ) be the set of maximal independent sets of I included in Y , that is, B(Y ) = {A ∈ I | A ⊆ Y and there is no A ∈ I such that A ⊂ A ⊆ Y }. Then I is a p-system if, for all Y ⊆ X, max A∈B(Y ) |A| min A∈B(Y ) |A| ≤ p. p-systems properly generalize several simpler and easier to understand special cases including families obtained from the Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php intersection of p matroids. We discuss some of these special cases in Appendix B). The set of matchings in a general graph forms a 2-system. Similarly the set of matchings in a hypergraph with edges of cardinality at most p forms a p-system.</p><p>The greedy algorithm. A greedy algorithm is quite natural for the problem max{f (S) : S ∈ I}. The algorithm incrementally builds a solution (without backtracking) starting with the empty set. In each iteration it adds an element that most improves the current solution (according to f ) while maintaining independence of the solution. The greedy algorithm yields a 1/p-approximation for maximizing a modular function subject to a p-system independence constraint <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b28">28]</ref>. For submodular functions, the greedy algorithm yields a ratio of 1/(p + 1) <ref type="bibr" target="#b17">[17]</ref>. <ref type="foot" target="#foot_0">1</ref> These ratios for the greedy algorithm are tight for all p, even for intersections of p matroids. For large but fixed p, the p-dimensional matching problem is NP-hard to approximate to within an Ω(log p/p) factor <ref type="bibr" target="#b24">[24]</ref>.</p><p>For the problem of maximizing a submodular function subject to a matroid constraint (special case of p = 1), the greedy algorithm achieves a ratio of 1/2. When the matroid is uniform, i.e., the problem is max{f (S) : |S| ≤ k}, the greedy algorithm yields a (1 -1/e)-approximation and this is optimal in the value oracle model <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b36">36]</ref>. This special case already captures the max-k-cover problem (with f (S) the coverage function of a set system) for which it is shown in <ref type="bibr" target="#b12">[13]</ref> that no (1 -1/e + )approximation is possible for any constant &gt; 0, unless P = N P . Thus it is natural to ask whether a 1 -1/e approximation is achievable for any matroid or whether there is a gap between the case of uniform matroids and general matroids. We resolve the question in this paper.</p><p>Theorem 1.1. There is a randomized algorithm giving a (1-1/e)-approximation (in expectation) to the problem max{f (S) : S ∈ I}, where f : 2 X → R + is a monotone submodular function given by a value oracle, and M = (X, I) is a matroid given by a membership oracle.</p><p>The proof of this theorem appears in section 3. Our main tools are the pipage rounding technique of Ageev and Sviridenko <ref type="bibr" target="#b0">[1]</ref> and a continuous greedy process <ref type="bibr" target="#b43">[42]</ref>. We give an overview of these techniques in section 2.</p><p>Applications. Using Theorem 1.1 we obtain (1 -1/e)-approximation algorithms for a number of optimization problems. An immediate application is the submodular welfare problem <ref type="bibr" target="#b32">[32]</ref>, which can be cast as a submodular maximization problem subject to a partition matroid. (This reduction already appeared in <ref type="bibr" target="#b17">[17]</ref>.) In this problem, we are given n players and m items. Each player i has a monotone submodular utility function w i : 2 [m] → R + . The goal is to allocate items to the agents to maximize the total utility n i=1 w i (S i ). It was known that the greedy algorithm yields a 1/2-approximation <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b32">32]</ref>, while a (1 -1/e)-approximation in the value oracle model would be optimal <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b35">35]</ref>. Improvements over the 1/2-approximation were achieved only in special cases or using a stronger computation model <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">16]</ref>. Our work implies the following optimal result, which first appeared in <ref type="bibr" target="#b43">[42]</ref>.</p><p>Theorem 1.2. There is a randomized algorithm which achieves a (1 -1/e)approximation (in expectation) for the submodular welfare problem in the value oracle model.</p><p>The proof of this theorem appears in section 4.1. Another application of Theorem 1.1 is related to variants of the generalized assignment problem (GAP). In GAP we are given n bins and m items. Each item i specifies a size s ij and a value (or profit) v ij for each bin j. Each bin has capacity 1, and the goal is to assign a subset of items to bins such that the bin capacities are not violated and the profit of the assignment is maximized. Fleischer et al. <ref type="bibr" target="#b19">[19]</ref> gave a (1 -1/e)-approximation for this problem, improving upon a previous 1/2-approximation <ref type="bibr" target="#b5">[6]</ref>. We rederive almost the same ratio, casting the problem as a special case of submodular function maximization. Moreover, our techniques allow us to obtain a (1 -1/eo( <ref type="formula">1</ref>))-approximation for GAP, even under any given matroid constraint on the bins. A simple example is GAP with the added constraint that at most k of the n bins be used for packing items.</p><p>Theorem 1.3. Let A be an instance of GAP with n bins and m items, and let B be the set of bins. Let M = (B, I) be a matroid on B. There is a randomized <ref type="formula">1</ref>))-approximation to find a maximum profit assignment to bins such that the subset S ⊆ B of bins that are used in the assignment satisfies the constraint S ∈ I.</p><formula xml:id="formula_1">(1 -1/e -o(</formula><p>The proof of this theorem appears in section 4.2. We note that the approximation ratio for GAP has been improved to 1-1/e+δ for a small δ &gt; 0 in <ref type="bibr" target="#b16">[16]</ref> using the same linear programming relaxation as in <ref type="bibr" target="#b19">[19]</ref>. However, the algorithm in <ref type="bibr" target="#b19">[19]</ref> extends to an even more general class of problems, the separable assignment problem (SAP). For SAP, it is shown in <ref type="bibr" target="#b19">[19]</ref> that an approximation ratio of 1 -1/e + for any constant &gt; 0 implies N P ⊆ DT IM E(n O(log log n) ). Our framework also extends to SAP, and hence 1 -1/e is the best approximation factor one can achieve with this approach. We discuss this further in section 4.2.</p><p>Remarks on efficiency. Our algorithm is conceptually quite simple and easy to implement; however, its running time is a different issue. The variant described here would run in time on the order of Õ(n 8 ), using Õ(n 7 ) oracle queries, mostly due to the number of random samples necessary to achieve high probability bounds (see section 3.1). This can be substantially reduced by a more careful implementation and analysis, which will be discussed in a future paper.</p><p>Prior and related work. Maximizing a submodular function subject to independence constraints is related to many important and interesting problems in combinatorial optimization. The seminal work of Edmonds on polyhedral aspects of matroids and matroid intersection led to a variety of investigations on linear function optimization subject to independence constraints. In particular, the greedy algorithm, which is known to be optimal for a single matroid <ref type="bibr" target="#b11">[12]</ref>, was shown to be 1/p-approximate for p-systems by Jenkyns <ref type="bibr" target="#b25">[25]</ref>, which generalized an earlier result <ref type="bibr" target="#b28">[28]</ref>. The impetus for considering maximizing submodular functions subject to a matroid constraint appears to have come from an application to a facility location problem in the work of Cornuejols, Fisher, and Nemhauser <ref type="bibr" target="#b8">[9]</ref>. In two important papers <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b17">17]</ref>, Fisher, Nemhauser, and Wolsey formally stated and studied the problem SUB-M and generalizations to other independent systems; they proved a number of useful theorems, including the analysis of greedy as well as local search, and also discussed various applications. Unfortunately, the results in these early papers appear to have been forgotten in later work on approximation algorithms, and easy consequences were often rediscovered. We note that the "locally greedy heuristic" for partition matroids in <ref type="bibr" target="#b17">[17]</ref> is particularly useful. See <ref type="bibr" target="#b21">[21]</ref> for a survey of recent applications. Nemhauser and Wolsey <ref type="bibr" target="#b36">[36]</ref> showed that for SUB-M with the uniform matroid, in the model where f is accessed via a value oracle, any algorithm that obtains an approximation better than (1 -1/e) requires an exponential number of queries. As we already mentioned, Feige <ref type="bibr" target="#b12">[13]</ref> showed that, unless P = N P , (1 -1/e) is the best approximation ratio for Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php max-k-cover.</p><p>The (historically) first part of our work (the pipage rounding technique) is inspired by that of Ageev and Sviridenko <ref type="bibr" target="#b0">[1]</ref>, who introduced the pipage rounding technique and gave a (1 -1/e)-approximation for the special case of the max-coverage problem with a partition matroid constraint, among several other results. See <ref type="bibr" target="#b40">[40,</ref><ref type="bibr" target="#b20">20]</ref> for randomized variants of pipage rounding. The starting point for this work was the observation that the pipage rounding technique can be generalized to arbitrary matroids <ref type="bibr" target="#b2">[3]</ref>. This work also introduced the notion of a multilinear extension of a submodular function, which is crucial in this paper. Another inspiration for this work came from the (1 -1/e)-approximation for GAP given in <ref type="bibr" target="#b19">[19]</ref>.</p><p>The second main technical ingredient of our work (the continuous greedy process) first appeared in <ref type="bibr" target="#b43">[42]</ref>. Related to it is the notion of a real-valued submodular function and a continuous greedy algorithm considered by Wolsey <ref type="bibr" target="#b45">[44]</ref>; the differences are discussed at the end of section 2.3. An important motivating problem for this part of our work is the submodular welfare problem; see section 4.1 for related work on this topic. Maximizing a monotone submodular function subject to knapsack constraints has also received attention; Sviridenko <ref type="bibr" target="#b42">[41]</ref> gave a (1 -1/e)-approximation for a single knapsack constraint based on earlier work <ref type="bibr" target="#b27">[27]</ref> on max-coverage. Recently, this has been extended to a constant number of knapsack constraints <ref type="bibr" target="#b29">[29]</ref>, using the continuous greedy algorithm described in this paper.</p><p>We have so far discussed the problem SUB-M and its generalizations in the context of monotone submodular functions. It is also of interest to consider nonmonotone submodular functions that are nonnegative; cut-functions in undirected and directed graphs are prominent special cases. Recent work has obtained several new approximation results in this more general setting with local search and randomization as the key techniques <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b31">31]</ref>. Further connections between the notion of a multilinear extension and approximability of submodular maximization problems are studied in <ref type="bibr" target="#b44">[43]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Overview of techniques.</head><p>We start with an overview of our approach to the problem of maximizing a monotone submodular function subject to a matroid constraint. We present background material and intuition for our algorithm, which appears in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Preliminaries. Submodular functions. A function</head><formula xml:id="formula_2">f : 2 X → R is submodular if, for all A, B ⊆ X, f (A ∪ B) + f (A ∩ B) ≤ f (A) + f (B). Given a submodular function f : 2 X → R and A ⊂ X, the function f A defined by f A (S) = f (S ∪ A) -f (A) is also submodular. Further, if f is monotone, f A</formula><p>is also monotone. For i ∈ X, we abbreviate S ∪ {i} by S + i. By f A (i), we denote the "marginal value" f (A + i)f (A). For monotone functions, submodularity is equivalent to f A (i) being nonincreasing as a function of A for every fixed i.</p><p>Smooth submodular functions. As a continuous analogy, Wolsey <ref type="bibr" target="#b46">[45]</ref> defines submodularity for a function F : [0, 1] X → R + as follows:</p><p>(2.1) </p><formula xml:id="formula_3">F (x ∨ y) + F (x ∧ y) ≤ F (x) + F (</formula><formula xml:id="formula_4">• F ∈ C 2 ([0, 1] X ); i.e.</formula><p>, it has second partial derivatives everywhere.</p><p>• For each j ∈ X, ∂F ∂yj ≥ 0 everywhere (monotonicity). • For any i, j ∈ X (possibly equal), ∂ 2 F ∂yi∂yj ≤ 0 everywhere (submodularity). Thus the gradient ∇F = ( ∂F ∂y1 , . . . , ∂F ∂yn ) is a nonnegative vector. The submodularity condition ∂ 2 F ∂yi∂yj ≤ 0 means that ∂F ∂yj is nonincreasing with respect to y i . It can be seen that this implies (2.1). Also, it means that a smooth submodular function is concave along any nonnegative direction vector; however, it is not necessarily concave in all directions.</p><p>Multilinear extension. For a monotone submodular set function f : 2 X → R + , a canonical extension to a smooth monotone submodular function can be obtained as follows <ref type="bibr" target="#b2">[3]</ref>: For y ∈ [0, 1] X , let ŷ denote a random vector in {0, 1} X where each coordinate is independently rounded to 1 with probability y j or 0 otherwise. We identify ŷ ∈ {0, 1} X with a set R ⊆ X whose indicator vector is ŷ = 1 R . Then, we define</p><formula xml:id="formula_5">F (y) = E[f (ŷ)] = R⊆X f (R) i∈R y i j / ∈R (1 -y j ).</formula><p>This is a multilinear polynomial which satisfies</p><formula xml:id="formula_6">∂F ∂y j = E[f (ŷ) | ŷj = 1] -E[f (ŷ) | ŷj = 0] ≥ 0</formula><p>by monotonicity of f . For i = j, we get</p><formula xml:id="formula_7">∂ 2 F ∂y i ∂y j = E[f (ŷ) | ŷi = 1, ŷj = 1] -E[f (ŷ) | ŷi = 1, ŷj = 0] -E[f (ŷ) | ŷi = 0, ŷj = 1] + E[f (ŷ) | ŷi = 0, ŷj = 0]</formula><p>≤ 0 by submodularity of f . In addition, ∂ 2 F ∂yj 2 = 0, since F is multilinear. Example. Consider X = [n] and f (S) = min{|S|, 1}. This is a monotone submodular function. The multilinear extension of this function is</p><formula xml:id="formula_8">F (y) = E[f (ŷ)] = 1 - n i=1 (1 -y i ).</formula><p>This is the unique multilinear function which coincides with f (S) on {0, 1}-vectors. It is also easy to see that its first partial derivatives are nonnegative and its second partial derivatives are nonpositive; i.e., F (y) is a smooth monotone submodular function.</p><p>Chernoff bounds. In the value oracle model, we cannot compute the multilinear extension exactly, but we can estimate it (and related quantities) by random sampling. To this end we will use the symmetric version of Theorem A.1.16 in <ref type="bibr" target="#b1">[2]</ref>.</p><p>Theorem 2.2. Let X i , 1 ≤ i ≤ k, be mutually independent with all E[X i ] = 0 and all </p><formula xml:id="formula_9">|X i | ≤ 1. Set S = X 1 + • • • + X k . Then P r[|S| &gt; a] ≤ 2e -a 2 /</formula><formula xml:id="formula_10">r M (S) = max{|I| : I ⊆ S, I ∈ I}.</formula><p>The rank function of a matroid is monotone and submodular. It is analogous to the notion of dimension in vector spaces.</p><p>Matroid polytopes. We consider polytopes P ⊂ R X + with the property that for any x, y ∈ R X , 0 ≤ x ≤ y, y ∈ P ⇒ x ∈ P . We call such a polytope down-monotone. A down-monotone polytope of particular importance here is the matroid polytope. For a matroid M = (X, I), the matroid polytope is defined as</p><formula xml:id="formula_11">P (M) = conv {1 I : I ∈ I}.</formula><p>As shown by Edmonds <ref type="bibr" target="#b11">[12]</ref>, an equivalent description is</p><formula xml:id="formula_12">P (M) = ⎧ ⎨ ⎩ x ≥ 0 : ∀S ⊆ X; j∈S x j ≤ r M (S) ⎫ ⎬ ⎭ .</formula><p>From this description, it is clear that</p><formula xml:id="formula_13">P (M) is down-monotone. A base of M is a set S ∈ I such that r M (S) = r M (X). The base polytope of M is given by B(M) = {y ∈ P (M) | i∈X y i = r M (X)}.</formula><p>The extreme points of B(M) are the characteristic vectors of the bases of M. Given the problem max{f (S) : S ∈ I}, where M = (X, I) is a matroid, there always exists an optimum solution S * such that S * is a base of M. Note that this is false if f is not monotone. Thus, for monotone f , it is equivalent to consider the problem max S∈B f (S), where B is the set of bases of M. See <ref type="bibr" target="#b39">[39]</ref> for more details on matroids and polyhedral aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Our approach.</head><p>We consider the problem</p><formula xml:id="formula_14">(2.2) max{f (S) : S ∈ I},</formula><p>where f : 2 X → R + is a monotone submodular function and M = (X, I) is a matroid. Apart from the greedy algorithm, which yields a 1/2-approximation for this problem, previous approaches have relied on linear programming. In special cases, such as the case of sums of weighted rank functions <ref type="bibr" target="#b2">[3]</ref>, the discrete problem (2.2) can be replaced by a linear programming problem,</p><formula xml:id="formula_15">(2.3) max i c i x i : x ∈ P ,</formula><p>where P is a convex polytope. This linear program relies on the structure of a specific variant of the problem and typically can be solved exactly or to an arbitrary precision.</p><p>Then, an optimal solution of (2.3) can be rounded to an integral solution S ∈ I while losing a certain fraction of the objective value. In the case where f (S) is a sum of weighted rank functions of matroids, we showed in <ref type="bibr" target="#b2">[3]</ref> that using the technique of pipage rounding we can recover an integral solution of value at least (1 -1/e)OP T . Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php For a monotone submodular function f (S) given by a value oracle, it is not obvious how to replace (2.2) by a linear program. Nonetheless, we have a generic way of replacing a discrete function f (S) by a continuous function: the multilinear extension F (y) = E[f (ŷ)] described in section 2.1. We note that although we cannot evaluate F (y) exactly, we can approximate it by random sampling. For the purposes of this section, we can assume that we can evaluate F (y) to an arbitrary precision. Using this extension, we obtain a multilinear optimization problem:</p><formula xml:id="formula_16">(2.4) max{F (y) : y ∈ P (M)},</formula><p>where P (M) is the matroid polytope of M. If F (y) were a concave function, we would be in good shape to deal with this continuous problem, using convex optimization techniques (although it is still not clear how we would then convert a fractional solution to a discrete one). However, F (y) is not a concave function (consider the example</p><formula xml:id="formula_17">F (y) = 1 - n i=1 (1 -y i ) from section 2.1</formula><p>). As we discussed in section 2.1, F (y) is a smooth submodular function. Typically, it is concave in certain directions while convex in others. This will actually be useful both for treating the continuous problem and rounding its fractional solution.</p><p>Our solution.</p><p>1. We use a continuous greedy process to approximate max{F (y) : y ∈ P (M)} within a factor of 1 -1/e. 2. We use the pipage rounding technique to convert a fractional solution y ∈ P (M) to a discrete solution S of value f (S) ≥ F (y) ≥ (1 -1/e)OP T . We remark that the second stage of the solution is identical to the one that we used in <ref type="bibr" target="#b2">[3]</ref> in the case of sums of weighted rank functions. The first stage has been discovered more recently; it first appeared in <ref type="bibr" target="#b43">[42]</ref> in the context of the submodular welfare problem. Next, we describe these two stages of our solution at a conceptual level before giving detailed proofs in section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">The continuous greedy process.</head><p>We consider any down-monotone polytope P and a smooth monotone submodular function F . For concreteness, the reader may think of the matroid polytope P (M) and the function F (y) = E[f (ŷ)] defined in section 2.1. Our aim is to define a process that runs continuously, depending only on local properties of F , and produces a point y ∈ P approximating the optimum OP T = max{F (y) : y ∈ P }. We propose moving in the direction of a vector constrained by P which maximizes the local gain.</p><p>The continuous greedy process. We view the process as a particle starting at y(0) = 0 and following a certain flow over a unit time interval:</p><formula xml:id="formula_18">dy dt = v max (y), where v max (y) is defined as v max (y) = argmax v∈P (v • ∇F (y)). Claim. y(1) ∈ P and F (y(1)) ≥ (1 -1/e)OP T .</formula><p>First, the trajectory for t ∈ [0, 1] is contained in P , since</p><formula xml:id="formula_19">y(t) = t 0 v max (y(τ ))dτ</formula><p>is a convex linear combination of vectors in P . To prove the approximation guarantee, fix a point y and suppose that x * ∈ P is the true optimum, OP T = F (x * ). The essence of our analysis is that the rate of increase in F (y) is at least as much as the deficit Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php OP T -F (y). This kind of behavior always leads to a factor of 1 -1/e, as we show below.</p><p>Consider the direction v * = (x * ∨ y)y = (x *y) ∨ 0. This is a nonnegative vector; since v * ≤ x * ∈ P and P is down-monotone, we also have v * ∈ P . By monotonicity, F (y + v * ) = F (x * ∨ y) ≥ F (x * ) = OP T . Consider the ray of direction v * starting at y, and the function F (y + ξv * ), ξ ≥ 0. The directional derivative of F along this ray is dF dξ = v * • ∇F . Since F is smooth submodular and v * is nonnegative, F (y + ξv * ) is concave in ξ and dF dξ is nonincreasing. By concavity,</p><formula xml:id="formula_20">F (y + v * ) -F (y) ≤ dF dξ ξ=0 = v * • ∇F (y). Since v * ∈ P , and v max (y) ∈ P maximizes v • ∇F (y) over all vectors v ∈ P , we get (2.5) v max (y) • ∇F (y) ≥ v * • ∇F (y) ≥ F (y + v * ) -F (y) ≥ OP T -F (y).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Now let us return to our continuous process and analyze F (y(t))</head><p>. By the chain rule and using (2.5), we get</p><formula xml:id="formula_21">dF dt = j ∂F ∂y j dy j dt = v max (y(t)) • ∇F (y(t)) ≥ OP T -F (y(t)).</formula><p>This means that F (y(t)) dominates the solution of the differential equation</p><formula xml:id="formula_22">dφ dt = OP T -φ(t), φ(0) = 0, which is φ(t) = (1 -e -t )OP T . This proves F (y(t)) ≥ (1 -e -t )OP T .</formula><p>The direction v max (y) at each point is determined by maximizing a linear function v • ∇F (y) over v ∈ P . In the case of a matroid polytope P (M), this problem can be solved very efficiently. We can assume that v max (y) is a vertex of P and furthermore, since ∇F is a nonnegative vector, that this vertex corresponds to a base of M. Hence, without loss of generality v max (y) is the indicator vector of a base and can be found by the greedy algorithm for maximum-weight base in a matroid. The final point y( <ref type="formula">1</ref>) is a convex linear combination of such vectors and hence lies in the base polytope B(M).</p><p>Remark. Wolsey's continuous greedy algorithm <ref type="bibr" target="#b46">[45]</ref> can be viewed as a greedy process guided by v max (y) = e j , where ∂F ∂yj is the maximum partial derivative out of those where y j can be still increased. In other words, only one coordinate is being increased at a time. In our setting, with F (y) = E[f (ŷ)] and starting at y(0) = 0, it can be seen that y j will increase up to its maximal possible value (which turns out to be 1) and then a new coordinate will be selected. This is equivalent to the classical greedy algorithm, which gives a 1/2-approximation. <ref type="bibr" target="#b0">[1]</ref> developed an elegant technique for rounding solutions of linear and nonlinear programs that they called "pipage rounding." Subsequently, Srinivasan <ref type="bibr" target="#b40">[40]</ref> and Gandhi et al. <ref type="bibr" target="#b20">[20]</ref> interpreted some applications of pipage rounding as a deterministic variant of dependent randomized rounding. In a typical scenario, randomly rounding a fractional solution of a linear program does not preserve the feasibility of constraints, in particular equality constraints. Nevertheless, the techniques of <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b20">20]</ref> show that randomized rounding can be applied in a certain controlled way to guide a solution that respects certain classes of constraints. In this paper we show that the rounding framework applies quite naturally to our problem. Further, our analysis also reveals the important role of submodularity in this context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Pipage rounding. Ageev and Sviridenko</head><p>In our setting, we have an (approximate) fractional solution of the problem max{F (y) : y ∈ P (M)}, where F (y) = E[f (ŷ)]. We wish to round a fractional Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php solution y * ∈ P (M) to a discrete solution S ∈ I. In other words we want to go from a point inside P (M) to a vertex of the polytope. As we argued above, we can assume that y * ∈ B(M); i.e., it is a convex linear combination of bases of M.</p><p>The base polytope has a particular structure: it is known, for example, that the edges of the base polytope are all of the form (1 I , 1 J ), where J is a base obtained from I by swapping one element for another <ref type="bibr" target="#b39">[39]</ref>. This implies (and we will argue about this more precisely in section 3.2) that it is possible to move from any point y ∈ B(M) to a vertex in a sequence of moves, where the direction in each move is given by a vector e ie j , where e i = (0, . . . , 0, 1, 0, . . . , 0) is a canonical basis vector. Moreover, in each step we have a choice of either e ie j or e je i . The crucial property of F (y) that makes this procedure work is the following.</p><p>Claim. For any y ∈ [0, 1] X and i, j ∈ X, the function</p><formula xml:id="formula_23">F y ij (t) = F (y + t(e i -e j )) is convex.</formula><p>We prove this by using the smooth submodularity of</p><formula xml:id="formula_24">F (y) = E[f (ŷ)]. We have F y ij (t) = F (y + td),</formula><p>where d = e ie j . The coordinates of d are d i = 1 and d j = -1, and the rest are 0. By differentiating F y ij (t) twice with respect to t, we obtain</p><formula xml:id="formula_25">d 2 F y ij dt 2 = α,β ∂ 2 F ∂y α ∂y β d α d β = ∂ 2 F ∂y i 2 -2 ∂ 2 F ∂y i ∂y j + ∂ 2 F ∂y j 2 .</formula><p>As we discussed in section 2.1,</p><formula xml:id="formula_26">∂ 2 F ∂yi 2 = ∂ 2 F ∂yj 2 = 0, while ∂ 2 F ∂yi∂yj ≤ 0. Therefore, d 2 F y ij dt 2 ≥ 0 and the function F y ij (t) is convex. The convexity of F y ij (t) = F (y + t(e i -e j ))</formula><p>allows us in each step to choose one of two possible directions, e ie j or e je i , so that the value of F (y) does not decrease. Eventually, we reach a vertex of the polytope and hence a discrete solution such that f (S) ≥ F (y * ) ≥ (1 -1/e)OP T . We will in fact present a randomized variant of this technique, where we choose a random direction in each step, and we prove a guarantee in expectation. We defer further details to section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The algorithm for submodular maximization subject to a matroid constraint.</head><p>Here we describe in detail the two main components of our algorithm. On a high level, the algorithm works as follows.</p><p>The algorithm. Given: matroid M = (X, I) (membership oracle), monotone submodular f : 2 X → R + (value oracle).</p><p>1. Run ContinuousGreedy(f, M) to obtain a fractional solution y * ∈ B(M).</p><p>2. Run PipageRound(M, y * ) to obtain a discrete solution S ∈ I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">The continuous greedy algorithm.</head><p>The first stage of our algorithm handles the continuous optimization problem max{F (y) : y ∈ P (M)}. The continuous greedy process (section 2.3) provides a guide on how to design our algorithm. It remains to deal with two issues.</p><p>• To obtain a finite algorithm, we need to discretize the time scale. This introduces some technical issues regarding the granularity of our discretization and the error incurred. • In each step, we need to find v max (y) = argmax v∈P (M) (v • ∇F (y)). Apart from estimating ∇F (which can be done by random sampling), observe that this amounts to a linear optimization problem over P (M). This means finding a maximum-weight independent set in a matroid, a task which can be solved easily. 1. Let δ = 1 9d 2 , where d = r M (X) (the rank of the matroid). Let n = |X|. Start with t = 0 and y(0) = 0. 2. Let R(t) contain each j independently with probability y j (t). For each j ∈ X, let ω j (t) be an estimate of E[f R(t) (j)], obtained by taking the average of 10 δ 2 (1 + ln n) independent samples of R(t). 3. Let I(t) be a maximum-weight independent set in M, according to the weights ω j (t). We can find this by the greedy algorithm. Let</p><formula xml:id="formula_27">y(t + δ) = y(t) + δ • 1 I(t) .</formula><p>4. Increment t := t + δ; if t &lt; 1, go back to step 2. Otherwise, return y(1). The fractional solution found by the continuous greedy algorithm is a convex combination of independent sets, y(1) = δ t 1 I(t) ∈ P (M). Since the independent sets I(t) are obtained by maximization with nonnegative weights, we can assume that each</p><formula xml:id="formula_28">I(t) is a base of M. Therefore, y(1) ∈ B(M).</formula><p>The crucial inequality that allows us to analyze the performance of this stage is the following lemma (analogous to (2.5)). In the following, we denote by OP T = max S∈I f (S) the optimum to our problem.</p><p>Lemma 3.1. Consider any y ∈ [0, 1] X , and let R denote a random set corresponding to ŷ, with elements sampled independently according to y j . Then</p><formula xml:id="formula_29">OP T ≤ F (y) + max I∈I j∈I E[f R (j)].</formula><p>Proof. Fix an optimal solution O ∈ I. By submodularity, we have OP T = f (O) ≤ f (R) + j∈O f R (j) for any set R. By taking the expectation over a random R as above,</p><formula xml:id="formula_30">OP T ≤ E[f (R) + j∈O f R (j)] = F (y) + j∈O E[f R (j)] ≤ F (y) + max I∈I j∈I E[f R (j)].</formula><p>In each step, our algorithm tries to find a set I ∈ I maximizing j∈I E[f R (j)]. However, instead of the true expectations E[f R (j)], we use the estimates ω j (t). The following lemma characterizes how much we lose by using these estimates. In the next lemma and the one after that, we use the term "with high probability" to mean with probability at least (1 -1/poly(n)).</p><p>Lemma 3.2. With high probability, the algorithm for every t finds a set I(t) such that</p><formula xml:id="formula_31">j∈I(t) E[f R(t) (j)] ≥ (1 -2dδ)OP T -F (y(t)).</formula><p>Proof. Recall that I(t) is an independent set maximizing j∈I ω j (t), where ω j (t) are our estimates of</p><formula xml:id="formula_32">E[f R(t) (j)]. Let us call an estimate bad if |ω j (t) -E[f R(t) (j)]| &gt; δ • OP T .</formula><p>We prove that with high probability there is no bad estimate throughout the algorithm.</p><p>Consider an estimate ω j (t) of E[f R(t) (j)], obtained using 10 δ 2 (1 + ln n) independent samples R i of R(t). We apply Theorem 2.2 with</p><formula xml:id="formula_33">X i = (f Ri (j) -E[f R(t) (j)])/OP T , k = 10 δ 2 (1 + ln n), and a = δk. We have |X i | ≤ 1, because OP T ≥ max j f (j) ≥ max R,j f R (j). The estimate is bad if and only if | X i | &gt; a, and Theorem 2.2 implies that Pr[| X i | &gt; a] ≤ 2e -a 2 /2k = 2e -δ 2 k/2 ≤ 1/(18n 5</formula><p>). In each time step, we compute n such estimates, and the total number of steps is 1/δ = 9d 2 . By the union bound, the probability that there is any bad estimate is at most </p><formula xml:id="formula_34">(t) -E[f R(t) (j)]| ≤ δ • OP T for all j, t. Let M = max I∈I j∈I E[f R(t) (j)],</formula><p>and let I * be a set achieving this maximum. By Lemma 3.1, we know that M ≥ OP T -F (y(t)). We have j∈I * ω j ≥ Mdδ • OP T , and since our algorithm finds a set I(t) ∈ I maximizing j∈I ω j , we also have</p><formula xml:id="formula_35">j∈I(t) ω j ≥ M -dδ • OP T . Finally, j∈I(t) E[f R(t) (j)] ≥ j∈I(t) ω j -dδ•OP T ≥ M -2dδ•OP T ≥ (1-2dδ)OP T -F (y(t)).</formula><p>Now we prove the main result of this section. Lemma 3.3. With high probability, the fractional solution y found by the continuous greedy algorithm satisfies</p><formula xml:id="formula_36">F (y) ≥ 1 - 1 e - 1 3d</formula><p>• OP T.</p><p>Proof. We start with F (y(0)) = 0. Our goal is to estimate how much F (y(t)) increases during one iteration of the algorithm. Consider a random set R(t) corresponding to ŷ(t) and an independently random set D(t) that contains each item j independently with probability Δ j (t) = y j (t + δ)y j (t). In other words Δ(t) = y(t + δ)y(t) = δ • 1 I(t) and D(t) is a random subset of I(t) where each element appears independently with probability δ. It can easily be seen that</p><formula xml:id="formula_37">F (y(t + δ)) = E[f (R(t + δ))] ≥ E[f (R(t) ∪ D(t))</formula><p>]. This follows from monotonicity, because R(t + δ) contains items independently with probabilities y j (t) + Δ j (t), while R(t) ∪ D(t) contains items independently with (smaller) probabilities 1 -(1y j (t))(1 -Δ j (t)). The two distributions can be coupled so that R(t) ∪ D(t) is a subset of R(t + δ), and hence the inequality follows.</p><p>Now we are ready to estimate how much F (y) gains at time t. It is important that the probability that any item appears in D(t) be very small, so we can focus on the contributions from sets D(t) that turn out to be singletons. From the discussion above, we obtain</p><formula xml:id="formula_38">F (y(t + δ)) -F (y(t)) ≥ E[f (R(t) ∪ D(t)) -f (R(t))] ≥ j Pr[D(t) = {j}] E[f R(t) (j)] = j∈I(t) δ(1 -δ) |I(t)|-1 E[f R(t) (j)] ≥ δ(1 -dδ) j∈I(t) E[f R(t) (j)],</formula><p>using |I(t)| = d in the last inequality. Applying Lemma 3.2, with high probability, for each t, we get</p><formula xml:id="formula_39">F (y(t + δ)) -F (y(t)) ≥ δ(1 -dδ) ((1 -2dδ)OP T -F (y(t))) ≥ δ( ÕP T -F (y(t))),</formula><p>where we set ÕP T = (1 -3dδ)OP T . From here, ÕP T -</p><formula xml:id="formula_40">F (y(t + δ)) ≤ (1 -δ)( ÕP T - F (y(t))) and, by induction, ÕP T -F (y(kδ)) ≤ (1 -δ) k ÕP T . For k = 1/δ, we get ÕP T -F (y(1)) ≤ (1 -δ) 1/δ ÕP T ≤ 1 e ÕP T .</formula><p>Therefore, F (y(1)) Remark. The error term 1/(3d) can be made /d for any fixed &gt; 0, but in fact it can be eliminated altogether. As we prove in Appendix A, when the discretization step δ is chosen small enough, the continuous greedy algorithm achieves a clean approximation factor of 1 -1/e.</p><formula xml:id="formula_41">≥ (1 -1/e) Õ P T ≥ (1 -1/e -3dδ)OP T = (1 -1/e -</formula><p>Here we sketch an alternative way to eliminate the error term, using partial enumeration <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b27">27]</ref>. We argue as follows: For each x ∈ X, we run the algorithm above with F x instead of F , where F x (y) = E[f {x} (ŷ)], and M x instead of M, where M x = M/x is the matroid with element x contracted (A is independent in M x iff A + x is independent in M). Since the optimum solution has d elements, by submodularity there is an element x such that f ({x}) ≥ OP T /d. We assume that this is the element chosen by the algorithm. The optimum solution in the reduced instance has value OP Tf ({x}), and the continuous greedy algorithm returns a point</p><formula xml:id="formula_42">y ∈ B(M x ) such that F x (y) ≥ (1 -1 e -1 3d )(OP T -f ({x}))</formula><p>. Hence, y = y + e x is feasible in B(M) and</p><formula xml:id="formula_43">F (y ) = f ({x})+F x (y) ≥ 1 - 1 e - 1 3d OP T + 1 e f ({x}) ≥ 1 - 1 e + 1 ed - 1 3d OP T.</formula><p>So in fact we gain a Θ( 1 d OP T ) term. Our bounds holds with probability at least 1 -1/poly(n), and hence we also get a clean factor 1 -1/e in expectation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The pipage rounding algorithm.</head><p>We start with a point y * in the base polytope B(M). The pipage rounding technique aims to convert y * into an integral solution, corresponding to a vertex of B(M). Given y ∈ [0, 1] n we say that i is fractional in y if 0 &lt; y i &lt; 1. Our goal is to gradually eliminate all fractional variables.</p><p>In the following, we use y(A) = i∈A y i . For </p><formula xml:id="formula_44">y ∈ P (M), a set A ⊆ X is tight if y(A) = r M (A).</formula><formula xml:id="formula_45">y(A) + y(B) = r M (A) + r M (B) ≥ r M (A ∩ B) + r M (A ∪ B) ≥ y(A ∩ B) + y(A ∪ B) = y(A) + y(B).</formula><p>Therefore, all the inequalities above must be tight. We are interested in tight sets that contain a fractional variable. Observe that a tight set with a fractional variable has at least two fractional variables. Given a tight set T with fractional variables i, j, we let y ij (t) = y +t(e i -e j ). In other words, we add t to y i , subtract t from y j , and leave the other values unchanged. We define a function of one variable F y ij , where F y ij (t) = F (y ij (t)). As we argued in section 2.4, F y ij (t) is convex, and hence it must be nondecreasing either for t &gt; 0 or t &lt; 0. Therefore we can modify the fractional variables y i , y j by increasing one of them and decreasing the other until we hit another constraint.</p><p>Instead of checking which direction is more profitable (as in <ref type="bibr" target="#b2">[3]</ref>), we make the choice random. We move from y to a random point y , choosing the probabilities so that E[y | y] = y; due to convexity, this preserves the guarantee on F (y) in expectation. (We analyze this step more formally in the proof of Lemma 3.5.) This has the advantage that the rounding technique is oblivious-it does not need to access Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php the objective function. For instance, we can use it even in settings where we have only approximate-oracle access to f (S).</p><p>In order to find the first constraint that would be violated in a direction e ie j , we need to minimize the function r M (S)y(S) over A = {S ⊆ X : i ∈ S, j / ∈ S}. Since r M (S)y(S) is a submodular function, minimization can be implemented in polynomial time <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b38">38]</ref>. In fact, in this particular case, we do not need the full power of submodular minimization; there is a simpler algorithm due to Cunningham <ref type="bibr" target="#b9">[10]</ref>.</p><p>After hitting a new constraint, we obtain a new tight set A . Then we either produce a new integral variable (in which case we restart with T = X), or we continue with T ∩ A which is a smaller set and again tight (due to Proposition 3.4). A formal description of the algorithm is given below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subroutine HitConstraint(y, i, j):</head><p>Denote A = {A ⊆ X : i ∈ A, j / ∈ A}; Find δ = min A∈A (r M (A)y(A)) and A ∈ A achieving this; If y j &lt; δ, then {y i ← y i + y j , y j ← 0, A ← {j}} Else {y i ← y i + δ, y j ← y jδ, A ← A}; Return (y, A ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm PipageRound(M, y):</head><p>While (y is not integral) do T ← X; While (T contains fractional variables) do Pick i, j ∈ T fractional; (y + , A + ) ← HitConstraint(y, i, j); (y -, A -) ← HitConstraint(y, j, i);</p><formula xml:id="formula_46">If (y + = y -= y), then T ← T ∩ A + Else p ← ||y + -y||/||y + -y -||; With probability p, {y ← y -, T ← T ∩ A -} Else {y ← y + , T ← T ∩ A + }; EndWhile EndWhile Output y.</formula><p>PipageRound(M, y) is the main procedure. The subroutine HitConstraint(y, i, j) finds the nearest constraint in the direction e ie j and returns the point of intersection as well as a new tight set (which could be a singleton if a variable has become integral).</p><p>We remark on a technical point in the procedure PipageRound. When considering the current tight set T with fractional variables i and j, it may be the case that there are strictly smaller tight sets containing i or j; in this case we cannot change y i and y j and need to find a smaller tight set containing two fractional variables. The procedure HitConstraint(y, i, j) returns (y + , A + ), where y + = y and A + is a smaller tight set containing i, and similarly HitConstraint(y, j, i) returns (y -, A -), where y -= y and A -is a smaller tight set containing j. PipageRound picks a new tight T = T ∩ A + (T = T ∩ A -would work as well). The new tight set is smaller, and hence eventually the algorithm finds two fractional variables that it can change. Proof. The algorithm does not alter a variable y i once y i ∈ {0, 1}. An invariant maintained by the algorithm is that y ∈ B(M) and T is a tight set. To verify that y ∈ B(M), observe that y(X) = r M (X) remains unchanged throughout the algorithm; we need to check that y(S) ≤ r M (S) remains satisfied for all sets S. Consider the subroutine HitConstraint. The only sets whose value y(S) increases are those containing i and not containing j, i.e., S ∈ A. We increase y i by at most δ = min S∈A (r M (S)y(S)); therefore y(S) ≤ r M (S) is still satisfied for all sets. We also make sure that we do not violate nonnegativity, by checking whether y j &lt; δ. In case y j &lt; δ, the procedure makes y j zero and returns A = {j}.</p><p>Concerning the tightness of T , we initialize T ← X, which is tight because y ∈ B(M). After calling HitConstraint, we obtain sets A + , A -, which are tight for y + and y -, respectively. The new set T is obtained by taking an intersection with one of these sets; in either case, we get a new tight set T at the end of the inner loop, due to Proposition 3.4. Note that each of the sets A + , A -returned by HitConstraint contains exactly one of the elements i, j. Therefore, the size of T decreases after the execution of the inner loop. As long as we do not make any new variable integral, one of the fractional variables y i , y j is still in the new tight set T and so we can in fact find a pair of fractional variables in T . However, due to the decreasing size of T , we cannot repeat this more than n -1 times. At some point, we must make a new variable integral, and then we restart the inner loop with T = X. The outer loop can also iterate at most n times, since the number of integral variables increases after each outer loop.</p><p>Finally, we need to show that the expected value of the final solution is E[f (S)] ≥ F (y * ). In each step, we move from y to a random point y ∈ {y + , y -}, y -with probability p or y + with probability 1p. We have F (y + ) = F y ij ( + ) and F (y -) = F y ij ( -), where -&lt; 0 &lt; + . The probabilities are chosen so that p -+ (1p) + = 0, i.e., E[y | y] = y. By Jensen's inequality, using the convexity of F y ij , we obtain</p><formula xml:id="formula_47">E[F (y )] = pF y ij ( -) + (1 -p)F y ij ( + ) ≥ F y ij (0) = F (y)</formula><p>. By induction on the number of steps of the rounding procedure, we obtain E[f (S)] ≥ F (y * ), where y * ∈ B(M) is the initial point and S is the final integral solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Simplification for partition matroids.</head><p>In the special case of a simple partition matroid, we can simplify the algorithm by essentially skipping the pipage rounding stage. This type of matroid appears in several applications. Definition 3.6. For a ground set partitioned into X</p><formula xml:id="formula_48">= X 1 ∪ X 2 ∪ • • • ∪ X k , the simple partition matroid is M = (X, I), where I = {S ⊆ X : ∀i; |S ∩ X i | ≤ 1}.</formula><p>By the definition of the matroid polytope, P (M) = {y ∈ R X + : ∀i; j∈Xi y j ≤ 1}. Therefore, it is natural to interpret the variables y j as probabilities and round a fractional solution by choosing exactly one random element in each X i , with probabilities according to y (we can assume that y ∈ B(M) and hence j∈Xi y j = 1 for each X i ).</p><p>The following lemma confirms that this works.</p><p>Lemma 3.7.</p><formula xml:id="formula_49">Let X = X 1 ∪ • • • ∪ X k , let f : 2 X → R + be</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a monotone submodular function, and let y ∈ B(M), where M is a simple partition matroid on</head><formula xml:id="formula_50">X = X 1 ∪ • • • ∪ X k .</formula><p>Let T be a random set where we sample independently from each X i exactly one random element, element j with probability y j . Then This problem (under a different name) was considered by Fisher, Nemhauser, and Wolsey <ref type="bibr" target="#b17">[17]</ref> as a motivating example for submodular maximization subject to a matroid constraint. They showed that the greedy algorithm achieves a 1/2-approximation in the value oracle model, in fact even for the on-line variant, where items are arriving one by one-this follows from the "locally greedy heuristic" in <ref type="bibr" target="#b17">[17]</ref> and was rediscovered in <ref type="bibr" target="#b32">[32]</ref>. On the hardness side, it has been shown that a (1-1/e+ )-approximation for any fixed &gt; 0 would imply P = N P <ref type="bibr" target="#b26">[26]</ref>. This hardness result holds in particular for submodular utilities induced by explicitly given set coverage systems. A (1 -1/e)-approximation has been found in this case <ref type="bibr" target="#b10">[11]</ref>, and also in the case of general submodular utilities, but using the stronger demand oracle model. In this model, the (1 -1/e)-approximation has been subsequently generalized to all fractionally subadditive functions <ref type="bibr" target="#b14">[14]</ref> and the ratio for submodular functions has been improved to 1 -1/e + δ for some fixed δ &gt; 0 <ref type="bibr" target="#b16">[16]</ref>. This does not contradict the hardness result of <ref type="bibr" target="#b26">[26]</ref>, which holds only in the value oracle model. Moreover, recently it has been proved that in the value oracle model a (1 -1/e + )-approximation for the submodular welfare problem would require exponentially many value queries <ref type="bibr" target="#b35">[35]</ref>. It was an open problem whether a (1 -1/e)-approximation can be achieved for the submodular welfare problem using only value queries.</p><formula xml:id="formula_51">E[f (T )] ≥ F (y).</formula><p>Our result. Since the submodular welfare problem can be seen as a special case of SUB-M <ref type="bibr" target="#b17">[17]</ref>, our work implies a randomized (1-1/e)-approximation, thus resolving the status of the problem in the value oracle model (this result first appeared in <ref type="bibr" target="#b43">[42]</ref>). For completeness, we describe the reduction to SUB-M.</p><p>The reduction. For a given set of items A and number of players n, we define a ground set X = [n]×A. The elements of X can be viewed as clones of items, one clone of each item for each player. For each player i, we define a mapping π i : 2 X → 2 A ,</p><formula xml:id="formula_52">π i (S) = {j ∈ A | (i, j) ∈ S},</formula><p>which simply takes all the clones in S corresponding to player i. Given utility functions w 1 , . . . , w n : 2 A → R + , we define a function f : 2</p><formula xml:id="formula_53">X → R + , f (S) = n i=1 w i (π i (S)).</formula><p>It can be seen that if w i is submodular, then w i • π i is submodular, and hence f is submodular as well.</p><p>The problem of partitioning</p><formula xml:id="formula_54">A = S 1 ∪S 2 ∪• • •∪S n so that n i=1 w i (S i ) is maximized is equivalent to finding S = n i=1 ({i} × S i ) ⊆ X</formula><p>, containing at most one clone of each item, so that f (S) is maximized. Sets of this type form a partition matroid:</p><formula xml:id="formula_55">I = {S ⊆ X | ∀j; |S ∩ X j | ≤ 1},</formula><p>where X j = [n] × {j}. Note that the rank of this matroid is m = |A|, the number of items. Therefore, the welfare maximization problem is equivalent to maximizing f (S) subject to S ∈ I.</p><p>Our algorithm yields a (1 -1/e)-approximation for the submodular welfare problem, which is optimal, as we mentioned above. Moreover, we can simplify the algorithm by skipping the pipage rounding stage. This is possible because we are dealing Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php with a simple partition matroid, as we discussed in section 3.3. The fractional variables are associated with elements of [n] × A, i.e., player-item pairs, and it is natural to denote them by y ij . Each set X j = [n] × {j} consists of all the clones of item j. By Lemma 3.7, the fractional solution obtained by the continuous greedy algorithm can be rounded by taking one random clone of each item, i.e., allocating each item to a random player, with probabilities y ij . Reinterpreting our continuous greedy algorithm in this setting, we obtain the following. Note that |X| = mn and the rank of the matroid is m = |A|.</p><p>The continuous greedy algorithm for the submodular welfare problem.</p><formula xml:id="formula_56">1. Let δ = 1 9m 2</formula><p>where m is the number of items. Start with t = 0 and y ij (0) = 0 for all i, j. 2. Let R i (t) be a random set containing each item j independently with probability y ij (t). For all i, j, estimate the expected marginal profit of player i from item j,</p><formula xml:id="formula_57">ω ij (t) = E[w i (R i (t) + j) -w i (R i (t))],</formula><p>by taking the average of 10 δ 2 (1 + ln(mn)) independent samples. 3. For each j, let i j (t) = argmax i ω ij (t) be the preferred player for item j (breaking possible ties arbitrarily). Set y ij (t + δ) = y ij (t)+ δ for the preferred player i = i j (t) and y ij (t + δ) = y ij (t) otherwise. 4. Increment t := t + δ; if t &lt; 1, go back to step 2. 5. Allocate each item j independently, with probability y ij (1) to player i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">The generalized and separable assignment problems.</head><p>Here we consider an application of our techniques to the generalized assignment problem (GAP). An instance of GAP consists of n bins and m items. Each item i has two nonnegative numbers for each bin j: a value v ij and a size s ij . We seek an assignment of items to bins such that the total size of items in each bin is at most one<ref type="foot" target="#foot_1">2</ref> and the total value of all items is maximized. In <ref type="bibr" target="#b19">[19]</ref>, a (1 -1/e)-approximation algorithm for GAP is presented. The algorithm is based on solving an exponential sized linear program. The separation oracle for the dual of this linear program is the knapsack problem, and one obtains an arbitrarily close approximation to it by using an FPTAS for knapsack. In <ref type="bibr" target="#b16">[16]</ref>, it is shown that the worst-case integrality gap is in fact 1 -1/e + δ for some constant δ &gt; 0, thus resulting in an improved approximation. It is also known that unless P = N P there is no 10/11 approximation for GAP <ref type="bibr" target="#b4">[5]</ref>.</p><p>Our techniques yield a (1-1/e-o(1))-approximation algorithm for GAP. Previous algorithms that achieve a comparable ratio <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b16">16]</ref> rely on solving a large linear program. Although the ratio guaranteed by our algorithm is slightly worse than the (1 -1/e + δ)-approximation of <ref type="bibr" target="#b16">[16]</ref>, we believe that the algorithm is conceptually simple and with additional work can be made efficient in practice. Our algorithm also generalizes to other assignment problems for which the factor 1 -1/e is known to be optimal.</p><p>The separable assignment problem. An instance of the separable assignment problem (SAP) consists of m items and n bins. Each bin j has an associated collection of feasible sets F j which is down-closed (A ∈ F j , B ⊆ A ⇒ B ∈ F j ). Each item i has a value v ij , depending on the bin j where it is placed. The goal is to choose disjoint G. CALINESCU, C. CHEKURI, M. P ÁL, AND J. VONDR ÁK feasible sets S j ∈ F j so as to maximize n j=1 i∈Sj v ij . For computational purposes we assume that each F j is accessed via a membership oracle.</p><p>Reduction to a matroid constraint. SAP can be cast as a special case of SUB-M as follows: We define the ground set X to be {(j, S)</p><formula xml:id="formula_58">| 1 ≤ j ≤ n, S ∈ F j }.</formula><p>The interpretation of X is that for each bin j we create a separate copy of the items and these can be packed only in j. Note that this allows us to pack an original item in multiple bins. We define a function f : 2</p><formula xml:id="formula_59">X → R + , f (S) = i max j {v ij : ∃(j, S) ∈ S, i ∈ S}.</formula><p>It is easy to check that f is monotone and submodular. We observe that, for an item i that is potentially packed in multiple bins (via copies in X), f gives only the profit for the most profitable copy. We maximize this function subject to a matroid constraint M = (X, I), where S ∈ I iff S contains at most one pair (j, S j ) for each j. Such a set S corresponds to an assignment of set S j to bin j for each (j, S j ) ∈ S. M is a simple partition matroid constraint on X.</p><p>The approximate greedy process. Before we describe our algorithm for SAP, we need to discuss a generalization of our framework. Let us consider a setting where we cannot optimize linear functions over P (M) exactly but only α-approximately (α &lt; 1). Let us consider the continuous setting (section 2.3). Assume that in each step we are able to find a vector v α (y</p><formula xml:id="formula_60">) ∈ P (M) such that v α (y)•∇F (y) ≥ α max v∈P (M) (v • ∇F (y)). By (2.5), v α (y) • ∇F (y) ≥ α(OP T -F (y)). This leads to a differential inequality dF dt ≥ α(OP T -F (y(t)))</formula><p>whose solution is F (y(t)) ≥ (1e -αt )OP T . At time t = 1, we obtain a (1e -α )approximation. The rest of the analysis follows as in section 3.1.</p><p>Implementing the algorithm for SAP. The ground set of M is exponentially large here, so we cannot use the algorithm of section 3 as a black box. However, the rank of M is only n (the number of bins), which is useful. This means the step size δ in the continuous greedy algorithm is polynomially small in n. The algorithm works with variables corresponding to the ground set X; let us denote them by y j,S , where S ∈ F j . Note that in each step only n variables are incremented (one for each bin j), and hence the number of nonzero variables remains polynomial. Based on these variables, we can generate a random set R ⊆ X in each step. However, we cannot estimate all marginal values ω j,S = E[f R (j, S)] since these are exponentially many.</p><p>What we do is the following: Observe that</p><formula xml:id="formula_61">ω j,S = E[f R (j, S)] = i∈S E[f R (j, i)],</formula><p>where</p><formula xml:id="formula_62">f R (j, i) = max{0, v ij -max{v ij : ∃(j , S) ∈ R; i ∈ S}}</formula><p>is the marginal profit of adding item i to bin j, compared to its assignment in R. For each item i, we estimate</p><formula xml:id="formula_63">ω ij = E[f R (j, i)].</formula><p>We choose the number of samples to be (mn) 5 so that the error per item is bounded by OP T /(mn) 2 with high probability.</p><p>We have ω j,S = i∈S ω ij for any set S; our estimate of ω j,S is accurate within Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php OP T /(mn 2 ). Finding a maximum-weight independent set I ∈ I means finding the optimal set S j for each bin j, given the weights ω ij . This is what we call the single-bin subproblem. We use the item weights ω ij and try to find a set S ∈ F j maximizing i∈S ω ij . If we can solve this problem α-approximately (α &lt; 1), we can also find an α-approximate maximum-weight independent set I. Our sampling estimates add an o <ref type="bibr" target="#b0">(1)</ref> error to this computation. As we argued above, we obtain a (1e -αo( <ref type="formula">1</ref>))approximation for SAP. We summarize the algorithm here.</p><p>The continuous greedy algorithm for SAP/GAP. 1. Let δ = 1 9n 2 . Start with t = 0 and y j,S (0) = 0 for all j, S. 2. Let R(t) be a random collection of pairs (j, S), each pair (j, S) appearing independently with probability y j,S (t). For all i, j, estimate the expected marginal profit of bin j from item i,</p><formula xml:id="formula_64">ω ij (t) = E R(t) [max{0, v ij -max{v ij : ∃(j , S) ∈ R(t); i ∈ S}}],</formula><p>by taking the average of (mn) 5 independent samples. 3. For each j, find an α-approximate solution S * j (t) to max{ i∈S ω ij (t) : S ∈ F j }. Set y j,S (t+ δ) = y j,S (t)+δ for the set S = S * j (t) and y j,S (t+ δ) = y j,S (t) otherwise. 4. Increment t := t + δ; if t &lt; 1, go back to Step 2. 5. For each bin j independently, choose a random set S j := S with probability y j,S <ref type="bibr" target="#b0">(1)</ref>. For each item occurring in multiple sets S j , keep only the occurrence of maximum value. Allocate the items to bins accordingly. Theorem 4.1. If we have an α-approximation algorithm for max{ i∈S ω ij : S ∈ F j }, for any bin j and any assignment of values ω ij , then the continuous greedy algorithm delivers a (1e -αo(1))-approximation algorithm for the corresponding SAP with families of feasible sets F j .</p><p>This beats both the factor α(1 -1/e) obtained by using the "configuration" linear program <ref type="bibr" target="#b19">[19]</ref> and the factor α/(1 + α) obtained by a simple greedy algorithm <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b21">21]</ref>.</p><p>GAP. Special cases of SAP are obtained by considering different types of collections of feasible sets F j . When each F j is given by a knapsack problem, F j = {S : i∈S s ij ≤ 1}, we obtain GAP. Since there is an FPTAS for the knapsack problem, we have α = 1o(1) and we obtain a (1 -1/eo(1))-approximation for GAP. <ref type="foot" target="#foot_2">3</ref>Matroid constraint on the bins. Consider GAP with the additional restriction that items be assigned to at most k of the given m bins. We can capture this additional constraint by altering the matroid M as follows: Previously, a set S was defined to be independent iff |S ∩ {(j, S) | S ∈ F j }| ≤ 1 for each bin j. Now a set S is independent iff |S ∩ {(j, S) | S ∈ F j }| ≤ 1 for each bin j and |S| ≤ k. It is easy to check that this is also a matroid constraint. More generally let B = {1, . . . , m} be the set of bins and M = (B, I) be a given matroid on B. A generalization of GAP is obtained by asking for a maximum profit feasible assignment of items to a subset of bins B ⊆ B, where B is required to be an independent set in I. This constraint can also be incorporated into the reduction by letting M be the matroid where S is independent iff (i) |S ∩ {(j, S) | S ∈ F j }| ≤ 1 for each bin j, and (ii) B S ∈ I, where B S = {j | ∃(j, S) ∈ S}. Once again it is easy to check that M is a matroid. The algorithm can be implemented in a way similar to the algorithm for SAP. Pipage rounding can also be implemented by first dealing with each bin separately as in subsection 3.3 before considering the matroid M as in subsection 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions.</head><p>The notion of a multilinear extension, F (y) = E[f (ŷ)], is crucial in this paper. Since it can be evaluated only probabilistically, our algorithm is intrinsically randomized. It is an interesting open problem whether a (1 -1/e)approximation can be obtained using a deterministic algorithm in the value oracle model. In some special cases, such as coverage in set systems, F (y) can be evaluated deterministically-in fact, Ageev and Sviridenko <ref type="bibr" target="#b0">[1]</ref> use explicit functions for several problems. The pipage rounding that we described is randomized, but one can use a deterministic variant <ref type="bibr" target="#b2">[3]</ref>. Therefore, in some special cases, a deterministic (1 -1/e)-approximation can be achieved.</p><p>One can also consider the multilinear extension for nonmonotone submodular functions. (We still assume that f (S) is nonnegative.) For such functions, even the unconstrained problem max S⊆X f (S) is APX-hard; the max-cut problem is a special case. Feige, Mirrokni, and Vondrák <ref type="bibr" target="#b15">[15]</ref> give constant factor approximations for the unconstrained problem. Under a matroid constraint, we can still use the pipage rounding framework, which is applicable even to nonmonotone functions (as already shown in special cases by <ref type="bibr" target="#b0">[1]</ref>). However, the continuous greedy algorithm for maximizing F (x) requires monotonicity. Hence, other techniques are required to deal with the continuous optimization problem. For specific cases, one may be able to combine pipage rounding with a linear programming relaxation. For example, in <ref type="bibr" target="#b0">[1]</ref>, max-cut with fixed sizes of parts and related problems is addressed in this fashion. In recent work, the multilinear extension and pipage rounding have been used directly to derive approximation algorithms for nonmonotone submodular maximization under matroid independence/base constraints <ref type="bibr" target="#b44">[43]</ref>, improving previous results using local search <ref type="bibr" target="#b30">[30]</ref>. The multilinear extension has also been used to design approximations for maximizing monotone and nonmonotone submodular functions subject to knapsack constraints <ref type="bibr" target="#b29">[29,</ref><ref type="bibr" target="#b30">30]</ref>. The hardness results of <ref type="bibr" target="#b44">[43]</ref> reveal a more general connection between the approximability of submodular maximization problems and properties of their multilinear relaxations.</p><p>At present, it is not clear how to use our framework for p &gt; 1 matroid constraints. The special case of p = 2 is of much interest since the matroid intersection polytope is integral. Although the continuous greedy algorithm is still applicable, pipage rounding does not generalize. In recent work, <ref type="bibr" target="#b31">[31]</ref> obtains a (1/p -)-approximation for monotone submodular maximization subject to p ≥ 2 matroids via local search; the running time of the algorithm is exponential in p and 1/ .</p><p>The original forms of pipage rounding <ref type="bibr" target="#b0">[1]</ref> and dependent randomized rounding <ref type="bibr" target="#b40">[40,</ref><ref type="bibr" target="#b20">20]</ref> address the question of rounding a fractional solution to the assignment problem while maintaining the quality of the solution in terms of a certain objective function. A number of applications are given in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b20">20]</ref>. This paper shows that submodularity and uncrossing properties of solutions in the matroid polytope and other related structures are the basic ingredients in the applicability of the pipage rounding technique. We hope this insight will lead to more applications in the future.</p><p>Appendix A. Clean (1 -1/e)-approximation using smaller steps. Here we present a tighter analysis of the continuous greedy algorithm from section 3.1, showing that a choice of δ = 1/(40d 2 n) is sufficient to achieve a clean approximation factor of 1 -1/e.</p><p>Recall the proof of Lemma 3.3. In each step, we compared the random set R(t) to R(t + δ). Instead of R(t + δ), we actually analyzed R(t) ∪ D(t), which is a strictly Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php smaller set. However, rather than R(t)∪D(t), we can consider R(t)∪ D(t), where D(t) is independent of R(t) and contains each element j with probability Δ j (t)(1 + y j (t)). It can be verified that, for any j, P r[j ∈ R(t) ∪ D(t)] ≤ P r[j ∈ R(t + δ)]. (We would get equality if we sampled D(t) with probabilities Δ j (t)/(1y j (t)), but we use a smaller value Δ j (t)(1 + y j (t)) so that the probabilities do not exceed 2δ.) D(t) is a random subset of I(t), and the size of I(t) is d. We can repeat the analysis with D(t) and get</p><formula xml:id="formula_65">F (y(t + δ)) -F (y(t)) ≥ j Pr[ D(t) = {j}]E[f R(t) (j)] ≥ δ(1 -2dδ) j∈I(t) E[f R(t) (j)](1 + y j (t)).</formula><p>Observe that we get a small gain over the previous analysis as the fractional variables y j (t) increase.</p><p>As before, with high probability all marginal values E[f R(t) (j)] are estimated within an additive error of δ OP T , so our computation of the maximum-weight base I(t) is accurate within 2dδ OP T . We assume in the following that this is the case. Denote ω * (t) = max j∈I(t) E[f R(t) (j)]. By Lemma 3.2 and submodularity, we know that, at any time, ω * (t) ≥ 1 d ((1 -2dδ)OP T -F (y(t))). Let j * (t) be the element achieving ω * (t). Let us call the steps where y j * (t) (t) &lt; 1 2n "bad" and the steps where y j * (t) (t) ≥ 1 2n "good." We argue that at least half of all steps must be good. If more than half of all steps were bad, the sum of all increments to j * (t) in bad steps would be more than 1/2, but then some variable would receive more than 1 2n as j * (t) in bad steps, which is a contradiction. In good steps, the improved analysis gives</p><formula xml:id="formula_66">F (y(t + δ)) -F (y(t)) ≥ δ(1 -2dδ) ⎛ ⎝ j∈I(t) E[f R(t) (j)] + y j * (t) (t)ω * (t) ⎞ ⎠ ≥ δ(1 -2dδ) 1 + 1 2dn ((1 -2dδ)OP T -F (y(t))) ≥ δ(1 -8dδ) 1 + 1 2dn (OP T -F (y(t))),</formula><p>assuming that F (y(t)) ≤ 2 3 OP T (otherwise we are done already). By taking δ = 1 40d 2 n , i.e., 1 2dn = 20dδ, we make this expression bigger than δ(1 + 10dδ)(OP T -F (y(t))). Then, we can conclude that in good steps we have</p><formula xml:id="formula_67">OP T -F (y(t + δ)) ≤ (1 -δ(1 + 10dδ))(OP T -F (y(t))).</formula><p>In bad steps, we ignore the term y j * (t) (t)ω * (t) and obtain</p><formula xml:id="formula_68">OP T -F (y(t + δ)) ≤ (1 -δ(1 -8dδ))(OP T -F (y(t))).</formula><p>Finally, using the fact that at least half of the steps are good, we get</p><formula xml:id="formula_69">OP T -F (y(1)) ≤ (1 -δ + 8dδ 2 ) 1 2δ (1 -δ -10dδ 2 ) 1 2δ OP T ≤ (1 -δ) 1/δ OP T, which means F (y(1)) ≥ (1 -(1 -δ) 1/δ )OP T ≥ (1 -1/e)OP T .</formula><p>Appendix B. Analysis of the greedy algorithm for p-systems. We give an analysis of the greedy algorithm for maximizing a submodular function subject to Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php G. CALINESCU, C. CHEKURI, M. P ÁL, AND J. VONDR ÁK a p-system, that is, max S∈I f (S), where (X, I) is a p-system and f : 2 X → R + is a monotone submodular set function. Fisher, Nemhauser, and Wolsey <ref type="bibr" target="#b17">[17]</ref> showed that the natural greedy algorithm has a tight approximation ratio of 1/(p + 1). In <ref type="bibr" target="#b17">[17]</ref>, a proof is given for a special case when the I is induced by the intersection of p matroids on X; it is mentioned that the proof extends to an arbitrary p-system using the same outline as that of Jenkyns <ref type="bibr" target="#b25">[25]</ref>, who showed a bound of 1/p if f is modular. As far as we are aware, a formal proof has not appeared in the literature, and hence we give a proof here for the sake of completeness. The proof also adapts to give a bound of α/(p + α) if only an α-approximate oracle for f is available (here α ≤ 1). We mention that Goundan and Schulz <ref type="bibr" target="#b21">[21]</ref> have, in an independent work, adapted the proof from <ref type="bibr" target="#b17">[17]</ref> for intersection of p matroids to the approximate setting. However, the proofs in <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b21">21]</ref> use a linear programming relaxation and differ from that of Jenkyns <ref type="bibr" target="#b25">[25]</ref>, whose scheme we follow.</p><p>We recap the definition of a p-system in more detail below. For a set Y ⊆ X, a set J is called a base of Y if J is a maximal independent subset of Y ; in other words, J ∈ I and for each e ∈ Y \ J, J + e ∈ I. Note that Y may have multiple bases, and, further, a base of Y may not be a base of a superset of Y . (X, I) is said to be a p-system if for each Y ⊆ X the cardinality of the largest base of Y is at most p times the cardinality of the smallest base of Y . In other words, for each Y ⊆ X,</p><formula xml:id="formula_70">max J:J is a base of Y |J| min J:J is a base of Y |J| ≤ p.</formula><p>Special cases of p-systems. We mention three examples of independence families that are special cases of p-systems in increasing order of generality.</p><p>• Intersection of p matroids.</p><p>• p-circuit-bounded families considered in <ref type="bibr" target="#b25">[25]</ref>. <ref type="foot" target="#foot_3">4</ref> A family I is a p-circuitbounded family if, for each A ∈ I and e ∈ X \ A, A + e has at most p circuits. Here, a circuit is a minimally dependent set. • p-extendible families defined in <ref type="bibr" target="#b33">[33]</ref>. A family I is p-extendible if the following holds: suppose A ⊂ B, A, B ∈ I, and A + e ∈ I; then there is a set Z ⊆ B \ A such that |Z| ≤ p and B \ Z + e ∈ I. It can be shown that I being the intersection of p matroids implies that it is p-circuitbounded, which in turn implies that it is p-extendible, which in turn implies that it is a p-system. Examples show that these inclusions are proper <ref type="bibr" target="#b34">[34]</ref>. An example of a natural 3-system which is not 3-extendible is the following: Given a simple graph G = (V, E), define an independence system (E, I), where a subset of edges A ⊆ E is independent (that is, A ∈ I) iff (V, A) is planar (the number 3 comes from Euler's formula; see <ref type="bibr" target="#b3">[4]</ref> for details). A simple and illustrative example of a 2-extendible system is the following: Take the ground set to be the edges of an undirected graph and the independent sets to be the set of matchings in the graph.</p><p>Analysis of the greedy algorithm. The greedy algorithm includes an element of maximum possible marginal value among those elements that keep the set independent, as long as possible. It is easy to see that the greedy algorithm can be implemented using a value oracle for f and a membership oracle for I. We let e 1 , e 2 , . . . , e k be the elements added to S by the greedy algorithm, and for i ≥ 0, we let S i denote the set {e 1 , e 2 , . . . , e i }.</p><p>In some settings, |X| is exponential and the greedy step in picking the element with the largest marginal value can be implemented only in an approximate way. Suppose we are guaranteed only that in each greedy step i the element e i picked in that step satisfies f Si-1 (e i ) ≥ α max e∈Ai f Si-1 (e) where A i is the set of all candidate augmentations of S i-1 . Here α ≤ 1. We prove directly that the approximation ratio of the greedy algorithm is α/(p + α).</p><p>Let δ i = f Si-1 (e i ) = f (S i )f (S i-1 ) be the improvement in the solution value when e i is added. Note that f (S k ) = i δ i . Fix some optimum solution O. We show the existence of a partition O 1 , O 2 , . . . , O k of O such that δ i ≥ α p f S k (O i ) for all i ∈ {1, 2, . . . , k}. We allow for some i that O i = ∅.</p><p>Assuming that we have such a partition of O, Thus we also have that |T 1 | = |O 1 | ≤ p. Now, by construction, every e ∈ O i for every i ∈ {1, 2, . . . , k} satisfies that S i-1 + e is independent. From the choice made by the greedy algorithm it follows that δ i ≥ αf Si-1 (e) for each e ∈ O i and hence</p><formula xml:id="formula_71">f (S k ) = k i=1 δ i ≥ α p k i=1 f S k (O i ) ≥ α p f S k (O) ≥ α p (f (O) -f (S k )),</formula><formula xml:id="formula_72">|O i |δ i ≥ α e∈Oi f Si-1 (e) ≥ αf Si-1 (O i ) ≥ αf S k (O i ).</formula><p>We use submodularity of f in both the middle inequality and the last inequality. For all i ∈ {1, 2, . . . , k}, we have |O i | ≤ p, and thus δ i ≥ α p f S k (O i ). This finishes the proof. Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php G. CALINESCU, C. CHEKURI, M. P ÁL, AND J. VONDR ÁK Remark. The proof is simpler and more intuitive for the special case of pextendible systems. We define a sequence of sets O = T 0 ⊇ T 1 ⊇ • • • ⊇ T k = ∅ such that, for 1 ≤ i ≤ k, (i) S i ∪ T i ∈ I and (ii) S i ∩ T i = ∅. In other words, every element in T i is a candidate for the greedy algorithm in step i + 1. We partition the optimum solution as</p><formula xml:id="formula_73">O = O 1 ∪ O 2 ∪ • • • ∪ O k , where O i = T i-1 \ T i .</formula><p>This partition is defined so that we can charge the value of the optimum to marginal improvements made by the greedy algorithm.</p><p>We start with T 0 = O and show how to construct T i from T i-1 . If e i ∈ T i-1 , we define O i = {e i } and T i = T i-1e i . Otherwise, we let O i be a smallest subset of T i-1 such that (S i-1 ∪ T i-1 ) \ O i + e i is independent; since I is a p-extendible family, |O i | ≤ p. We let T i = T i-1 \ O i . It is easy to check that in both cases S i ∪ T i ∈ I and S i ∩ T i = ∅. Finally, T k = ∅ since S k ∪ T k is independent, and the algorithm stops only when {e | S k + e ∈ I} = ∅. Since any of the elements in O i (in fact, T i-1 ) was a candidate for e i in the greedy algorithm, δ i ≥ αf Si-1 (e) for each e ∈ O i . Moreover, |O i | ≤ p, which implies δ i ≥ α p f Si-1 (O i ). Note that the proof for p-systems is more subtle since we cannot use a local argument to show that |O i | ≤ p for each i; we need a more global argument.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>3 . 4 .</head><label>34</label><figDesc>The following well-known proposition follows from the submodularity of the rank function r M . Proposition If y ∈ P (M) and A, B are two tight sets with respect to y, then A ∩ B and A ∪ B are also tight with respect to y. Proof. Using y(A) = r M (A), y(B) = r M (B), y(A ∩ B) ≤ r M (A ∩ B), y(A ∪ B) ≤ r M (A ∪ B), the submodularity of r M , and the linearity of y, we get</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Lemma 3 . 5 .</head><label>35</label><figDesc>Given y * ∈ B(M), PipageRound(M, y * ) outputs in polynomial time an integral solution S ∈ I of value E[f (S)] ≥ F (y * ). Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php G. CALINESCU, C. CHEKURI, M. P ÁL, AND J. VONDR ÁK</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Algorithm Greedy:S ← ∅, A ← ∅; Repeat A ← {e | S ∪ {e} ∈ I}; If (A = ∅),then e ← argmax e ∈A f S (e ); S ← S ∪ {e}; Endif Until (A = ∅); Output S;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>which implies that f (S k ) ≥ α p+α f (O). The penultimate inequality relies on submodularity of f . We now prove the existence of the desired partition of O. For this we use the following algorithm. Define T k = O. For i = k, k -1, . . . , 2, execute:Let B i = {e ∈ T i | S i-1 + e ∈ I}. If |B i | ≤ p, set O i = B i ; else pick an arbitrary O i ⊂ B i with |O i | = p. Then set T i-1 = T i \ O i before decreasing i. After the for-loop, set O 1 = T 1 . It is immediate that for j = 2, . . . , k, |O j | ≤ p.We prove by induction on i = 0, 1, . . . , k -1 that |T k-i | ≤ (ki)p. For i = 0, we reason as follows: When the greedy algorithm stops, S k is a maximal independent set contained in X, and thus any independent set includingT k = O satisfies |T k | ≤ p|S k | = pk.For the inductive step, let i &gt; 0. We have two cases:If |B k-i+1 | &gt; p, then |O k-i+1 | = p and |T k-i | = |T k-i+1 | -|O k-i+1 | ≤ (ki + 1)pp = (ki)p, using the induction hypothesis. If |B k-i+1 | ≤ p, we have T k-i = T k-i+1 \ B k-i+1 . Consider Y = S k-i ∪ T k-i . By the way B k-i+1 is defined, S k-i is a maximal independent set in Y . With T k-i independent and contained in Y , we must have that |T k-i | ≤ p|S k-i | = p(ki).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>2k .Downloaded  12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Matroids. A matroid is a pair M = (X, I), where I ⊆ 2 X and 1. for all B ∈ I, A ⊂ B ⇒ A ∈ I, 2. for all A, B ∈ I; |A| &lt; |B| implies that there exists x ∈ B \ A; A + x ∈ I. A matroid is a combinatorial abstraction of the notion of linear independence among vectors. By r M , we denote the rank function of M:</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</figDesc><table><row><cell>Algorithm ContinuousGreedy(f, M):</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>d 2 2n 4 . Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Therefore, with probability at least (1 -1 2n 2 ), all estimates are good; i.e., we have |ω j</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Note that the probability of success is the same as that in Lemma 3.2. Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php G. CALINESCU, C. CHEKURI, M. P ÁL, AND J. VONDR ÁK</figDesc><table /><note><p>1/(3d))OP T .</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Positive results have been achieved only under strong assumptions on the utility functions. A particular case of interest is when the utility functions are submodularthis is what we call the submodular welfare problem.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We give a proof of this result in Appendix B for the sake of completeness. If only an αapproximate oracle (α ≤ 1) is available for the function evaluation, the ratio obtained is α/(p + α). Several old and recent applications of the greedy algorithm can be explained using this observation. Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Sometimes GAP is defined with bins having specified capacities. Since the item sizes are allowed to vary with the bin, one can scale them to reduce to an instance in which each bin capacity is 1. Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>It may be possible to eliminate the o(1) term and obtain a clean (1 -1/e)-approximation by partial enumeration; however, we believe that the algorithm is simpler and more "practical" as it stands.Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>In<ref type="bibr" target="#b25">[25]</ref> no name is suggested for these families. Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. The last author would like to thank Uriel Feige, Mohammad Mahdian, and Vahab Mirrokni for inspiring discussions concerning the submodular welfare problem. We thank Julian Mestre for discussions that clarified the different notions of p-independence families. We thank the anonymous reviewers for their careful reading and suggestions.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This author's research was partially supported by NSF grant CCF-0515088. This author's work was partly done while the author was at Lucent Bell Labs and was partially supported by NSF grant CCF-0728782.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Proof. Let T be sampled as above, and let ŷ = 1 R . The difference between R and T is that in R each element appears independently with probability y j (and therefore R is not necessarily an independent set in M). In T , we sample exactly one element from each X i , with the same probabilities. We claim that</p><p>We proceed by induction on k. First, assume that k = 1 and X = X 1 . Then,</p><p>using the base case for f T on X k . Then,</p><p>Therefore, we can replace pipage rounding for simple partition matroids by the following simple procedure. (This procedure can also be seen as performing all the steps of pipage rounding at once.)</p><p>Simple rounding.</p><p>• Given y ∈ R X + such that for all i, j∈Xi y j = 1, sample independently from each X i exactly one element: element j ∈ X i with probability y j . Return the set T of the sampled elements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Applications.</head><p>4.1. Submodular welfare maximization. Here we describe an application of our framework to the submodular welfare problem. First, we review the general framework and known results.</p><p>Social welfare maximization. Given a set X of m items, and n players, each having a monotone utility function w i : 2 X → R + , the goal is to partition X into disjoint subsets S 1 , . . . , S n in order to maximize the social welfare n i=1 w i (S i ). This problem arises in combinatorial auctions and has been studied intensively in recent years <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b35">35]</ref>. Before studying its complexity status, one needs to specify how the algorithm accesses the input to the problem. Usually, an algorithm is allowed to ask certain queries about the players' utility functions. This leads to different oracle models of computation. The two types of oracles most commonly considered are the following:</p><p>• Value oracle: This returns the value of w i (S) for a given player i and S ⊆ X.</p><p>• Demand oracle: This returns a set S maximizing w i (S) -j∈S p j for a given player i and an assignment of prices p j . Previous work. In general, social welfare maximization contains set packing as a special case (the case of single-minded bidders), and hence an m 1/2--approximation for any fixed &gt; 0, even in the demand oracle model, would imply P = N P <ref type="bibr" target="#b32">[32]</ref>. Downloaded 12/21/12 to 129.173.72.87. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pipage rounding: A new method of constructing algorithms with proven performance guarantee</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ageev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sviridenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Combin. Optim</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="307" to="328" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Probabilistic Method</title>
		<author>
			<persName><forename type="first">N</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Spencer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Wiley Interscience</publisher>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Maximizing a submodular set function subject to a matroid constraint</title>
		<author>
			<persName><forename type="first">G</forename><surname>Calinescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chekuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pál</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vondrák</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th IPCO Conference</title>
		<meeting>the 12th IPCO Conference</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="182" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A new approximation algorithm for finding heavy planar subgraphs</title>
		<author>
			<persName><forename type="first">G</forename><surname>Calinescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Karloff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zelikovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="179" to="205" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the approximability of budgeted allocations and improved lower bounds for submodular welfare maximization and GAP</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chakrabarty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Goel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual IEEE Symposium on Foundations of Computer Science</title>
		<meeting>the 49th Annual IEEE Symposium on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="687" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A polynomial time approximation scheme for the multiple knapsack problem</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chekuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Khanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="713" to="728" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Maximum coverage problem with group budget constraints and applications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chekuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Approximation, Randomization, and Combinatorial Optimization</title>
		<title level="s">Lecture Notes in Comput. Sci.</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3122</biblScope>
			<biblScope unit="page" from="72" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A recursive greedy algorithm for walks in directed graphs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chekuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pál</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual Symposium on Foundations of Computer Science</title>
		<meeting>the 46th Annual Symposium on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="245" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Location of bank accounts to optimize float: An analytic study of exact and approximate algorithms</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cornuejols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nemhauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="789" to="810" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Testing membership in matroid polyhedra</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Cunningham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Combin. Theory Ser. B</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="161" to="188" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An improved approximation algorithm for combinatorial auctions with submodular bidders</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dobzinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schapira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Annual ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>the Seventeenth Annual ACM-SIAM Symposium on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1064" to="1073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Submodular functions, matroids, and certain polyhedra</title>
		<author>
			<persName><forename type="first">J</forename><surname>Edmonds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Combinatorial Structures and Their Applications</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Gordon and Breach</publisher>
			<date type="published" when="1970">1970</date>
			<biblScope unit="page" from="69" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A threshold of ln n for approximating set cover</title>
		<author>
			<persName><forename type="first">U</forename><surname>Feige</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="634" to="652" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Redistribution subject to SIAM license or copyright</title>
		<idno>Downloaded 12/21/12 to 129.173.72.87</idno>
		<ptr target="http://www.siam.org/journals/ojsa.php" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On maximizing welfare when utility functions are subadditive</title>
		<author>
			<persName><forename type="first">U</forename><surname>Feige</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th ACM Symposium on Theory of Computing</title>
		<meeting>the 38th ACM Symposium on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="41" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Maximizing a non-monotone submodular function</title>
		<author>
			<persName><forename type="first">U</forename><surname>Feige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mirrokni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vondrák</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual IEEE Symposium on Foundations of Computer Science</title>
		<meeting>the 48th Annual IEEE Symposium on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="461" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Approximation algorithms for allocation problems: Improving the factor of 1 -1/e</title>
		<author>
			<persName><forename type="first">U</forename><surname>Feige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vondrák</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual IEEE Symposium on Foundations of Computer Science</title>
		<meeting>the 47th Annual IEEE Symposium on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="667" to="676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An analysis of approximations for maximizing submodular set functions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Nemhauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Wolsey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">II., Math. Programming Stud</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="73" to="87" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A combinatorial, strongly polynomial-time algorithm for minimizing submodular functions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fleischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fujishige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Iwata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="761" to="777" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Tight approximation algorithms for maximum general assignment problems</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fleischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">X</forename><surname>Goemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Mirrokni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sviridenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Annual ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>the Seventeenth Annual ACM-SIAM Symposium on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="611" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dependent rounding and its applications to approximation algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Khuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="324" to="360" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Revisiting the Greedy Approach to Submodular Set Function Maximization, manuscript</title>
		<author>
			<persName><forename type="first">P</forename><surname>Goundan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schulz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bounds for certain multiprocessor anomalies</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell System Tech. J</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="1563" to="1581" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Geometric Algorithms and Combinatorial Optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Grötschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lovász</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schrijver</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On the complexity of approximating k-set packing</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Safra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Approximation, Randomization, and Combinatorial Optimization</title>
		<title level="s">Lecture Notes in Comput. Sci.</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2764</biblScope>
			<biblScope unit="page" from="83" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The efficacy of the &quot;greedy&quot; algorithm</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Jenkyns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Southeastern Conference on Combinatorics, Graph Theory and Computing</title>
		<meeting>the 7th Southeastern Conference on Combinatorics, Graph Theory and Computing</meeting>
		<imprint>
			<date type="published" when="1976">1976</date>
			<biblScope unit="page" from="341" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Inapproximability results for combinatorial auctions with submodular utility functions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Markakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mehta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="3" to="18" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The budgeted maximum coverage problem</title>
		<author>
			<persName><forename type="first">S</forename><surname>Khuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Process. Lett</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="39" to="45" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An analysis of the greedy heuristic for independence systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Korte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hausmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Discrete Math</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="65" to="74" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Maximizing submodular functions subject to multiple linear constraints</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kulik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shachnai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="545" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Non-monotone submodular maximization under matroid and knapsack constraints</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mirrokni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nagarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sviridenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st ACM Symposium on Theory of Computing</title>
		<meeting>the 41st ACM Symposium on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="323" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Submodular maximization over multiple matroids via generalized exchange properties, in Approximation, Randomization, and Combinatorial Optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sviridenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vondrák</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Comput. Sci.</title>
		<imprint>
			<biblScope unit="volume">5687</biblScope>
			<biblScope unit="page" from="244" to="257" />
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Combinatorial auctions with decreasing marginal utilities</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nisan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Games Econom. Behav</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="270" to="296" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Greedy in approximation algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mestre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th European Symposium on Algorithms</title>
		<meeting>the 14th European Symposium on Algorithms<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="528" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Mestre</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>private communication</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Tight information-theoretic lower bounds for welfare maximization in combinatorial auctions</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mirrokni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schapira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vondrák</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Electronic Commerce</title>
		<meeting>the ACM Conference on Electronic Commerce</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="70" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Best algorithms for approximating the maximum of a submodular set function</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Nemhauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Wolsey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="177" to="188" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An analysis of approximations for maximizing submodular set functions</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Nemhauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Wolsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">I., Math. Programming</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="265" to="294" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A combinatorial algorithm minimizing submodular functions in strongly polynomial time</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schrijver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Combin. Theory Ser. B</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="346" to="355" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Combinatorial Optimization-Polyhedra and Efficiency</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schrijver</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Distributions on level-sets with applications to approximation algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual IEEE Symposium on Foundations of Computer Science</title>
		<meeting>the 42nd Annual IEEE Symposium on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="588" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Redistribution subject to SIAM license or copyright</title>
		<idno>Downloaded 12/21/12 to 129.173.72.87</idno>
		<ptr target="http://www.siam.org/journals/ojsa.phpCopyright©bySIAM" />
		<imprint/>
	</monogr>
	<note>Unauthorized reproduction of this article is prohibited</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A note on maximizing a submodular set function subject to knapsack constraint</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sviridenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res. Lett</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="41" to="43" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Optimal approximation for the submodular welfare problem in the value oracle model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vondrák</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th ACM Symposium on Theory of Computing</title>
		<meeting>the 40th ACM Symposium on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="67" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Symmetry and approximability of submodular maximization problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vondrák</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual IEEE Symposium on Foundations of Computer Science</title>
		<meeting>the 50th Annual IEEE Symposium on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="651" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An analysis of the greedy algorithm for the submodular set covering problem</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wolsey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorica</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="385" to="393" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Maximizing real-valued submodular functions: Primal and dual heuristics for location problems</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wolsey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="410" to="425" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
