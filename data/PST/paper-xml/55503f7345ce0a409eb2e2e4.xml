<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self Regulating Particle Swarm Optimization Algorithm</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-09-01">September 1, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Tanweer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<addrLine>50 Nanyang Avenue</addrLine>
									<postCode>639798, 6790 6185</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">S</forename><surname>Suresh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<addrLine>50 Nanyang Avenue</addrLine>
									<postCode>639798, 6790 6185</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">N</forename><surname>Sundararajan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Electrical and Electronics Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<addrLine>50 Nanyang Avenue</addrLine>
									<postCode>639798</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Self Regulating Particle Swarm Optimization Algorithm</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-09-01">September 1, 2014</date>
						</imprint>
					</monogr>
					<idno type="MD5">C69A20EF91C61D0E93C8E29416784C75</idno>
					<idno type="DOI">10.1016/j.ins.2014.09.053</idno>
					<note type="submission">Preprint submitted to Information Sciences</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Particle Swarm Optimization</term>
					<term>Self Regulating Particle Swarm Optimization</term>
					<term>Self Regulating Inertia Weight</term>
					<term>Self-Perception on Search Direction</term>
					<term>Radar System Design</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose a new particle swarm optimization algorithm incorporating the best human learning strategies for finding the optimum solution, referred to as a Self Regulating Particle Swarm Optimization (SRPSO) algorithm.</p><p>Studies in human cognitive psychology have indicated that the best planners regulate their strategies with respect to the current state and their perception of the best experiences from others. Using these ideas, we propose two learning strategies for the PSO algorithm. The first one uses a self-regulating inertia weight and the second uses the self-perception on the global search direction. The self-</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>regulating inertia weight is employed by the best particle for better exploration and the self-perception of the global search direction is employed by the rest of the particles for intelligent exploitation of the solution space. SRPSO algorithm has been evaluated using the 25 benchmark functions from CEC2005 and a realworld problem for a radar system design. The results have been compared with six state-of-the-art PSO variants like Bare Bones PSO (BBPSO), Comprehensive Learning PSO (CLPSO), etc. The two proposed learning strategies help SRPSO to achieve faster convergence and provide better solutions in most of the problems. Further, a statistical analysis on performance evaluation of the different algorithms on CEC2005 problems indicates that SRPSO is better than other algorithms with a 95% confidence level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent years, many real-world optimization problems such as nonlinear process control <ref type="bibr" target="#b62">[63]</ref>, structural design <ref type="bibr" target="#b68">[69]</ref>, grouping problems <ref type="bibr" target="#b25">[26]</ref>, text mining <ref type="bibr" target="#b7">[8]</ref>, etc. have become extremely complex and are difficult to solve using conventional optimization algorithms. For these problems, population based nature inspired search optimization is providing better and efficient solutions.</p><p>Among the nature inspired optimization algorithms, Particle Swarm Optimization (PSO) is a computationally effective and simple algorithm. It was introduced in 1995 by Kennedy and Ebenhart <ref type="bibr" target="#b30">[31]</ref>. Currently, PSO has become one of the most preferred choices for optimization problems due to its lesser memory requirements and ease of implementation <ref type="bibr" target="#b17">[18]</ref> along with better performance for providing solutions closer to optimum on different benchmark and engineering problems. PSO is based on the collaborative swarm behavior of birds flocking and fish schooling <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b12">13]</ref>. Each member in a swarm updates its search patterns using its own experience, i.e. exploration and other members' experience, i.e. exploitation and share information with each other throughout the searching process to ensure that all of them move towards the optimum solution <ref type="bibr" target="#b16">[17]</ref>.</p><p>Similar to other population based algorithms, PSO also experiences premature convergence due to particles getting trapped in local minima <ref type="bibr" target="#b5">[6]</ref>. Recently, researchers focussed on developing new PSO algorithms that avoid this premature convergence problem <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b76">77,</ref><ref type="bibr" target="#b8">9]</ref>. A complete review of PSO practical application is given in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b56">57]</ref>.</p><p>From the time of initial introduction of the PSO algorithm, several variants have been proposed by researchers for providing better performance. These variants can be broadly classified under four categories, namely; a) algorithms based on parameter settings; b) algorithms based on neighborhood topology; c) algorithms based on learning strategies; and d) hybridized versions. A brief overview of the above categories of the PSO algorithms and also the selected algorithms from each category for later comparisons are highlighted below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithms based on parameter settings:</head><p>The proper selection of control parameters such as inertia weight, acceleration coefficients significantly influence the convergence. There are many variants of PSO algorithms with inertia weights that are fixed <ref type="bibr" target="#b59">[60]</ref>, linearly decreasing <ref type="bibr" target="#b60">[61]</ref>, linearly increasing <ref type="bibr" target="#b80">[81]</ref>, simulated annealing <ref type="bibr" target="#b23">[24]</ref>, Gaussian <ref type="bibr" target="#b49">[50]</ref>, random <ref type="bibr" target="#b40">[41]</ref>, non-linear <ref type="bibr" target="#b34">[35]</ref>, exponential <ref type="bibr" target="#b27">[28]</ref> and fuzzy adaptive settings <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b41">42]</ref>. A recent study <ref type="bibr" target="#b22">[23]</ref> has shown that the linearly decreasing inertia weight is the most appropriate setting because it is the simplest and most efficient way. Further, researchers have studied the effect of the acceleration coefficient in self and social cognition on the convergence of the PSO algorithms <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b82">83]</ref>. Recently, an adaptive parameter selection scheme for both the inertia weight and acceleration coefficients have been proposed in <ref type="bibr" target="#b78">[79,</ref><ref type="bibr" target="#b1">2]</ref>. Nonuniform tuning of parameters has been proposed in <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b14">15]</ref>. A constriction factor was also introduced in PSO <ref type="bibr" target="#b11">[12]</ref> to control the magnitude of all the velocities and it has been found to be very effective on certain problems.</p><p>Algorithms based on neighborhood topology: Initially, different topologies like fully connected, wheel and Von Neumann <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b31">32]</ref> were studied and later other topologies were introduced <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b72">73]</ref> aiming towards enhancing the exploration capabilities of the PSO algorithm. In <ref type="bibr" target="#b44">[45]</ref>, a novel information flow process was introduced for updating the position of each particle and the strategy was named as a Fully Informed Particle Swarm (FIPS) algorithm. FIPS used a weighted sum of all the neighboring particles for updating the position of a given particle. The main advantage of the strategy is that a particle's new position is evaluated using the information of all its topological neighbors. Instead of using a fixed neighborhood topology, a dynamically changing neighborhood topology for position update of each particle was proposed in <ref type="bibr" target="#b36">[37]</ref>, and is named as the Dynamic Multi-Swarm Particle Swarm Optimizer (DMSPSO). The strategy involves a random selection of small swarms with small neighborhoods in the early stages to provide better exploration and then dynamically increase the neighborhood by regrouping the swarms to incorporate social interaction and perform better exploitation in the later stages of the search process. Many variants of neighborhood topologies are available in the literature <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b83">84]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithms based on learning strategies:</head><p>Recently, many PSO variants with different learning strategies have been introduced for providing better convergence towards the global optimum. This list comprises of teaching and peer learning PSO <ref type="bibr" target="#b39">[40]</ref>, bidirectional teaching and peer-learning PSO <ref type="bibr" target="#b38">[39]</ref>, adaptive two-layer PSO with elitist learning strategy <ref type="bibr" target="#b37">[38]</ref>, orthogonal learning strategy for PSO <ref type="bibr" target="#b81">[82]</ref>, adaptive learning PSO <ref type="bibr" target="#b33">[34]</ref>, ageing mechanism transformed PSO <ref type="bibr" target="#b9">[10]</ref>, distance based locally informed PSO <ref type="bibr" target="#b57">[58]</ref>, cellular PSO <ref type="bibr" target="#b61">[62]</ref>, multi-layer particle swarm optimization <ref type="bibr" target="#b73">[74]</ref> and a new fitness estimation strategy for PSO <ref type="bibr" target="#b64">[65]</ref>.</p><p>A novel algorithm using the personal best, global best and another particle's personal best with a maximum fitness-to-distance ratio for updating a particle's velocity was introduced in <ref type="bibr" target="#b54">[55]</ref>. A compact particle swarm optimization <ref type="bibr" target="#b47">[48]</ref> has also been introduced for efficient hardware utilization. An emerging advancement in the form of multi-swarm is used in <ref type="bibr" target="#b10">[11]</ref> and <ref type="bibr" target="#b74">[75]</ref> for increasing the diversity of swarms. The PSO algorithm was investigated by eliminating some of its traditional features in <ref type="bibr" target="#b29">[30]</ref> referred to as a Bare Bones Particle Swarm Optimization (BBPSO). A Gaussian distribution based search space is utilized by BBPSO where the swarm's structure and search history are used for setting the mean and standard deviation of the distribution. Each particle finds its mean position by investigating in a region where its best value is encountered and fly in the search space by adjusting its variance through the neighborhood distance.</p><p>Hence, the strategy of exploration has been implemented in the early stages of the algorithm since each particle's best position are far from each other. The exploitation process is allowed in the later stages because of the neighborhood interaction. The individual influence of the global and local components in the PSO were investigated in <ref type="bibr" target="#b53">[54]</ref> and a unification factor was introduced to combine all the influences together in an efficient manner. It is referred to as the Unified Particle Swarm Optimization (UPSO). The unified strategy combines the ex-ploration and exploitation capabilities efficiently and hence, it provides better convergence. A novel strategy for providing comprehensive learning strategies to the particles called Comprehensive Learning Particle Swarm Optimization (CLPSO) has been proposed for solving complex multimodal functions in <ref type="bibr" target="#b35">[36]</ref>. CLPSO updates a given particle's velocity using all the other particles' personal best information. Here, each dimension of a given particle can learn from the different particles' best dimensions. This helps in retaining a particle's diversity and hence avoids premature convergence as any of the particle stuck in a local optimum can learn from other particles and eventually escape the local optimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hybridized versions:</head><p>For improving the performance of the PSO algorithm, research focus has been directed towards mitigating the weaknesses of the PSO algorithm by combining it with useful properties of different evolutionary algorithms (genetic algorithm, bee colony optimization and etc.). The techniques include embedding the unique evolutionary operators: selection, crossover and mutation inside PSO <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b24">25]</ref>, differential evolution <ref type="bibr" target="#b79">[80,</ref><ref type="bibr" target="#b18">19]</ref>, diversity enhancing mechanism <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b71">72]</ref>, avoidance mechanism <ref type="bibr" target="#b52">[53]</ref>, combination of multi-crossover with bee colony mechanism <ref type="bibr" target="#b43">[44]</ref>, PSO with levy flight <ref type="bibr" target="#b21">[22]</ref> and PSO combined with Newton's laws of motion <ref type="bibr" target="#b4">[5]</ref>. A detailed survey of the hybrid PSO algorithms is given in <ref type="bibr" target="#b70">[71,</ref><ref type="bibr" target="#b19">20]</ref>.</p><p>Among the above four categories, algorithms based on learning strategies and hybridized versions are gaining attention due to their better convergence characteristics and solutions closer to the optimum. Further, researchers have focussed on different cognition strategies for better PSO convergence <ref type="bibr" target="#b77">[78,</ref><ref type="bibr" target="#b69">70]</ref>. In human cognitive psychology, it has been shown that the best planners employ self-regulation <ref type="bibr" target="#b46">[47]</ref>, i.e., best planners are those who regulate their strategies with respect to their current status. Also, they use self-perception on past experience to adjust their future directions of search. Inspired by these findings, this paper explores the use of self-regulation and self-perception in PSO.</p><p>In this paper, we propose a new particle swarm optimization algorithm inspired by learning principles found in human cognitive psychology. The pro-posed algorithm employs self-regulation and self-perception based learning strategies for better exploration and exploitation. The self-regulating inertia weights are employed only for the best particle without self or social cognition to accelerate the exploration. The self-perception of the global best search direction is employed by the rest of the particles to perform better exploitation. These particles change their perception of global best direction at every iteration for intelligent exploitation. Since the particles employ self-regulating search and perception, it is referred to as Self Regulating Particle Swarm Optimization (SRPSO) algorithm. The effect of these strategies on convergence is studied using CEC2005 benchmark problems. A boxplot has been presented to show the SRPSO convergence on the set of benchmark functions across various runs.</p><p>The performance of SRPSO has been evaluated using 25 benchmark problems of CEC2005 <ref type="bibr" target="#b63">[64]</ref> and its performance is compared with six state-of-the-art PSO variants. The PSO variants have been selected from different categories as follows: PSO with constriction factor (χPSO) <ref type="bibr" target="#b11">[12]</ref> from the category of algorithms that discuss the parameter setting; two algorithms, namely, dynamic multi-swarm particle swarm optimizer (DMSPSO) <ref type="bibr" target="#b36">[37]</ref> and fully informed particle swarm (FIPS) <ref type="bibr" target="#b44">[45]</ref> from the category of algorithms that discuss the neighborhood topology and three algorithms, namely, bare bones particle swarm (BBPSO) <ref type="bibr" target="#b29">[30]</ref>, unified particle swarm optimization (UPSO) <ref type="bibr" target="#b53">[54]</ref> and comprehensive learning particle swarm optimization (CLPSO) <ref type="bibr" target="#b35">[36]</ref> from the category of algorithms that discuss the learning strategies. The results are evaluated using the guidelines provided in CEC2005 <ref type="bibr" target="#b63">[64]</ref> and the results clearly indicate that SRPSO provide results closer to global optimum in many benchmark problems.</p><p>A statistical comparative analysis is also performed using the non-parametric Friedman test followed by the pairwise post-hoc Bonferroni-Dunn test <ref type="bibr" target="#b13">[14]</ref>. The experimental results obtained from SRPSO and its statistical analysis clearly prove that SRPSO is significantly better than the selected six variants in providing accurate solutions for the benchmark problems with a confidence level of 95%. Further, the order of complexity and computational time requirements are also discussed to present the computational complexity of SRPSO and its comparison with others. We have also tested the performance of SRPSO on a real-world radar system design problem <ref type="bibr" target="#b55">[56]</ref> where SRPSO has provided statistically better solutions. The self-regulation and self-perception help SRPSO to converge faster with solution closer to the global optimum.</p><p>The rest of the paper is organized as follows. Section 2 describes briefly the basic PSO algorithm for a better understanding of the proposed SRPSO algorithm. Section 3 provides the detailed description of the strategies introduced in this paper and the SRPSO algorithm. Section 4 presents the experimental setup, performance results highlighting the effects of the newly introduced learning strategies. This section also presents a detailed analysis of the performance comparison and statistical significance of SRPSO based on the CEC2005 benchmark problem results. This section also includes the computational complexity and convergence analysis of SRPSO. Section 5 summarize the conclusions from this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">A Brief Overview of The Particle Swarm Optimization Algorithm</head><p>Particle swarm optimization <ref type="bibr" target="#b30">[31]</ref> is a search optimization technique used to find the optimal solution motivated from the behavior of bird flocking. Each swarm has a population of N particles, which are uniformly initialized along the D-dimensional search space, having random positions and velocities. These particles search along the entire space by moving with a certain velocity to find the global best position. Each particle collaborates with other particles and shares its experiences with all of them. For each particle the new velocity is updated using its own experience and the entire swarms' best experience. Each particle</p><formula xml:id="formula_0">i consists of a D-dimensional position vector -→ X i = [X i1 , X i2 , X i3 , • • • , X iD ] and a velocity vector - → V i = [V i1 , V i2 , V i3 , • • • , V iD ].</formula><p>The two equations used in the algorithm for updating the velocity and position of the particles are:</p><formula xml:id="formula_1">V t+1 id = V t id + c 1 r 1 (P t id -X t id ) + c 2 r 2 (P t gd -X t id )<label>(1)</label></formula><formula xml:id="formula_2">X t+1 id = X t id + V t+1 id , i = 1, 2, • • • , N ; d = 1, 2, • • • , D<label>(2)</label></formula><p>where V id and X id are the velocity and position respectively, of i th particle in the d th dimension. t and t+1 represents the current and next iteration respectively; P t id is the personal best for particle i in the d th dimension and P t gd is the global best in d th dimension. c 1 and c 2 represents the acceleration coefficients and r 1 and r 2 are the random numbers distributed uniformly within the range [0, 1].</p><p>The velocity update equation of the PSO algorithm is a sum of three parts where the first part is that of exploration, the second part is that of self-exploitation and the third part is that of social exploitation respectively.</p><p>For achieving the desirable outcome, an inertia weight was introduced in PSO's velocity update equation <ref type="bibr" target="#b59">[60]</ref>. For updating the velocity of the particles, the previous velocities are multiplied by a parameter called inertia weight to balance the exploration and exploitation capabilities. During the entire run of the search process, the inertia weight is decreased linearly in order to ensure that the particles are focused towards exploration at initial stages and later focus on exploitation. The corresponding velocity update equation is:</p><formula xml:id="formula_3">V t+1 id = ωV t id + c 1 r 1 (P t id -X t id ) + c 2 r 2 (P t gd -X t id )<label>(3)</label></formula><p>It has been proven that the inclusion of linearly decreasing 'ω' in the velocity update equation provides much better solutions <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b60">61]</ref>. The selection of the best learning strategy influences the convergence of PSO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Self Regulating Particle Swarm Optimization Algorithm</head><p>Inspired by the best human learning principles, a new particle swarm optimization algorithm is proposed in this paper. According to the human cognitive psychology <ref type="bibr" target="#b46">[47]</ref>, the best decision maker employs a self-regulating strategy and self-perception about the global knowledge. It has been shown in machine learning literature that the learning algorithm employing self-regulation provides better generalization performance over other algorithms <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b67">68]</ref>. The self-regulated and cooperative/collaborative learning help the human being to make better decisions based on his current state and the desired objective. Thereby, it provides better exploration and exploitation. This motivated us to develop self-regulating and self-perception strategies in the basic PSO algorithm and observe the effectiveness of the achieved resultant performance. This algorithm is called Self</p><p>Regulating Particle Swarm Optimization Algorithm (SRPSO).</p><p>The human learning based PSO schematic is shown is figure <ref type="figure" target="#fig_0">1</ref>. The figure consists of a basic PSO block that is monitored and controlled by the decision maker. The performance of the particles in the basic PSO is input to the decision maker based on which it provides the self-regulation and self-perception strategies to the particles for their velocity updates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Particle Swarm Optimization Decision Maker</head><p>Performance Monitoring</p><p>Learning Strategies </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Basic Concepts of Human Learning Principles</head><p>Self-regulated learning describes the actions taken by an individual through continuous monitoring of his performance and adopting the best learning strategies. This helps the learners to regulate their actions for achieving the desired outcomes. Recent studies in human learning suggest that the learning process is effective when self-regulation is guided by meta-cognition <ref type="bibr" target="#b6">[7]</ref>. Self-regulation controls the learning process through proper planning and selection of appropriate learning strategies. We have taken the inspiration from the self-regulation strategies of human learning principles and are introducing two main strategies in the basic PSO algorithm for enhancing its search capabilities.</p><p>The first strategy is the use of the self-regulating inertia weight for the best particle, i.e. the best particle will be given a higher acceleration of its exploration process through an increased inertia weight. It will perform the search without any interaction with the other particles. It will return to the normal search strategy as soon as it loses the global best position. The strategy is inspired by that human learning principle, which is: if one is confirmed that he is the best in searching compared to others in a particular direction, he will accelerate quickly following the same direction without much consideration of the social/self-experience. As an example, the strategy of a hill climber is that if at any known position, he finds himself at the highest altitude as compared to others, he will start climbing in the same directions as fast as possible.</p><p>The second strategy is the use of self-perception for appropriate selection of search direction. Here, the best particle in the current iteration uses his direction as the best direction and is not influenced by his experience and also from others experiences. The rest of the particles use their perception on the global best position to find the appropriate direction in the current iteration, i.e., particles select only those directions from the global position where they have confidence. This strategy is purely based on human perception about himself and his social peers, i.e., if someone is best, his perception of the self and social experience is always negligible and he is only concerned about his present situation. The perception of someone who is not the best is that he should believe in his previous best experience and must have a certain amount of belief on his social peers to learn in a better way.</p><p>A general equation for the velocity update in SRPSO is given by</p><formula xml:id="formula_4">V t+1 id = ω i V t id + c 1 r 1 p se id (P t id -X t id ) + c 2 r 2 p so id (P t gd -X t id )<label>(4)</label></formula><p>where ω i is the inertia weight of i th particle which is self-regulated by the best particle. p se id is the perception for the self-cognition and p so id is the perception for the social cognition and they are defined as</p><formula xml:id="formula_5">p se id =      0, for best particle 1, otherwise<label>(5)</label></formula><p>and</p><formula xml:id="formula_6">p so id =      0, for best particle γ, otherwise<label>(6)</label></formula><p>where γ is binary (i.e., 0 or 1) depending on the threshold value for defining the confidence. Now, we describe the proposed two strategies in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Self-Regulating Inertia Weight</head><p>Inertia weight plays a vital role in controlling the process of exploration and exploitation by maintaining a balance in their capabilities. In this work, we have introduced a new strategy for the best particle, i.e. in any given time a particle that has achieved the global best value will perform self-regulation of its inertia weight to accelerate its search towards the global optimum. The basic idea behind this strategy is that the best particle (particle achieving the global best position) believes his direction and accelerates in that direction in search of global optimum. The rest of the particles follow the standard procedure of linearly decreasing the inertia weight to have balance between exploration and exploitation. The self-regulating inertia weight strategy is defined as</p><formula xml:id="formula_7">ω i =      ω i (t) + η∆ω, for best particle ω i (t) -∆ω, otherwise<label>(7)</label></formula><p>where ω i (t) is the current inertia weight, ∆ω = ω I -ω F N Iter = 0.55 N Iter (N Iter is the number of iterations, ω I and ω F are the initial and final values of inertia weight respectively) and η is the constant to control the rate of acceleration. In our simulation, the rate is set as 1.</p><p>Figure <ref type="figure" target="#fig_1">2</ref> shows the effect of self-regulating inertia weights experienced by particles during the search process. In figure <ref type="figure" target="#fig_1">2</ref>, the fitness history and inertia weight for three particles have been presented. The fitness curves and the inertia weights of the three particles 'a', 'b' and 'c' are shown for 1000 iterations to clearly illustrated the strategy used in the algorithm. In the beginning, the particle 'a' is the best particle as it has the best fitness value, so it utilizes the self-regulating strategy by using equation 7 as shown. The other particles, 'b' and 'c' simply perform the linearly decreasing inertia weight process. After 200 iterations, particle 'b' achieves the best fitness value and hence becomes the best particle so the self-regulating strategy is utilized for particle 'b' and since particle 'a' is no more the best particle, therefore, its inertia weight starts to decrease linearly. After 400 iterations, the particle 'a' becomes the best particle again so its inertia weight is again increased and just before the 1000 iterations particle 'b' achieves the best fitness value so from that point the inertia weight of the particle 'a' is linearly decreased and the inertia weight of particle 'b' is linearly increased. Particle 'c' is demonstrating the behavior of all the other particles except the best one as it never achieves the best fitness value and hence performs the linearly decreasing strategy for ω throughout the iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Self-Perception of Search Directions</head><p>The velocity update strategy of all the other particles is different from the best particle. It has been shown in human psychology that the best planners have a better perception of the impact of their decisions and they also collaborate with others. This perception helps them to regulate their action towards achieving the goal <ref type="bibr" target="#b46">[47]</ref>. Inspired by human collaborative learning strategy, we have developed a new learning strategy for all the other particles where particles will perform social exploitation by taking information according to their perception in the global search direction.</p><p>The self-perception strategy is implemented using a uniform random number within the range [0, 1], a ∼ U ([0, 1]) for all the directions of the global best position. The threshold (λ) value is set at 0.5 for selection of any direction. Social cognition is necessary for better convergence. If one employs full social cognition, then the result will be biased towards the global best position reached at a particular iteration. Note that, the global position at that particular iteration may not be the global optimum solution. This may lead to premature convergence. Similarly, if a much higher threshold value is selected, then there will be very low social cognition and particles will keep flying in their own directions without turning towards the global solution. This may leads to diversity loss.</p><p>Hence, in order to perform a balanced social exploitation together with effective exploration 0.5 is selected as the threshold value. The social perception of a particle is given by</p><formula xml:id="formula_8">p so id =      1, if a &gt; λ 0, otherwise where i = 1,2,...,m<label>(8)</label></formula><p>The self-perception influences the particles' search directions significantly, i.e.</p><p>the best particle assumes that his direction is the best and discards the social and self-knowledge. Hence, its social (p so id ) and self (p se id ) perceptions are set to zero. The self-perception for the rest of the particles is set to 1. Hence, other particles use self-cognition and partial social cognition for velocity update. The self-perception in global search direction reduces the risk of particles attracted to local optima. The velocity update equation for best particle is given by</p><formula xml:id="formula_9">V t+1 id = ω i V t id , (i = best) (9)</formula><p>and for all the other particles is represented as</p><formula xml:id="formula_10">V t+1 id = ω i V t id + c 1 r 1 (P t id -X t id ) + c 2 r 2 p so id (P t gd -X t id )<label>(10)</label></formula><p>Incorporating the above two strategies, the pseudo-code for SRPSO is summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1:</head><p>The SRPSO Algorithm Initialization:</p><p>for each particle i do Randomly initialize position of each particle X i in the search range (X min , X max ) Randomly initialize velocity of each particle V i end Calculate the fitness values for each particle; Find the personal best position of each particle; The SRPSO Loop: while <ref type="bibr">(</ref> Reject the directions end end Update the velocity using equation 10; end Update the position of each particle using equation 2; end</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Setup, Results and Discussion</head><p>Since, most of the existing PSO variants are evaluated using CEC2005 standard benchmark problems <ref type="bibr" target="#b63">[64]</ref>, the same has been selected in this paper for performance evaluation and a statistical comparison of SRPSO with other wellknown PSO variants. This section is organized as follows: A detailed description of the CEC2005 benchmark problems used in the study is described first, followed by the impact of the proposed learning strategies in the SRPSO algorithm. Next, a performance evaluation of SRPSO on CEC2005 benchmark problems are compared with results available in the literature for the well-known PSO variants. Further, a statistical comparison analysis, computational complexity, convergence analysis and a practical application of SRPSO are also provided in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Benchmark Functions</head><p>The CEC 2005 benchmark functions <ref type="bibr" target="#b63">[64]</ref> broadly fall into four different groups (based on their characteristics), namely; unimodal (F 1 -F 5 ), basic multimodal (F 6 -F 12 ), expanded multimodal (F 13 and F 5 ) and hybrid composition (F 15 -F 25 ). Table <ref type="table" target="#tab_1">1 contains</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Study and Effects of Learning Strategies in SRPSO</head><p>SRPSO employs two main strategies, namely; self-regulating inertia weight and self-perception on global search direction. The effect of each strategy is studied separately first. Their combined effects for enhancing the basic PSO convergence is then studied. The algorithm employing the self-regulating inertia weight strategy is referred to as the 'SRPSO-ω' and that using the selfperception on global search direction strategy as the 'SRPSO-p'. The rate of acceleration (η) in the self-regulating inertia weight and the random perception of directions (λ) influence the convergence of SRPSO. In order to study the effect of these strategies, four functions F 4 , F 6 , F 11 and F 14 are used for different values of η (0.5,1 and 2) and λ (0.25, 0.5 and 0.75). The PSO algorithm is run 30 times with the standard settings suggested in <ref type="bibr" target="#b63">[64]</ref>.    </p><formula xml:id="formula_11">f i = [F 8, F 8, F 9, F 9, F 1, F 1, F 11, F 11, F 7, F 7]</formula><formula xml:id="formula_12">f i = [F 8, F 8, F 9, F 9, F 1, F 1, F 11, F 11, F 7, F 7]</formula><formula xml:id="formula_13">f i = [F 11, F 14, F 13, F 8, F 9, F 7, F 13nc , F 9nc , F 3, F 1] without fb (nc = non -continuous) [2, 5] D 260</formula><p>The median, mean and standard deviation fitness values for the <ref type="bibr" target="#b29">30</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Experimental Results and Performance Comparison</head><p>In this section, the results for all the benchmark functions are presented and compared with the well-known PSO variants. For the experiments, 30dimensional and 50-dimensional benchmark problems are considered with a swarm size of 40 particles. For a comparative analysis, the following widely ac-  cepted PSO variants by the evolutionary computing research community have been selected in this study. Since, the constriction factor PSO <ref type="bibr" target="#b11">[12]</ref> has been proven to be better in controlling the convergence characteristics of the particles, it is selected for comparison from the category of parameter settings.</p><p>From the category of neighborhood topology, the dynamic multi-swarm particle swarm optimizer <ref type="bibr" target="#b36">[37]</ref> and fully informed particle swarm <ref type="bibr" target="#b44">[45]</ref> have been selected. DMSPSO has introduced a dynamically changing neighborhood in the search process that performed much better than that provided by the fixed neighborhood search. Similarly, FIPS employs a novel search strategy using a weighted sum of the neighboring particles as compared to other variants and hence it provides better solution to selected problems. Since, the proposed SRPSO belongs to the category of learning strategy, three well-known algorithms, namely, BBPSO, UPSO and CLPSO are selected for comparison. The bare bones PSO <ref type="bibr" target="#b29">[30]</ref> has successfully enhanced the exploration and exploitation powers of the PSO algorithm and has resulted in better convergence on a set of problems.</p><p>The unified particle swarm optimization <ref type="bibr" target="#b53">[54]</ref> has efficiently utilized the local and global search variants of PSO to enhance the convergence characteristics and eventually prove to be a competitive PSO variant. The comprehensive learning particle swarm optimization <ref type="bibr" target="#b35">[36]</ref> has been very efficient in accelerating the convergence towards the optimum solution and it has been widely accepted as the most promising PSO variant by the evolutionary community. Compared to other variants of PSO, CLPSO searches more potential regions of the search space to find the global optima. The parameter settings and the experimental setup for the selected PSO variants are:</p><p>• Parameters: φ = 4.1, χ = 0.72984, ω = [0.9-0.4] and c 1 = c 2 = 2.05 <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b35">36]</ref> • Ring Topology for neighborhood radius of 2</p><p>• Function evaluations = 10 4 ×D (D is the dimension)</p><p>Results for these algorithms are taken from <ref type="bibr" target="#b18">[19]</ref> and the performance of SRPSO has been evaluated using the experimental guidelines defined in CEC2005</p><p>[64] evaluation criteria. The SRPSO parameters are set as: initial value for ω= First, the results for the five unimodal benchmark functions, i.e., F 1 to F 5 are presented. Table <ref type="table" target="#tab_4">3</ref> presents the median, mean and standard deviation of the SRPSO along with the other algorithms for both 30-dimensional and 50dimensional cases. From table <ref type="table" target="#tab_4">3</ref>, one can observe that SRPSO performs better than the other PSO variants. Both in the 30-dimensional and 50-dimensional cases, SRPSO has provided better mean and median performances and it has outperformed all the other algorithms by a significant margin. In case of function F 1 , SRPSO , CLPSO and BBPSO converges to the optimal solution, whereas in the case of function F 2 , only SRPSO converges to the optimal solution. The rest of the algorithm does not converge to the optimal solution for these problems.</p><p>It may also be noted that SRPSO obtains better solutions for other functions, particularly for the function F 3 . The mean error is closer to zero, whereas other PSO variants are in the range of 10 6 and 10 7 . Based on these observations, it may be inferred that SRPSO provides significantly better solutions for unimodal functions.</p><p>Next, the results of the five basic multimodal benchmark functions, i.e., F 6 to F 10 are presented in table <ref type="table" target="#tab_6">4</ref>. With the exception of F 8 , where all the selected algorithms have more or less the same results, SRPSO has provided promising results in both the 30-dimensional and 50-dimensional cases. From the table, it can be seen that SRPSO converges closer to the optimum in F 7 , whereas mean deviation from the optimum of the rest of the algorithms are in the order of 10 3 .</p><p>In case of F 9 , CLPSO finds the optimum, whereas mean deviation of SRPSO is of the order of 10 1 . Overall, it is seen that SRPSO performs better in the 50-dimensional case, whereas its performance is similar to that of CLPSO in the 30-dimensional case.   F 24 ). It can also be seen that the 30-dimensional median result of SRPSO is the same as that of CLPSO.</p><p>To summarise, one can say that the proposed SRPSO converges with better accuracy in all groups of functions. Hence, the performance of SRPSO on the entire 25 benchmark functions can be termed as the best among all the other variants. As a whole, out of the 25 functions studied, SRPSO has outperformed all other variants of PSO in 17 benchmark functions for the 30-dimensional median fitness values, 18 benchmark functions for the 50-dimensional median fitness values, 15 benchmark functions for the 30-dimensional mean fitness val- ues and 16 benchmark functions for the 50-dimensional mean fitness values.</p><p>Since CLPSO and DMSPSO are designed only for multimodal functions, their performance is better only in those problems. Other selected variants perform well only in a few of the problems. Due to the diverse behavior of different PSO algorithms, a rank based study for performance comparison has also been undertaken and is presented next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Rank Based Analysis</head><p>In this study, the algorithms are ranked based on their median/mean performances. The algorithms are ranked according to their performances using a standard competition ranking scheme. In competition ranking, algorithms receive the same rank if their performances are same. The next performing algorithm is assigned a rank with a gap (gap is determined based on the number of equally performing algorithms). Table <ref type="table" target="#tab_10">8</ref> provides the ranks of the individual algorithms and the average rank for all the functions based on both the cases of 30 and 50-dimensional median performances. Based on the average ranking, the order of performance obtained is SRPSO followed by CLPSO, BBPSO, χPSO, DMSPSO, FIPS and UPSO respectively in the 30-dimensional case and it is SRPSO followed by CLPSO and BBPSO, DMSPSO, χPSO, UPSO and FIPS respectively in the 50-dimensional case.</p><p>Figure <ref type="figure" target="#fig_10">4</ref> presents the histograms that indicate the number of times each algorithm have achieved the ranks in the range of 1 to 7. Figure <ref type="figure" target="#fig_16">4(a)</ref> shows the results for the 30-dimensional case and figure 4(b) shows the same for the 50-dimensional case. It can be seen that SRPSO achieves the top rank twice as compared to CLPSO which is the second best algorithm in the 30-dimensional case. For the 50-dimensional case, SRPSO is the top ranked algorithm at least three times more than that of the second best algorithm. </p><formula xml:id="formula_14">SRPSO 1 1 1 1 1 1 1 5 3 1 1 1 1 2 3 1 1 1 1 1 3 1 3 3 1 1.68(1)</formula><p>Next, the algorithms are ranked according to their mean (instead of the median) performances. The rankings of the individual algorithm and the average rank based on all the functions for both on the 30-dimensional and 50dimensional mean performances are given in table <ref type="table" target="#tab_11">9</ref>. Using the average ranks, one can note that SRPSO performs much better than other PSO variants. Based on the average ranking, the order of performance is SRPSO followed by CLPSO, BBPSO, χPSO, DMSPSO, FIPS and UPSO respectively in the 30-dimensional cases and SRPSO followed by CLPSO, BBPSO, DMSPSO and FIPS, UPSO and χPSO respectively in the 50-dimensional case.</p><p>Similar to the median rank analysis, the histogram of ranks for mean performance are also presented in figure <ref type="figure" target="#fig_11">5</ref>. One can make similar observations on the performance of SRPSO over other PSO variants. Based on the above rank (both median and mean) studies, it is evident that SRPSO performs better than the other PSO variants in all the 25 benchmark problems. Mean rank of algorithms over 25 different benchmark problems is not a conclusive measure and hence a statistical comparison has been conducted to understand the significance of the performance of SRPSO over other algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Statistical Comparison</head><p>For statistical comparison, the non-parametric Friedman test on the average rank followed by the pairwise post-hoc Bonferroni-Dunn test <ref type="bibr" target="#b13">[14]</ref> has been conducted to indicate the significance of the performance improvement of SRPSO over other PSO variants. Friedman test is a non-parametric statistical test, which is used to detect the differences between the performance of the algo-  The average ranks of χPSO, BBPSO, DMSPSO, FIPS, UPSO, CLPSO and SRPSO for different dimensions are given in Table <ref type="table" target="#tab_10">8</ref> and Table <ref type="table" target="#tab_11">9</ref>. The null hypothesis states that all algorithms are equal and hence their average ranks must be equal.</p><p>In this study, there are 7 algorithms (A) and 25 benchmark problems (P).</p><p>The F-statistic value for a confidence level of 95% can be obtained using the notation F (A-1),P (A-1),α/2 i.e. F 6,150,0.025 which gives the critical value as From the table, it is observed that the difference in average rank is greater than the computed critical difference and hence one can infer that the SRPSO is statistically better than the six PSO variants considered in this study (except for CLPSO in 30-dimensional mean case). At 90% confidence level, the critical difference is 0.6233 for which the performance of SRPSO is better than CLPSO in 30-dimensional mean case. To summarize, it is clear that the human learning strategies incorporated in the SRPSO algorithm have provided better performances on the set of benchmark functions especially in unimodal and multimodal benchmark functions.</p><p>The self-regulation of inertia weight has indeed enhanced the exploration capabilities of the particles and perception based selection of directions for the global best has made the particles capable of tackling the premature convergence. Also, from tables 8 and 9 it may be noted that SRPSO has not performed that well on a few hybrid composition functions. This shortcoming may be due to the fact that not all the capabilities of human learning strategies have been brought in here. One may be able to overcome this deficiency by incorporating more human learning strategies that can effectively provide better performance for the case of hybrid composite functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Computational Complexity and CPU Time Analysis of SRPSO</head><p>In this section, the computational complexity and CPU time requirements of the proposed SRPSO algorithm are analysed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.1.">Computational Complexity</head><p>The order of complexity of any algorithm describes its efficiency. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.2.">Computational Time Requirements</head><p>The CPU clock time of SRPSO and PSO are calculated based on the set of benchmark functions to demonstrate the computation time requirements of the proposed algorithm. The following equation as suggested in <ref type="bibr" target="#b18">[19]</ref> has been utilized to evaluate the same:</p><formula xml:id="formula_15">Burden(F ) = SRP SO t (F ) -P SO t (F ) P SO t (F )<label>(11)</label></formula><p>The average CPU clock time of SRPSO on functions F The same is observed across the 25 functions, where SRPSO has provided a CPU time reduction of 4%-8%. It is obvious that in SRPSO, social perception p so id will use the social cognitive part lesser number of times as compared to the standard PSO algorithm and hence it reduces the computational time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Convergence Characteristics of the SRPSO algorithm</head><p>In this section, the analysis of the convergence characteristics of the proposed SRPSO algorithm on all the 25 benchmark problems for the 30-dimensional case is performed. It is represented using the convergence graph and also the boxplot.</p><p>The convergence characteristics of the SRPSO algorithm are shown in figure <ref type="figure" target="#fig_13">6</ref>. The figure provides the logarithmic difference between the optimum and the solution obtained by SRPSO over number of function evaluations. Figure <ref type="figure" target="#fig_13">6</ref>  In figure <ref type="figure" target="#fig_13">6</ref> Similarly, the faster convergence characteristics of the SRPSO algorithm on the expanded multimodal functions are evident in figure <ref type="figure" target="#fig_13">6(c</ref>). The results in table 5 and the average rank from table <ref type="table" target="#tab_11">9</ref> prove that SRPSO converges close to the optimum solution. One can make similar observations for the convergence characteristics of the hybrid composition functions. Based on the convergence characteristics and the statistical analysis, it is evident that SRPSO has faster convergence closer to the global optimum for wide range of benchmark functions.</p><p>Next, the box-plot of Error fitness values (F(x)-F(x*)) for the entire hundred runs are given to demonstrate the convergence analysis.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8.">SRPSO performance on a Real-World problem</head><p>In this section, the performance of SRPSO is studied on a widely used real world problem for the radar system design known as the spread spectrum radar polyphase code design problem. Pulse compression technique is the most widely accepted technique in radar systems. A method for polyphase pulse compression code design was introduced in <ref type="bibr" target="#b15">[16]</ref> and the min-max nonlinear optimization problem model is available in <ref type="bibr" target="#b55">[56]</ref> x k ), i = 1, 2,</p><formula xml:id="formula_16">• • • , D -1 Φ m+i (X) = -Φ i (X), i = 1, 2, • • • , m<label>(13)</label></formula><p>In this paper, a 20-dimensional spread spectrum radar polyphase code design problem is considered. All the experimental setup is performed according to the recent work <ref type="bibr" target="#b39">[40]</ref> and the results for three algorithms, namely, CLPSO, FIPS and UPSO are taken. The performance of SRPSO is also compared with the recently proposed teaching and peer learning PSO algorithm <ref type="bibr" target="#b39">[40]</ref>. The mean and standard deviation fitness values after 30 runs for the radar system design problem are reported in Table <ref type="table" target="#tab_18">12</ref>. The results in the table provide the significance of the proposed SRPSO algorithm as it is the best optimizer for the problem. From the table, it can be easily concluded that SRPSO has significantly outperformed the three other PSO variants as well as the TPLPSO algorithm. The standard deviation of SRPSO is also very low which signifies the searching accuracy and robustness of the algorithm. Hence, it can be concluded that SRPSO is an effective optimization algorithm for real-world applications. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, a new self-regulating particle swarm optimization algorithm is presented. It uses the self-regulating inertia weight only for the best particle to improve exploration and self-perception in global search direction for the rest of the particles for better exploitation. It is observed that the presence of more exploration through self-regulating inertia weight and intelligent exploitation through self-perception based selection of directions help SRPSO to perform better. The performance of SRPSO has been evaluated using 25 benchmark functions (unimodal, basic multimodal, expanded multimodal and hybrid composition) from CEC2005 and the results are compared with PSO with constriction factor, bare bones particle swarm, dynamic multi-swarm particle swarm optimizer, fully informed particle swarm, unified particle swarm optimization and comprehensive learning particle swarm optimization. The results clearly highlight that SRPSO consistently performs better in all four categories of the benchmark functions. The non-parametric Friedman test followed by the pairwise post-hoc Bonferroni-Dunn test clearly indicate that SRPSO is better than other PSO variants with 95% confidence level. SRPSO has performed better, especially on the unimodal and multimodal benchmark problems. On a few hybrid composition functions, other algorithms performed better than SRPSO indicating further refinement of human learning strategies is needed. Finally, the performance of SRPSO has been evaluated using a real-world radar system design problem where SRPSO has been found as an effective optimization tool.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The Human Learning based PSO Schematic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The inertia weight update strategy</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>a brief description of the objective function, search range and bias value for all the 25 functions. The shifted global optimum for all the functions is provided as o = [o 1 , o 2 , • • • , o D ] and the functions are defined as z = x-o for shifted functions and z = (x-o)*M for shifted rotated functions where M is the transformation matrix for the rotating matrices. The hybrid composition functions select different basic unimodal and multimodal functions without shift or rotation and then provide new shifted rotated optimum positions to the selected functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>F8 2 [</head><label>2</label><figDesc>)) + 20 + e + fb[-32, 32]  cos(2πb k (zi +0.5))])-D kmax k=0 [a k cos(2πb k * 0.5)]+fb where a = 0.5, b = 3 &amp; kmax = 20. [-0.5, 0.5] D 90 Schwefel's Problem 2.13 F12 = D i=1 (|Ai -Bi (x)|) 2 + fb where Ai = D j=1 (aij sinαj + bij cosαj ) and Bi (x) = D j=1 (aij sinxj + bij cosxj ) [-π, π] D -460 Shifted Expanded Griewank's plus Rosenbrock's Function (F8F2) F13 =F 8(F 2(z1 , z2 )) + F 8(F 2(z2 , z3 )) + • • • + F 8(F 2(zD-1 , zD )) + F 8(F 2(zD , z1 )) + fb [-5, 5] D -130 Shifted Rotated Expanded Scaffer's F6 Function F14 =F (z1 , z2 ) + F (z2 , z3 ) + • • • + F (zD-1 , zD ) + F (zD , z1 ) + fb F (x, y) = 0.5 + (sin 2 ( √ x2 +y2 )-0.5) (1+0.0001(x2 +y2 ))* [f i (z) + biasi ] + fb where n = 10 f i = [F 9, F 9, F 11, F 11, F 7, F 7, F 8, F 8, F 1, F 1] without fb [-5, 5] D 120 Rotated Hybrid Composition Function F16 = n i=1 wi * [f i (z) + biasi ] + fb where n = 10 f i = [F 9, F 9, F 11, F 11, F 7, F 7, F 8, F 8, F 1, F 1] without fb [-5, 5] D 120 F16 with Noise in Fitness F17 =G(x) * (1 + 0.2|N (0, 1)|) + fb where G(x) = F16 -fb (16) [-5, 5] D 120 Rotated Hybrid Composition Function F18 = n i=1 wi * [f i (z) + biasi ] + fb where n = 10</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>f i (z) + biasi ] + fb where n = 10</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>[[[</head><label></label><figDesc>f i (z) + biasi ] + fb where n = 10f i = [F 8, F 8, F 9, F 9, F 1, F 1, F 11, F 11, F 7,F 7] without fb [-5, 5] D 10 Rotated Hybrid Composition Function F21 = n i=1 wi * [f i (z) + biasi ] + fb where n = 10 f i = [F 14, F 14, F 9, F 9, F 13, F 13, F 11, F 11, F 7, F 7] without fb f i (z) + biasi ] + fb where n = 10 f i = [F 14, F 14, F 9, F 9, F 13, F 13, F 11, F 11, F 7, F 7] without fb f i (z) + biasi ] + fb where n = 10 f i = [F 14, F 14, F 9, F 9, F 13, F 13, F 11, F 11, F 7, F 7] without fb f i (z) + biasi ] + fb where n = 10 f i = [F 11, F 14, F 13, F 8, F 9, F 7, F 13nc , F 9nc , F 3, F 1] without fb (nc = non -continuous) f i (z) + biasi ] + fb where n = 10</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>in three of the selected functions as compared to its other values. The results for the other strategy SRPSO-p have also provided promising convergence accuracy of the basic PSO algorithm. The value λ = 0.5 is providing the best results in two of the selected functions. Based on these observations, the parameters η and λ are set at 1 and 0.5 respectively for all problems. The combined effects of both the strategies is also provided in the table where the results for the full SRPSO (η=1 &amp; λ=0.5) are significantly better than the basic PSO algorithm in all the problems and the results for the individual strategies in three of the problems.To see the convergence characteristics of the SRPSO, both the standard PSO and SRPSO algorithms are run using the Function F 4 . The fitness versus time for both the algorithms is shown in figure3. From the figure, one can see that SRPSO converges towards the global optimum closely and with a faster rate of convergence. Similar behavior is also observed on most of the other functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>1.193E+01 6.167E-01 SRPSO-p (λ=0.25) 1.169E+01 1.168E+01 5.302E-01 SRPSO-p (λ=0.5) 1.190E+01 1.177E+01 5.522E-01 SRPSO-p (λ=0.75) 1.253E+01 1.253E+01 2.459E-01 SRPSO (η=1 &amp; λ=0.5) 1.185E+01 1.182E+01 4.856E-01</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Convergence of SRPSO vs standard PSO</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>1 .</head><label>1</label><figDesc>05, the final value for ω= 0.5, c 1 = c 2 = 1.49445, swarm size = 40 and V max = 0.06708 * Range. All the 30-dimensional and 50-dimensional median, mean and standard deviation fitness values for 100 runs are presented.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Histogram of individual median Ranks (a) 30-Dimensional, (b) 50-Dimensional</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Histogram of individual mean Ranks (a) 30-Dimensional, (b) 50-Dimensional</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>figure 6(c) presents the convergence characteristics for the expanded multimodal functions and figure 6(d) presents the convergence characteristics for the hybrid composition functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Convergence graphs of the CEC 2005 benchmark functions: (a)Unimodal functions, (b)Basic Multimodal functions, (c)Expanded Multimodal functions and (d)Hybrid Composition functions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 7</head><label>7</label><figDesc>illustrates the performance of SRPSO on all the 25 benchmark functions. The figure contains the boxplots of 100 runs where the functions are plotted against the final output produced by SRPSO. In the plot, it is clearly illustrated that with the exception of a few outliers, SRPSO algorithm has converged around the same point in the functions F 2 , F 8 , F 13 , F 14 , F 22 , F 23 and F 24 . The boxplots are comparatively short in functions F 3 , F 4 , F 9 , F 10 , F 11 and F 25 which shows a high level of accuracy across the 100 runs. There are uneven boxes for function</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Boxplot for the 25 Benchmark Functions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>F 4 ,</head><label>4</label><figDesc>F 7 , F 16 , F 17 , F 21 and F 25 which show that there are different convergence points. There are a number of outliers in function F 6 , but still the median value is comparatively small. Evenly distributed behaviour is observed in functions F 9 , F 14 , F 15 , F 18 , F 19 and F 20 . Hence it can be concluded that the overall the performance of SRPSO on the 25 benchmark functions across 100 runs has been fairly good.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>. The problem is a continuous min-max global optimization problem with numerous local optima. The min-max model is defined asGlobal minf (x) = max{Φ 1 (X), Φ 2 (X), • • • , Φ 2m (X)} (12)whereX = {(x 1 , x 2 , • • • , x D ) R D |0 ≤ x j ≤ 2π}, m = 2D -1 and Φ(X) is Φ 2i-1 (X) =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>CEC2005 Benchmark functions</figDesc><table><row><cell>Name</cell><cell cols="4">Objective Function</cell><cell></cell><cell></cell><cell>Search RangeBias(fb )</cell></row><row><cell></cell><cell>D</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Shifted Sphere</cell><cell>F1 =</cell><cell cols="3">z 2 i + fb</cell><cell></cell><cell></cell><cell>[-100, 100] D</cell><cell>-450</cell></row><row><cell></cell><cell>i=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>D</cell><cell></cell><cell>D</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Shifted Schwefel's Problem 1.2</cell><cell>F2 =</cell><cell>(</cell><cell></cell><cell cols="2">zj ) 2 + fb</cell><cell></cell><cell>[-100, 100] D</cell><cell>-450</cell></row><row><cell></cell><cell>i=1</cell><cell cols="2">j=1</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>D</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Shifted Rotated High Conditioned Elliptic</cell><cell>F3 =</cell><cell cols="2">(10 6 )</cell><cell cols="2">i-1 D-1 z 2 i + fb</cell><cell></cell><cell>[-100, 100] D</cell><cell>-450</cell></row><row><cell></cell><cell>i=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>D</cell><cell></cell><cell>D</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Shifted Schwefel's Problem 1.2 with</cell><cell>F4 =(</cell><cell>(</cell><cell></cell><cell cols="4">zj ) 2  *  (1 + 0.4|N (0, 1)|) + fb</cell><cell>[-100, 100] D</cell><cell>-450</cell></row><row><cell>Noise in Fitness</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">i=1</cell><cell>j=1</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Schwefel's Problem 2.6 with Global</cell><cell cols="5">F5 =max |Ai x -Bi | + fb</cell><cell cols="2">where Ai is the ith row of a D*D</cell><cell>[-100, 100] D</cell><cell>-310</cell></row><row><cell>Optimum on Bounds</cell><cell cols="7">matrix A andBi is the ith element of D*1 vector B</cell></row><row><cell></cell><cell>D</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Shifted Rosenbrock's Function</cell><cell>F6 =</cell><cell cols="6">(100(z 2 i -zi+1 ) 2 + (zi -1) 2 ) + fb</cell><cell>[-100, 100] D</cell><cell>390</cell></row><row><cell></cell><cell>i=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>D</cell><cell></cell><cell></cell><cell>D</cell><cell></cell><cell></cell></row><row><cell>Shifted Rotated Griewank's Func-tion without Bounds</cell><cell>F7 =</cell><cell cols="3">z 2 i 4000 -</cell><cell cols="2">cos( zi √ i</cell><cell>) + 1 + fb</cell><cell>[0, 600] D</cell><cell>-180</cell></row><row><cell></cell><cell>i=1</cell><cell></cell><cell></cell><cell>i=1</cell><cell></cell><cell></cell></row><row><cell>Shifted Rotated Ackley's Function</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>with Global Optimum on Bounds</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>-dimensional problems are provided in table 2. The table contains the results for the standard PSO, SRPSO-ω, SRPSO-p and the full SRPSO algorithms. From table 2, the results for SRPSO-ω have provided a better convergence to the basic PSO algorithm, whereas η =1 has provided the best median and mean fitness values</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Strategy analysis on selected 30-Dimensional CEC 2005 Benchmark Functions</figDesc><table><row><cell>Func.</cell><cell>Algorithm</cell><cell>Median</cell><cell>Mean</cell><cell>STD.</cell></row><row><cell></cell><cell>Basic PSO</cell><cell cols="3">1.044E+02 1.544E+02 9.842E+01</cell></row><row><cell></cell><cell>SRPSO-w (η=0.5)</cell><cell cols="3">9.495E+01 1.028E+02 5.577E+01</cell></row><row><cell></cell><cell>SRPSO-w (η=1)</cell><cell cols="3">8.079E+01 1.001E+02 6.607E+01</cell></row><row><cell>F 4</cell><cell>SRPSO-w (η=2) SRPSO-p (λ=0.25)</cell><cell cols="3">8.874E+01 1.011E+02 6.046E+01 1.339E+02 1.393E+02 6.071E+01</cell></row><row><cell></cell><cell>SRPSO-p (λ=0.5)</cell><cell cols="3">5.685E+01 6.889E+01 4.094E+01</cell></row><row><cell></cell><cell cols="4">SRPSO-p (λ=0.75) 4.560E+01 6.191E+01 4.891E+01</cell></row><row><cell></cell><cell cols="4">SRPSO (η=1 &amp; λ=0.5) 1.998E+01 2.988E+01 2.480E+01</cell></row><row><cell></cell><cell>Basic PSO</cell><cell cols="3">2.575E+01 5.021E+01 4.937E+01</cell></row><row><cell></cell><cell>SRPSO-w (η=0.5)</cell><cell cols="3">2.386E+01 6.052E+01 6.814E+01</cell></row><row><cell></cell><cell>SRPSO-w (η=1)</cell><cell cols="3">2.327E+01 3.790E+01 3.512E+01</cell></row><row><cell>F 6</cell><cell>SRPSO-w (η=2) SRPSO-p (λ=0.25)</cell><cell cols="3">2.341E+01 5.226E+01 4.314E+01 2.123E+01 3.420E+01 2.946E+01</cell></row><row><cell></cell><cell>SRPSO-p (λ=0.5)</cell><cell cols="3">1.144E+01 2.683E+01 3.994E+01</cell></row><row><cell></cell><cell>SRPSO-p (λ=0.75)</cell><cell cols="3">2.028E+01 5.930E+01 7.660E+01</cell></row><row><cell></cell><cell cols="4">SRPSO (η=1 &amp; λ=0.5) 1.472E+01 3.978E+01 5.708E+01</cell></row><row><cell></cell><cell>Basic PSO</cell><cell cols="3">1.168E+01 1.285E+01 3.160E+00</cell></row><row><cell></cell><cell>SRPSO-w (η=0.5)</cell><cell cols="3">9.204E+00 9.497E+00 1.707E+00</cell></row><row><cell></cell><cell>SRPSO-w (η=1)</cell><cell cols="3">9.665E+00 9.905E+00 2.647E+00</cell></row><row><cell>F 11</cell><cell>SRPSO-w (η=2) SRPSO-p (λ=0.25)</cell><cell cols="3">1.086E+01 1.087E+01 2.253E+00 1.331E+01 1.287E+01 3.151E+00</cell></row><row><cell></cell><cell>SRPSO-p (λ=0.5)</cell><cell cols="3">1.250E+01 1.286E+01 3.078E+00</cell></row><row><cell></cell><cell>SRPSO-p (λ=0.75)</cell><cell cols="3">2.925E+01 2.895E+01 2.946E+00</cell></row><row><cell></cell><cell cols="4">SRPSO (η=1 &amp; λ=0.5) 9.080E+00 9.583E+00 4.273E+00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Median, Mean and Standard Deviation for 30-Dimensional and 50-Dimensional of CEC 2005 Benchmark Functions F 1 to F 5</figDesc><table><row><cell cols="2">Func. Algorithm</cell><cell>Median</cell><cell cols="2">30-Dimensional Mean</cell><cell>StD.</cell><cell>Median</cell><cell>50-Dimensional Mean</cell><cell>STD.</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">5.328E+00 9.657E+00 1.233E+01 5.328E+00 9.657E+00 1.233E+01</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">0.000E+00 0.000E+00 0.000E+00 0.000E+00 0.000E+00 0.000E+00</cell></row><row><cell></cell><cell cols="7">DMSPSO 1.143E+02 3.135E+02 4.149E+02 2.349E+02 3.870E+02 3.855E+02</cell></row><row><cell>F1</cell><cell>FIPS</cell><cell cols="6">3.185E+02 5.252E+02 5.571E+02 1.149E+03 1.673E+03 1.524E+03</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">1.269E+03 1.306E+03 7.328E+02 6.840E+02 7.100E+02 3.290E+02</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">0.000E+00 0.000E+00 0.000E+00 0.000E+00 0.000E+00 0.000E+00</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">0.000E+00 0.000E+00 0.000E+00 0.000E+00 0.000E+00 0.000E+00</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">0.000E+00 1.573E+01 8.112E+01 2.334E+02 7.774E+02 1.806E+03</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="2">6.000E-03</cell><cell cols="4">9.260E-03 8.480E-03 2.407E+02 2.886E+02 1.452E+02</cell></row><row><cell></cell><cell cols="7">DMSPSO 1.536E+02 7.801E+02 2.109E+03 3.311E+02 9.666E+02 1.409E+03</cell></row><row><cell>F2</cell><cell>FIPS</cell><cell cols="6">1.460E+04 1.470E+04 2.316E+03 2.633E+04 2.574E+04 4.424E+03</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">6.688E+03 7.602E+03 5.290E+03 3.632E+03 4.220E+03 2.894E+03</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">3.828E+02 3.828E+02 1.060E+02 1.013E+04 1.021E+04 1.357E+03</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">0.000E+00 0.000E+00 0.000E+00 1.400E-03 3.767E-03 1.753E-02</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">3.491E+06 1.020E+07 1.336E+07 1.852E+07 1.988E+07 1.266E+07</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">1.243E+06 1.295E+06 5.728E+05 3.693E+06 3.709E+06 9.352E+05</cell></row><row><cell></cell><cell cols="7">DMSPSO 3.898E+06 5.623E+06 6.225E+06 8.835E+06 1.317E+07 1.579E+07</cell></row><row><cell>F3</cell><cell>FIPS</cell><cell cols="6">1.530E+07 1.945E+07 1.109E+07 5.586E+07 5.867E+07 2.346E+07</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">4.308E+07 5.303E+07 3.856E+07 4.885E+07 5.340E+07 3.743E+07</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">1.204E+07 1.188E+07 3.107E+06 5.084E+07 4.930E+07 1.161E+07</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">2.542E+01 4.519E+01 5.820E+01 6.967E+02 5.316E+03 2.321E+04</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">1.555E+03 1.834E+03 1.088E+03 2.813E+04 2.760E+04 1.007E+04</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">1.962E+03 2.307E+03 1.188E+03 3.026E+04 2.965E+04 6.094E+03</cell></row><row><cell></cell><cell cols="7">DMSPSO 2.945E+02 8.561E+02 1.292E+03 1.306E+04 1.343E+04 3.945E+03</cell></row><row><cell>F4</cell><cell>FIPS</cell><cell cols="6">2.077E+04 2.068E+04 3.107E+03 3.355E+04 3.424E+04 3.850E+03</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">1.913E+04 1.876E+04 6.086E+03 1.353E+04 1.449E+04 4.462E+03</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">5.481E+03 5.396E+03 1.250E+03 3.477E+04 3.428E+04 5.637E+03</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">1.998E+01 2.988E+01 2.480E+01 1.985E+03 2.177E+03 8.567E+02</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">7.886E+03 8.101E+03 1.210E+03 1.127E+04 1.117E+04 1.975E+03</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">5.243E+03 5.314E+03 1.033E+03 1.295E+04 1.262E+04 1.969E+03</cell></row><row><cell></cell><cell cols="7">DMSPSO 4.368E+03 4.261E+03 1.873E+03 5.311E+03 5.533E+03 1.449E+03</cell></row><row><cell>F5</cell><cell>FIPS</cell><cell cols="6">1.164E+04 1.174E+04 1.393E+03 1.594E+04 1.589E+04 1.147E+03</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">1.268E+04 1.282E+04 2.288E+03 1.177E+04 1.207E+04 2.304E+03</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">4.011E+03 4.001E+03 4.276E+02 9.753E+03 9.698E+03 7.903E+02</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">1.658E+03 1.758E+03 6.590E+02 3.602E+03 3.686E+03 8.526E+02</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc>presents the results for the functions F 11 to F 15 . These functions are</figDesc><table><row><cell>from three different categories, namely; the basic multimodal class, expanded</cell></row><row><cell>multimodal class and a hybrid composition class. The mean, median and stan-</cell></row><row><cell>dard deviation for both 30-dimensional and 50-dimensional cases for the selected</cell></row><row><cell>PSO variants and SRPSO are given in the table. Note that, the difference be-</cell></row><row><cell>tween the optimum and the solutions generated by the PSO variants are almost</cell></row></table><note><p>in the same range with a few exceptions. For function F 11 , SRPSO has provided</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Median, Mean and Standard Deviation for 30-Dimensional and 50-Dimensional of CEC 2005 Benchmark Functions F 6 to F 10CLPSO results are one order better than all the other variants. From table 5, it can be seen that SRPSO's performance improvement is marginal for at least three out of five functions in both 30-dimensional and 50-dimensional cases. It should also be noted that, SRPSO is either the 2 nd best or 3 rd best algorithm in the other two functions where it has not provided better results.Next, the results for the hybrid composition benchmark functions F 16 to F 20 are presented in table 6. Note that, SRPSO performs better in all the five functions compared to the other PSO variants based on the median performance,</figDesc><table><row><cell cols="2">Func. Algorithm</cell><cell>Median</cell><cell>30-Dimensional Mean</cell><cell>StD.</cell><cell>Median</cell><cell>50-Dimensional Mean</cell><cell>STD.</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">3.602E+02 1.170E+03 1.790E+03 3.979E+01 6.370E+06 2.129E+07</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">1.148E+01 2.796E+01 4.218E+01 4.016E+01 5.831E+01 4.576E+01</cell></row><row><cell></cell><cell cols="7">DMSPSO 2.226E+06 2.721E+07 7.289E+07 2.226E+06 1.768E+07 4.103E+07</cell></row><row><cell>F6</cell><cell>FIPS</cell><cell cols="6">9.832E+06 2.457E+07 3.493E+07 6.483E+07 8.021E+07 6.118E+07</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">6.826E+06 1.187E+07 1.355E+07 1.160E+06 2.731E+06 3.667E+06</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">7.369E+00 1.779E+01 2.285E+01 8.998E+01 8.705E+01 3.757E+01</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">1.472E+01 3.978E+01 5.708E+01 3.053E+01 5.008E+01 4.440E+01</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">6.788E+03 6.780E+03 1.291E+02 6.158E+03 6.154E+03 7.416E+01</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">4.696E+03 4.696E+03 5.039E-01 6.195E+03 6.197E+03 4.553E+00</cell></row><row><cell></cell><cell cols="7">DMSPSO 4.297E+03 4.335E+03 2.190E+02 6.029E+03 6.050E+03 1.312E+02</cell></row><row><cell>F7</cell><cell>FIPS</cell><cell cols="6">7.507E+03 7.477E+03 2.158E+02 1.037E+04 1.036E+04 2.122E+02</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">7.513E+03 7.524E+03 3.409E+02 7.419E+03 7.420E+03 3.034E+02</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">4.696E+03 4.696E+03 1.837E-12 6.195E+03 6.195E+03 4.594E-12</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">2.940E-02 7.610E-02 9.962E-02 5.569E-01 5.444E-01 2.253E-01</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">2.090E+01 2.090E+01 5.354E-02 2.114E+01 2.113E+01 4.368E-02</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">2.095E+01 2.094E+01 5.696E-02 2.115E+01 2.114E+01 2.978E-02</cell></row><row><cell></cell><cell cols="7">DMSPSO 2.093E+01 2.093E+01 6.189E-02 2.113E+01 2.113E+01 3.770E-02</cell></row><row><cell>F8</cell><cell>FIPS</cell><cell cols="6">2.095E+01 2.094E+01 6.409E-02 2.115E+01 2.114E+01 4.304E-02</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">2.096E+01 2.095E+01 5.009E-02 2.094E+01 2.093E+01 5.023E-02</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">2.072E+01 2.072E+01 5.905E-02 2.105E+01 2.104E+01 4.617E-02</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">2.095E+01 2.094E+01 4.214E-02 2.115E+01 2.114E+01 3.766E-02</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">6.517E+01 6.543E+01 1.239E+01 1.782E+02 1.765E+02 2.498E+01</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">5.622E+01 5.635E+01 1.079E+01 1.338E+02 1.329E+02 2.131E+01</cell></row><row><cell></cell><cell cols="7">DMSPSO 4.524E+01 4.848E+01 1.499E+01 1.006E+02 9.893E+01 2.169E+01</cell></row><row><cell>F9</cell><cell>FIPS</cell><cell cols="6">5.401E+01 5.395E+01 1.097E+01 1.550E+02 1.530E+02 1.791E+01</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">7.719E+01 7.839E+01 1.689E+01 6.326E+01 6.520E+01 1.764E+01</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">0.000E+00 0.000E+00 0.000E+00 0.000E+00 0.000E+00 0.000E+00</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">3.681E+01 3.754E+01 9.353E+00 8.955E+01 9.034E+01 2.037E+01</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">8.756E+01 8.665E+01 1.850E+01 1.837E+02 1.816E+02 3.686E+01</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">7.213E+01 7.556E+01 1.919E+01 1.691E+02 1.755E+02 4.101E+01</cell></row><row><cell></cell><cell cols="7">DMSPSO 7.797E+01 7.999E+01 2.003E+01 1.673E+02 1.662E+02 2.167E+01</cell></row><row><cell>F10</cell><cell>FIPS</cell><cell cols="6">1.545E+02 1.525E+02 2.533E+01 3.868E+02 3.928E+02 3.625E+01</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">1.526E+02 1.589E+02 5.514E+01 1.453E+02 1.442E+02 4.564E+01</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">8.008E+01 8.023E+01 1.495E+01 2.183E+02 2.173E+02 2.000E+01</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">4.577E+01 5.192E+01 2.669E+01 8.855E+01 1.041E+02 5.751E+01</cell></row></table><note><p>the result that is one order better than all the other variants. For function F 15 ,</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Median, Mean and Standard Deviation for 30-Dimensional and 50-Dimensional of CEC 2005 Benchmark Functions F 11 to F 15<ref type="bibr" target="#b15">16</ref> , where SRPSO results are one order better than that of all the other variants. Based on the mean performance, one can say that SRPSO performs marginally better in at least three out of the five functions in both the 30-dimensional and 50-dimensional cases.Finally, the results for the last five more complex hybrid composition benchmark functions F 21 to F 25 are given in table 7. From the table, one can note that CLPSO and SRPSO are the two top performing algorithms for this group.</figDesc><table><row><cell cols="2">Func. Algorithm</cell><cell>Median</cell><cell>30-Dimensional Mean</cell><cell>StD.</cell><cell>Median</cell><cell>50-Dimensional Mean</cell><cell>STD.</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">2.802E+01 2.797E+01 2.487E+00 5.874E+01 5.817E+01 3.433E+00</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">2.790E+01 2.802E+01 1.926E+00 5.483E+01 5.471E+01 3.821E+00</cell></row><row><cell></cell><cell cols="7">DMSPSO 2.929E+01 2.903E+01 2.259E+00 5.795E+01 5.774E+01 2.256E+00</cell></row><row><cell>F11</cell><cell>FIPS</cell><cell cols="6">2.662E+01 2.688E+01 2.641E+00 5.363E+01 5.343E+01 3.789E+00</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">3.164E+01 3.140E+01 4.692E+00 2.910E+01 2.954E+01 4.439E+00</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">2.548E+01 2.526E+01 1.854E+00 5.263E+01 5.268E+01 2.212E+00</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">9.080E+00 9.583E+00 4.273E+00 2.172E+01 2.195E+01 5.652E+00</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">1.128E+04 1.872E+04 2.137E+04 2.896E+05 3.293E+05 1.922E+05</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">1.590E+03 2.585E+03 2.746E+03 1.447E+04 1.505E+04 9.270E+03</cell></row><row><cell></cell><cell cols="7">DMSPSO 5.375E+04 7.843E+04 6.836E+04 1.212E+05 1.659E+05 1.461E+05</cell></row><row><cell>F12</cell><cell>FIPS</cell><cell cols="6">4.679E+04 5.185E+04 3.213E+04 2.771E+05 2.929E+05 1.490E+05</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">7.752E+04 8.984E+04 5.430E+04 6.052E+04 7.135E+04 4.785E+04</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">1.293E+04 1.324E+04 4.162E+03 8.996E+04 8.949E+04 2.001E+04</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">1.642E+03 2.495E+03 2.804E+03 6.996E+03 1.183E+04 1.215E+04</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">5.389E+00 5.691E+00 1.775E+00 1.471E+01 1.543E+01 4.475E+00</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">6.252E+00 6.503E+00 1.855E+00 1.763E+01 1.839E+01 4.973E+00</cell></row><row><cell></cell><cell cols="7">DMSPSO 9.962E+00 1.127E+01 5.622E+00 7.812E+00 8.219E+00 2.218E+00</cell></row><row><cell>F13</cell><cell>FIPS</cell><cell cols="6">9.604E+00 9.641E+00 1.730E+00 2.583E+01 2.638E+01 3.451E+00</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">8.489E+00 9.231E+00 4.563E+00 6.236E+00 6.478E+00 2.102E+00</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">1.979E+00 1.888E+00 3.977E-01 7.093E+00 7.074E+00 6.947E-01</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">2.508E+00 2.631E+00 6.148E-01 5.222E+00 5.237E+00 1.011E+00</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">1.211E+01 1.205E+01 4.311E-01 2.193E+01 2.190E+01 4.937E-01</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">1.237E+01 1.229E+01 3.984E-01 2.223E+01 2.209E+01 4.659E-01</cell></row><row><cell></cell><cell cols="7">DMSPSO 1.212E+01 1.207E+01 6.594E-01 2.246E+01 2.241E+01 2.289E-01</cell></row><row><cell>F14</cell><cell>FIPS</cell><cell cols="6">1.237E+01 1.234E+01 3.198E-01 2.196E+01 2.190E+01 3.078E-01</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">1.289E+01 1.283E+01 4.178E-01 1.282E+01 1.274E+01 4.817E-01</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">1.248E+01 1.248E+01 3.051E-01 2.214E+01 2.212E+01 2.642E-01</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">1.185E+01 1.182E+01 4.856E-01 2.124E+01 2.122E+01 4.793E-01</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">4.036E+02 3.929E+02 8.708E+01 4.513E+02 4.198E+02 8.718E+01</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">3.033E+02 3.249E+02 8.537E+01 2.511E+02 2.834E+02 8.431E+01</cell></row><row><cell></cell><cell cols="7">DMSPSO 5.105E+02 5.222E+02 8.016E+01 3.694E+02 3.778E+02 6.679E+01</cell></row><row><cell>F15</cell><cell>FIPS</cell><cell cols="6">4.536E+02 4.556E+02 8.414E+01 5.175E+02 5.174E+02 5.406E+01</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">5.373E+02 5.305E+02 9.060E+01 5.087E+02 4.843E+02 1.137E+02</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">4.116E+01 5.623E+01 5.212E+01 1.301E+02 1.422E+02 5.276E+01</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">3.000E+02 2.870E+02 1.317E+02 3.131E+02 3.063E+02 1.061E+02</cell></row><row><cell cols="8">especially for function F Out of the five functions, SRPSO is better than all other variants in two func-</cell></row></table><note><p>tions (F 22 and F 25 ) and CLSPO is better in three functions, viz., (F 21 , F 23 and</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Median, Mean and Standard Deviation for 30-Dimensional and 50-Dimensional of CEC 2005 Benchmark Functions F 16 to F 20</figDesc><table><row><cell cols="2">Func. Algorithm</cell><cell>Median</cell><cell>30-Dimensional Mean</cell><cell>StD.</cell><cell>Median</cell><cell>50-Dimensional Mean</cell><cell>STD.</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">1.512E+02 1.867E+02 1.055E+02 1.679E+02 1.872E+02 5.268E+01</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">1.187E+02 1.356E+02 5.300E+01 1.318E+02 1.408E+02 3.960E+01</cell></row><row><cell></cell><cell cols="7">DMSPSO 2.250E+02 2.916E+02 1.683E+02 1.419E+02 1.670E+02 8.193E+01</cell></row><row><cell>F16</cell><cell>FIPS</cell><cell cols="6">3.271E+02 3.414E+02 1.081E+02 3.227E+02 3.296E+02 6.967E+01</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">3.827E+02 3.865E+02 1.416E+02 2.909E+02 3.287E+02 1.336E+02</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">1.413E+02 1.453E+02 3.171E+01 1.967E+02 1.969E+02 3.751E+01</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">8.388E+01 1.783E+02 1.723E+02 8.372E+01 1.504E+02 1.276E+02</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">1.881E+02 2.136E+02 8.914E+01 2.834E+02 2.890E+02 7.083E+01</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">1.580E+02 1.737E+02 6.599E+01 2.038E+02 2.099E+02 4.542E+01</cell></row><row><cell></cell><cell cols="7">DMSPSO 2.300E+02 2.988E+02 1.675E+02 2.163E+02 2.413E+02 7.257E+01</cell></row><row><cell>F17</cell><cell>FIPS</cell><cell cols="6">4.333E+02 4.502E+02 1.420E+02 4.371E+02 4.576E+02 9.022E+01</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">3.486E+02 3.875E+02 1.322E+02 3.100E+02 3.497E+02 1.259E+02</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">2.084E+02 2.134E+02 3.624E+01 2.767E+02 2.822E+02 3.860E+01</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">1.099E+02 1.900E+02 1.629E+02 1.605E+02 2.101E+02 1.353E+02</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">9.746E+02 9.388E+02 7.088E+01 9.376E+02 9.392E+02 8.816E+00</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">9.270E+02 9.101E+02 4.536E+01 9.928E+02 9.935E+02 2.367E+01</cell></row><row><cell></cell><cell cols="7">DMSPSO 9.249E+02 9.372E+02 3.011E+01 9.300E+02 9.334E+02 1.156E+01</cell></row><row><cell>F18</cell><cell>FIPS</cell><cell cols="6">1.055E+03 1.052E+03 2.219E+01 1.070E+03 1.069E+03 1.346E+01</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">1.051E+03 1.047E+03 3.627E+01 1.035E+03 1.033E+03 3.041E+01</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">9.132E+02 8.993E+02 7.031E+01 9.430E+02 9.414E+02 1.894E+01</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">8.280E+02 8.279E+02 1.706E+00 8.456E+02 8.473E+02 1.019E+01</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">9.761E+02 9.355E+02 6.813E+01 9.346E+02 9.383E+02 1.234E+01</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">9.247E+02 9.209E+02 3.222E+01 9.866E+02 9.913E+02 1.812E+01</cell></row><row><cell></cell><cell cols="7">DMSPSO 9.191E+02 9.328E+02 2.703E+01 9.297E+02 9.315E+02 9.374E+00</cell></row><row><cell>F19</cell><cell>FIPS</cell><cell cols="6">1.047E+03 1.049E+03 1.873E+01 1.070E+03 1.070E+03 1.603E+01</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">1.040E+03 1.049E+03 4.636E+01 1.027E+03 1.028E+03 3.344E+01</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">9.140E+02 9.102E+02 1.853E+01 9.435E+02 9.418E+02 1.317E+01</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">8.281E+02 8.282E+02 1.619E+00 8.455E+02 8.461E+02 3.846E+00</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">9.756E+02 9.553E+02 5.665E+01 9.371E+02 9.393E+02 1.197E+01</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">9.247E+02 9.167E+02 3.558E+01 9.868E+02 9.890E+02 2.113E+01</cell></row><row><cell></cell><cell cols="7">DMSPSO 9.281E+02 9.394E+02 2.991E+01 9.299E+02 9.303E+02 8.262E+00</cell></row><row><cell>F20</cell><cell>FIPS</cell><cell cols="6">1.049E+03 1.050E+03 1.811E+01 1.062E+03 1.065E+03 1.335E+01</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">1.043E+03 1.044E+03 2.626E+01 1.027E+03 1.026E+03 2.788E+01</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">9.132E+02 9.119E+02 8.572E+00 9.430E+02 9.438E+02 4.918E+00</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">8.281E+02 8.282E+02 1.637E+00 8.455E+02 8.455E+02 3.826E+00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Median, Mean and Standard Deviation for 30-Dimensional and 50-Dimensional of CEC 2005 Benchmark Functions F 21 to F 25</figDesc><table><row><cell cols="2">Func. Algorithm</cell><cell>Median</cell><cell>30-Dimensional Mean</cell><cell>StD.</cell><cell>Median</cell><cell>50-Dimensional Mean</cell><cell>STD.</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">5.098E+02 5.893E+02 2.082E+02 1.018E+03 1.019E+03 3.643E+00</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">5.000E+02 5.060E+02 4.243E+01 5.000E+02 5.199E+02 1.063E+02</cell></row><row><cell></cell><cell cols="7">DMSPSO 1.098E+03 1.037E+03 1.558E+02 1.011E+03 1.011E+03 2.700E+00</cell></row><row><cell>F21</cell><cell>FIPS</cell><cell cols="6">1.172E+03 1.093E+03 1.633E+02 1.209E+03 1.196E+03 5.787E+01</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">1.162E+03 1.021E+03 2.099E+02 7.525E+02 8.542E+02 2.499E+02</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">5.000E+02 5.000E+02 0.000E+00 5.000E+02 5.000E+02 0.000E+00</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">5.000E+02 5.855E+02 1.529E+02 7.212E+02 6.757E+02 1.059E+02</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">1.024E+03 1.026E+03 2.429E+01 9.095E+02 9.149E+02 2.018E+01</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">9.649E+02 9.675E+02 2.823E+01 1.006E+03 1.006E+03 1.564E+01</cell></row><row><cell></cell><cell cols="7">DMSPSO 9.261E+02 9.344E+02 5.295E+01 8.997E+02 9.059E+02 1.972E+01</cell></row><row><cell>F22</cell><cell>FIPS</cell><cell cols="6">1.121E+03 1.126E+03 2.782E+01 1.200E+03 1.202E+03 2.191E+01</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">1.106E+03 1.109E+03 4.488E+01 1.085E+03 1.086E+03 4.747E+01</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">9.603E+02 9.609E+02 1.477E+01 9.912E+02 9.917E+02 7.240E+00</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">5.194E+02 5.195E+02 2.312E+00 5.002E+02 5.002E+02 4.391E-02</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">5.068E+02 5.277E+02 1.018E+02 1.019E+03 1.019E+03 3.335E+00</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">5.000E+02 5.653E+02 1.887E+02 5.000E+02 5.000E+02 0.000E+00</cell></row><row><cell></cell><cell cols="7">DMSPSO 1.097E+03 1.063E+03 1.192E+02 1.011E+03 1.011E+03 2.830E+00</cell></row><row><cell>F23</cell><cell>FIPS</cell><cell cols="6">1.177E+03 1.072E+03 1.936E+02 1.210E+03 1.191E+03 9.395E+01</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">1.156E+03 1.030E+03 2.002E+02 1.049E+03 9.335E+02 2.551E+02</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">5.000E+02 5.000E+02 0.000E+00 5.000E+02 5.000E+02 0.000E+00</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">7.012E+02 7.020E+02 2.329E+00 7.074E+02 7.083E+02 4.471E+00</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">2.000E+02 2.000E+02 0.000E+00 1.029E+03 1.018E+03 5.740E+01</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">2.000E+02 2.000E+02 0.000E+00 2.000E+02 2.211E+02 1.374E+02</cell></row><row><cell></cell><cell cols="7">DMSPSO 9.769E+02 9.851E+02 5.687E+01 1.025E+03 1.025E+03 2.067E+00</cell></row><row><cell>F24</cell><cell>FIPS</cell><cell cols="6">1.268E+03 1.254E+03 5.409E+01 1.282E+03 1.283E+03 1.049E+01</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">1.141E+03 9.806E+02 3.183E+02 5.298E+02 6.952E+02 3.888E+02</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">2.000E+02 2.000E+02 0.000E+00 2.000E+02 2.000E+02 4.950E-03</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">2.136E+02 2.265E+02 1.047E+02 2.310E+02 2.405E+02 8.591E+01</cell></row><row><cell></cell><cell>χPSO</cell><cell cols="6">1.750E+03 1.750E+03 7.509E+00 1.682E+03 1.682E+03 5.316E+00</cell></row><row><cell></cell><cell>BBPSO</cell><cell cols="6">1.669E+03 1.668E+03 7.609E+00 1.724E+03 1.724E+03 6.689E+00</cell></row><row><cell></cell><cell cols="7">DMSPSO 1.639E+03 1.640E+03 8.368E+00 1.675E+03 1.676E+03 4.880E+00</cell></row><row><cell>F25</cell><cell>FIPS</cell><cell cols="6">1.780E+03 1.781E+03 1.046E+01 1.866E+03 1.866E+03 7.076E+00</cell></row><row><cell></cell><cell>UPSO</cell><cell cols="6">1.778E+03 1.778E+03 1.256E+01 1.769E+03 1.771E+03 1.389E+01</cell></row><row><cell></cell><cell>CLPSO</cell><cell cols="6">1.659E+03 1.659E+03 4.102E+00 1.701E+03 1.702E+03 2.610E+00</cell></row><row><cell></cell><cell>SRPSO</cell><cell cols="6">1.247E+03 1.113E+03 3.227E+02 1.288E+03 1.292E+03 3.059E+01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>Rank Table for the Median values of 30-Dimensional and 50-Dimensional Cases</figDesc><table><row><cell cols="2">Dim Algo.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">Individual Ranking of Benchmark Functions</cell><cell>Avg.</cell></row><row><cell></cell><cell></cell><cell cols="10">F1 F2 F3 F4 F5 F6 F7 F8 F9 F10 F11 F12 F13 F14 F15 F16 F17 F18 F19 F20 F21 F22 F23 F24 F25 RANK(R)</cell></row><row><cell></cell><cell>χPSO</cell><cell>4 1</cell><cell>3</cell><cell>3</cell><cell>5</cell><cell>4</cell><cell>5</cell><cell>2</cell><cell>6</cell><cell>5 5 3 3 2 4 4 3 5 5 5 4 5 3 1 5</cell><cell>3.8(4)</cell></row><row><cell></cell><cell cols="2">BBPSO 1 3</cell><cell>2</cell><cell>4</cell><cell>4</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>2 4 1 4 4 3 2 2 4 4 3 1 4 1 1 4</cell><cell>2.88(3)</cell></row><row><cell></cell><cell cols="2">DMSPSO 5 4</cell><cell>4</cell><cell>2</cell><cell>3</cell><cell>5</cell><cell>2</cell><cell>3</cell><cell>3</cell><cell>3 6 6 7 3 6 5 5 3 3 4 5 2 5 5 2</cell><cell>4.04(5)</cell></row><row><cell>30</cell><cell>FIPS</cell><cell>6 7</cell><cell>6</cell><cell>7</cell><cell>6</cell><cell>7</cell><cell>6</cell><cell>4</cell><cell>4</cell><cell>7 3 5 6 5 5 6 7 7 7 7 7 7 7 7 7</cell><cell>6.12(6)</cell></row><row><cell></cell><cell>UPSO</cell><cell>7 6</cell><cell>7</cell><cell>6</cell><cell>7</cell><cell>6</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>6 7 7 5 6 7 7 6 6 6 6 6 6 6 6 6</cell><cell>6.36(7)</cell></row><row><cell></cell><cell cols="2">CLPSO 1 5</cell><cell>5</cell><cell>5</cell><cell>2</cell><cell>1</cell><cell>4</cell><cell>1</cell><cell>1</cell><cell>4 2 4 1 7 1 3 4 2 2 2 1 3 1 1 3</cell><cell>2.64(2)</cell></row><row><cell></cell><cell cols="2">SRPSO 1 1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>3</cell><cell>1</cell><cell>4</cell><cell>2</cell><cell>1 1 2 2 1 2 1 1 1 1 1 1 1 4 4 1</cell><cell>1.6(1)</cell></row><row><cell></cell><cell>χPSO</cell><cell>4 2</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>7</cell><cell>5 7 7 5 3 5 4 5 3 3 3 6 3 5 6 3</cell><cell>4.28(5)</cell></row><row><cell></cell><cell cols="2">BBPSO 1 3</cell><cell>2</cell><cell>5</cell><cell>6</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>5</cell><cell>4 5 2 6 6 2 1 1 5 5 5 1 5 1 1 5</cell><cell>3.56(2)</cell></row><row><cell></cell><cell cols="2">DMSPSO 5 4</cell><cell>3</cell><cell>2</cell><cell>2</cell><cell>6</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>3 6 5 4 7 4 3 3 2 2 2 5 2 4 5 2</cell><cell>3.6(4)</cell></row><row><cell>50</cell><cell>FIPS</cell><cell>7 7</cell><cell>7</cell><cell>6</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>5</cell><cell>6</cell><cell>7 4 6 7 4 7 7 7 7 7 7 7 7 7 7 7</cell><cell>6.56(7)</cell></row><row><cell></cell><cell>UPSO</cell><cell>6 5</cell><cell>5</cell><cell>3</cell><cell>5</cell><cell>5</cell><cell>6</cell><cell>1</cell><cell>2</cell><cell>2 2 3 2 1 6 6 6 6 6 6 4 6 6 4 6</cell><cell>4.4(6)</cell></row><row><cell></cell><cell cols="2">CLPSO 1 6</cell><cell>6</cell><cell>7</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>2</cell><cell>1</cell><cell>6 3 4 3 5 1 5 4 4 4 4 1 4 1 1 4</cell><cell>3.56(2)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 :</head><label>9</label><figDesc>Rank Table for the Mean values of 30-Dimensional and 50-Dimensional</figDesc><table><row><cell cols="2">Dim Algo.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="13">Individual Ranking of Benchmark Functions</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Avg.</cell></row><row><cell></cell><cell></cell><cell cols="27">F1 F2 F3 F4 F5 F6 F7 F8 F9 F10 F11 F12 F13 F14 F15 F16 F17 F18 F19 F20 F21 F22 F23 F24 F25 RANK(R)</cell></row><row><cell></cell><cell>χPSO</cell><cell>4</cell><cell>3</cell><cell>4</cell><cell cols="2">3</cell><cell>5</cell><cell>4</cell><cell>5</cell><cell>2</cell><cell>6</cell><cell>5</cell><cell>4</cell><cell>4</cell><cell>3</cell><cell>2</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>5</cell><cell>5</cell><cell>5</cell><cell>4</cell><cell>5</cell><cell>2</cell><cell>1</cell><cell>5</cell><cell>3.92(4)</cell></row><row><cell></cell><cell>BBPSO</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell cols="2">4</cell><cell>4</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>2</cell><cell>5</cell><cell>2</cell><cell>4</cell><cell>4</cell><cell>3</cell><cell>1</cell><cell>1</cell><cell>3</cell><cell>3</cell><cell>3</cell><cell>2</cell><cell>4</cell><cell>3</cell><cell>1</cell><cell>4</cell><cell>2.88(3)</cell></row><row><cell></cell><cell cols="2">DMSPSO 5</cell><cell>5</cell><cell>3</cell><cell cols="2">2</cell><cell>3</cell><cell>7</cell><cell>2</cell><cell>3</cell><cell>3</cell><cell>3</cell><cell>6</cell><cell>6</cell><cell>7</cell><cell>3</cell><cell>6</cell><cell>5</cell><cell>5</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>5</cell><cell>2</cell><cell>6</cell><cell>6</cell><cell>2</cell><cell>4.28(5)</cell></row><row><cell>30</cell><cell>FIPS</cell><cell>6</cell><cell>7</cell><cell>6</cell><cell cols="2">7</cell><cell>6</cell><cell>6</cell><cell>6</cell><cell>4</cell><cell>4</cell><cell>6</cell><cell>3</cell><cell>5</cell><cell>6</cell><cell>5</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>7</cell><cell>6</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>6(6)</cell></row><row><cell></cell><cell>UPSO</cell><cell>7</cell><cell>6</cell><cell>7</cell><cell cols="2">6</cell><cell>7</cell><cell>5</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>5</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>6</cell><cell>6</cell><cell>7</cell><cell>6</cell><cell>5</cell><cell>6</cell><cell>5</cell><cell>5</cell><cell>6</cell><cell>6.32(7)</cell></row><row><cell></cell><cell>CLPSO</cell><cell>1</cell><cell>4</cell><cell>5</cell><cell cols="2">5</cell><cell>2</cell><cell>1</cell><cell>4</cell><cell>1</cell><cell>1</cell><cell>4</cell><cell>2</cell><cell>3</cell><cell>1</cell><cell>6</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>1</cell><cell>3</cell><cell>1</cell><cell>1</cell><cell>3</cell><cell>2.44(2)</cell></row><row><cell></cell><cell>SRPSO</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell cols="2">1</cell><cell>1</cell><cell>3</cell><cell>1</cell><cell>4</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>2</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>3</cell><cell>1</cell><cell>4</cell><cell>4</cell><cell>1</cell><cell>1.76(1)</cell></row><row><cell></cell><cell>χPSO</cell><cell>4</cell><cell>3</cell><cell>4</cell><cell cols="2">4</cell><cell>4</cell><cell>5</cell><cell>3</cell><cell>3</cell><cell>7</cell><cell>5</cell><cell>7</cell><cell>7</cell><cell>5</cell><cell>3</cell><cell>5</cell><cell>4</cell><cell>5</cell><cell>3</cell><cell>3</cell><cell>3</cell><cell>6</cell><cell>3</cell><cell>6</cell><cell>5</cell><cell>3</cell><cell>4.4(6)</cell></row><row><cell></cell><cell>BBPSO</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell cols="2">5</cell><cell>6</cell><cell>2</cell><cell>5</cell><cell>5</cell><cell>5</cell><cell>4</cell><cell>5</cell><cell>2</cell><cell>6</cell><cell>5</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>5</cell><cell>5</cell><cell>5</cell><cell>2</cell><cell>5</cell><cell>1</cell><cell>2</cell><cell>5</cell><cell>3.56(3)</cell></row><row><cell></cell><cell cols="2">DMSPSO 5</cell><cell>4</cell><cell>3</cell><cell cols="2">2</cell><cell>2</cell><cell>6</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>3</cell><cell>6</cell><cell>5</cell><cell>4</cell><cell>7</cell><cell>4</cell><cell>3</cell><cell>3</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>5</cell><cell>2</cell><cell>5</cell><cell>6</cell><cell>2</cell><cell>3.68(4)</cell></row><row><cell>50</cell><cell>FIPS</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell cols="2">6</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>4</cell><cell>6</cell><cell>7</cell><cell>4</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>6.56(7)</cell></row><row><cell></cell><cell>UPSO</cell><cell>6</cell><cell>5</cell><cell>6</cell><cell cols="2">3</cell><cell>5</cell><cell>4</cell><cell>6</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>3</cell><cell>2</cell><cell>1</cell><cell>6</cell><cell>6</cell><cell>6</cell><cell>6</cell><cell>6</cell><cell>6</cell><cell>4</cell><cell>6</cell><cell>4</cell><cell>4</cell><cell>6</cell><cell>4.32(5)</cell></row><row><cell></cell><cell>CLPSO</cell><cell>1</cell><cell>6</cell><cell>5</cell><cell cols="2">7</cell><cell>3</cell><cell>3</cell><cell>4</cell><cell>2</cell><cell>1</cell><cell>6</cell><cell>3</cell><cell>4</cell><cell>3</cell><cell>6</cell><cell>1</cell><cell>5</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>1</cell><cell>4</cell><cell>1</cell><cell>1</cell><cell>4</cell><cell>3.48(2)</cell></row><row><cell></cell><cell>SRPSO</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell cols="2">1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>5</cell><cell>3</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>2</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>3</cell><cell>1</cell><cell>3</cell><cell>3</cell><cell>1</cell><cell>1.68(1)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>15</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Rank1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Rank2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">5 10 Number of Occurence</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Rank3 Rank4 Rank5 Rank6 Rank7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell>χPSO</cell><cell></cell><cell cols="4">BBPSO DMSPSO</cell><cell>FIPS</cell><cell></cell><cell>UPSO</cell><cell></cell><cell cols="2">CLPSO</cell><cell cols="2">SRPSO</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(a)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>18</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Rank1 Rank2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Number of Occurence</cell><cell>4 6 8 10 12 14 16</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Rank3 Rank4 Rank5 Rank6 Rank7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell>χPSO</cell><cell></cell><cell cols="4">BBPSO DMSPSO</cell><cell>FIPS</cell><cell></cell><cell>UPSO</cell><cell></cell><cell cols="2">CLPSO</cell><cell cols="2">SRPSO</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(b)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 :</head><label>10</label><figDesc>Average Rank Difference and Statistics for α = 0.05 significance level</figDesc><table><row><cell>Avg Rank differ-ence w.r.t. SRPSO</cell><cell cols="4">30D Median 30D Mean 50D Median 50D Mean</cell></row><row><cell>χPSO</cell><cell>2.2</cell><cell>2.16</cell><cell>2.68</cell><cell>2.72</cell></row><row><cell>BBPSO</cell><cell>1.28</cell><cell>1.12</cell><cell>1.96</cell><cell>1.88</cell></row><row><cell></cell><cell>2.44</cell><cell>2.52</cell><cell>2.0</cell><cell>2.0</cell></row><row><cell>FIPS</cell><cell>4.52</cell><cell>4.24</cell><cell>4.96</cell><cell>4.88</cell></row><row><cell>UPSO</cell><cell>4.76</cell><cell>4.56</cell><cell>2.8</cell><cell>2.64</cell></row><row><cell>CLPSO</cell><cell>1.04</cell><cell>0.68</cell><cell>1.96</cell><cell>1.8</cell></row><row><cell>F-score (Friedman)</cell><cell>44.4071</cell><cell>41.1826</cell><cell>20.2696</cell><cell>19.3138</cell></row><row><cell>Critical Difference (Benforroni-Dunn)</cell><cell>0.7249</cell><cell>0.7442</cell><cell>0.9037</cell><cell>0.9139</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>If one compares the velocity update equations of PSO given in equation 1 and SRPSO given in equation 9 and 10, it can be seen that SRPSO has the same order of complexity as that of PSO. The order of complexity of the selected variants and SRPSO is compared in table 11. The table contains the order of complexity in terms of O notation for the process of initialization, evaluation and update and finally the overall complexity of each of the algorithms. In the table N, n and D represent the population size, number of neighbors and the total dimensions respectively. From the table, it may be noted that SRPSO has not increased the order of complexity of the PSO algorithm at any stage and hence has the overall complexity of O(ND).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 11 :</head><label>11</label><figDesc>Order of Complexity of the PSO variants</figDesc><table><row><cell cols="2">Algorithm Initialize</cell><cell>Evaluate</cell><cell>Update</cell><cell>Overall</cell></row><row><cell>χPSO</cell><cell>O(ND)</cell><cell>O(ND)</cell><cell>O(ND)</cell><cell>O(ND)</cell></row><row><cell>BBPSO</cell><cell>O(ND)</cell><cell>O(ND)</cell><cell>O(ND)</cell><cell>O(ND)</cell></row><row><cell cols="5">DMSPSO O(ND) O(ND+NnD) O(ND+NnD) O(NnD)</cell></row><row><cell>FIPS</cell><cell>O(ND)</cell><cell>O(ND)</cell><cell>O(ND)</cell><cell>O(ND)</cell></row><row><cell>UPSO</cell><cell>O(ND)</cell><cell>O(ND)</cell><cell cols="2">O(ND+NnD) O(NnD)</cell></row><row><cell>CLPSO</cell><cell>O(ND)</cell><cell>O(ND)</cell><cell>O(ND)</cell><cell>O(ND)</cell></row><row><cell>SRPSO</cell><cell>O(ND)</cell><cell>O(ND)</cell><cell>O(ND)</cell><cell>O(ND)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head></head><label></label><figDesc>(b), the faster convergence characteristics of the SRPSO are shown as all the functions converge to a point in a significantly lesser number of function evaluations. By observing the results of these functions provided in table4 and table 5, it is evident that SRPSO is providing convergence closer to the optimum solution. The same is also indicted in the rank based analysis of mean values in table9. From the table, the average rank in basic multimodal functions for SRPSO is 2 whereas for all the other algorithms the average rank is greater than that of SRPSO. Based on these observations, one can conclude that the performance of SRPSO shown in figure6(b) is closer to optimum value with faster convergence characteristics.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 12 :</head><label>12</label><figDesc>Mean and StD. fitness values for 20-Dimensional spread spectrum radar polyphase code design problem FIPS UPSO CLPSO TPLPSO SRPSO Mean 1.04E+00 1.40E+00 1.08E+00 9.28E-01 5.09E-01 St.D 1.47E-01 2.06E-01 7.81E-02 1.41E-01 3.73E-02</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors thank the reviewers for their valuable comments/suggestions which helped to improve the quality of this paper significantly. The first and second author would like to thank the funding agency 'Nanyang Technological University-Ministry of Defence', Singapore (Grant No: MINDEF-NTU-JPP/13/02/01) for the financial support to conduct the study.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A review of particle swarm optimization. PartII: Hybridization, combinatorial, multicriteria and constrained optimization and indicative applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Banks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Anyakoha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Computing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Chaos embedded particle swarm optimization algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Alatas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Akin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Ozer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chaos, Solitons and Fractals</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1715" to="1734" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fuzzy adaptive particle swarm optimization for bidding strategy in uniform price spot market</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bajpai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Power systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2152" to="2160" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Particle swarm optimization algorithm with asymmetric time-varying acceleration coefficients</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Q</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE International Conference on robotics and biomimetics</title>
		<meeting>of IEEE International Conference on robotics and biomimetics</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2134" to="2139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">CAPSO: centripetal accelerated particle swarm optimization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Beheshti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Hj Shamsuddin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">258</biblScope>
			<biblScope unit="page" from="54" to="79" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A cooperative approach to particle swarm optimization</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V D</forename><surname>Bergh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Engelbrecht</surname></persName>
		</author>
		<author>
			<persName><surname>Andries</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="225" to="239" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Self-Regulated Cognition: Interdependence of Metacognition</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Borkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rellinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pressley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dimensions of Thinking and Cognitive Instruction</title>
		<imprint>
			<biblScope unit="page">53</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An efficient particle swarm optimization approach to cluster short texts</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cagnina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Errecalde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ingaramo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">265</biblScope>
			<biblScope unit="page" from="36" to="49" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Behavioral analysis of the leader particle during stagnation in a particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">279</biblScope>
			<biblScope unit="page" from="18" to="36" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Particle swarm optimization with an aging leader and challengers</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="258" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">AHPS 2 : An optimizer using adaptive heterogeneous particle swarms</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Weir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">280</biblScope>
			<biblScope unit="page" from="26" to="52" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The particle swarm -Explosion, stability, and convergence in a multidimensional complex space</title>
		<author>
			<persName><forename type="first">M</forename><surname>Clerc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="58" to="73" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Particle swarm optimization: basic concepts, variants and applications in power systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Del Valle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Venayagamoorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohagheghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Harley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="171" to="195" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Statistical comparisons of classifiers over multiple data sets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Demšar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A particle swarm optimization using local stochastic search and enhancing diversity for continuous optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page" from="261" to="267" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A method of spread-spectrum radar polyphase code design</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dukic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dobrosavljevic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on Selected Areas in Communications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="748" to="749" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Particle swarm optimization: developments, applications and resources</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Cong. on Evolutionary Computation</title>
		<meeting>of Cong. on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="81" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Computational intelligence: An introduction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Engelbrecht</surname></persName>
		</author>
		<author>
			<persName><surname>Andries</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>John Wiley and Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Evolving cognitive and social experience in Particle Swarm Optimization through Differential Evolution: A hybrid approach</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Epitropakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">P</forename><surname>Plagianakos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Vrahatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">216</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="92" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A survey of the state of the art in particle swarm optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shareef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Khajehzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research Journal of Applied Sciences, Engineering and Technology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1181" to="1197" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A novel particle swarm optimization based on the selfadaptation strategy of acceleration coefficients</title>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Int. Conf. on Computational intelligence and security</title>
		<meeting>of the IEEE Int. Conf. on Computational intelligence and security</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="277" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A novel particle swarm optimization algorithm with levy flight</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hakli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Uǧuz</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.asoc.2014.06.034</idno>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Comparison study of several kinds of inertia weight for PSO</title>
		<author>
			<persName><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Int. Conf. on progress in informatics and computing</title>
		<meeting>of the IEEE Int. Conf. on progress in informatics and computing</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="280" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">PSOSA: An optimised particle swarm technique for solving the urban planning problem</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Fayek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Shaheen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Int. Conf. of Computer Engineering and systems</title>
		<meeting>of the IEEE Int. Conf. of Computer Engineering and systems</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="401" to="405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Particle swarm optimization with Gaussian mutation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Higashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE SIS</title>
		<meeting>of IEEE SIS</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="72" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A particle swarm optimizer for grouping problems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Husseinzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Husseinzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karimiyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">252</biblScope>
			<biblScope unit="page" from="81" to="95" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A hierarchical particle swarm optimizer and its adaptive variant</title>
		<author>
			<persName><forename type="first">S</forename><surname>Janson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Middendorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Systems, Man, and Cybernetics, Part B: Cybernetics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1272" to="1282" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Exponential inertia weight particle swarm algorithm for dynamic optimization of electromechanical coupling system</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jianxin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">X</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Weiguo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Rui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Int. Conf. on Intelligent computing and intelligent systems</title>
		<meeting>of the IEEE Int. Conf. on Intelligent computing and intelligent systems</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="479" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Small worlds and mega-minds: Effects of neighborhood topology on particle swarm performance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Cong. on Evolutionary Computation</title>
		<meeting>of Cong. on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Bare bones particle swarms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE SIS</title>
		<meeting>of IEEE SIS</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="80" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Int. Conf. on Neural Networks</title>
		<meeting>of IEEE Int. Conf. on Neural Networks</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Population structure and particle swarm performance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mendes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Cong. on Evolutionary Computation</title>
		<meeting>of Cong. on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1671" to="1676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Grey particle swarm optimization</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Leu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Yeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2985" to="2996" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A self-learning particle swarm optimizer for global optimization problems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Systems, Man, and Cybernetics, Part B: Cybernetics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="627" to="646" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The novel nonlinear strategy of inertia weight in particle swarm optimization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Int.Conf. on Bio-inspired computation</title>
		<meeting>of the IEEE Int.Conf. on Bio-inspired computation</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Comprehensive learning particle swarm optimizer for global optimization of multimodal functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="281" to="295" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Dynamic multi-swarm particle swarm optimizer</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE SIS</title>
		<meeting>of IEEE SIS</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="210" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An adaptive two-layer particle swarm optimization with elitist learning strategy</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A M</forename><surname>Isa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">273</biblScope>
			<biblScope unit="page" from="49" to="72" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Bidirectional teaching and peer-learning particle swarm optimization</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A M</forename><surname>Isa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">280</biblScope>
			<biblScope unit="page" from="111" to="134" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Teaching and peer-learning particle swarm optimization</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A M</forename><surname>Isa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="39" to="58" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A new particle swarm optimization algorithm with random inertia weight and evolution strategy</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Int. Conf. on CIS</title>
		<meeting>of the IEEE Int. Conf. on CIS</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="199" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">An adaptive fuzzy weight PSO algorithm</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conf. on Genetic and Evolutionary computation</title>
		<meeting>of the IEEE Conf. on Genetic and Evolutionary computation</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="8" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Hybrid particle swarm optimizer with breeding and subpopulations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lovbjerg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Int. Conf. on Genetic and Evolutionary computation</title>
		<meeting>of the IEEE Int. Conf. on Genetic and Evolutionary computation</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="469" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">HEPSO: High exploration particle swarm optimization</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mahmoodabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">M</forename><surname>Salahshoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bagheri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">273</biblScope>
			<biblScope unit="page" from="101" to="111" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The fully informed particle swarm: simpler, maybe better</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="204" to="210" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Particle swarm optimization with random sampling in variable neighbourhoods for solving global minimization problems. Swarm Intelligence</title>
		<author>
			<persName><forename type="first">G</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Grau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bello</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="352" to="353" />
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Metamemory: A theoretical framework and new findings. The psychology of learning and motivation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Narens</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="125" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Compact particle swarm optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Neri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mininno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Iacca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">239</biblScope>
			<biblScope unit="page" from="96" to="121" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Particle swarm optimization: Surfing the waves</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ozcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mohan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Cong. on Evolutionary Computation</title>
		<meeting>of Cong. on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1939" to="1944" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Particle swarm optimization using Gaussian inertia weight</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Radha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Int. Conf. on Computataional intelligence and multimedia</title>
		<meeting>of the IEEE Int. Conf. on Computataional intelligence and multimedia</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="97" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Locating and tracking multiple dynamic optima by a particle swarm model using speciation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Parrott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="440" to="458" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Empirical study of particle swarm optimizer with an increasing inertia weight</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Parsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Vrahatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Cong. on Evolutionary Computation</title>
		<meeting>of Cong. on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="868" to="873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">On the computation of all global minimizers through particle swarm optimization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Parsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Vrahatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="224" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">UPSO: A unified particle swarm optimization scheme</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Parsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Vrahatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lecture Series on Computer and Computational Sciences: Proc. of Int. Conf. of Computational Methods in Sciences and Engineering</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="868" to="873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Fitness-distance-ratio based particle swarm optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Peram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Veeramachaneni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Mohan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE SIS</title>
		<meeting>of IEEE SIS</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="174" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A hybrid evolutionary programming algorithm for spread spectrum radar polyphase codes design</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Perez-Bellido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Salcedo-Sanz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Ortiz-Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Portilla-Figueras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 9th annual conf. on Genetic and evolutionary computation</title>
		<meeting>of the 9th annual conf. on Genetic and evolutionary computation</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="682" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Analysis of the publications on the applications of particle swarm optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Poli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Evolution and Applications</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Distance-based locally informed particle swarm model for multimodal optimization</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="387" to="402" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Self-organizing hierarchical particle swarm optimizer with time-varying acceleration coefficients</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ratnaweera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Halgamuge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="240" to="255" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A modified particle swarm optimizer</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WCCI</title>
		<meeting>of WCCI</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="69" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Empirical study of particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Cong. on Evolutionary Computation</title>
		<meeting>of Cong. on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1945" to="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Cellular particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="4460" to="4493" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">New chaotic PSO-based neural network predictive control for nonlinear process</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="595" to="601" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Problem definitions and evaluation criteria for the CEC 2005 special session on real-parameter optimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tiwari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005005. 2005</date>
		</imprint>
		<respStmt>
			<orgName>Nanyang Technological University AND KanGAL</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">A new fitness estimation strategy for particle swarm optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">221</biblScope>
			<biblScope unit="page" from="355" to="370" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Diversity-guided quantum-behaved particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Int. Conf. on Simulated Evolution and Learning</title>
		<meeting>of Int. Conf. on Simulated Evolution and Learning</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="497" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A sequential learning algorithm for self-adaptive resource allocation network classifier</title>
		<author>
			<persName><forename type="first">S</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="3012" to="3019" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A sequential learning algorithm for complex-valued self-regulating resource allocation network-CSRAN</title>
		<author>
			<persName><forename type="first">S</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Savitha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sundararajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1061" to="1072" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Particle swarm optimization approach for multi-objective composite box-beam design</title>
		<author>
			<persName><forename type="first">S</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Sujit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Composite Structures</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="598" to="605" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Human cognition inspired particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Tanweer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Suresh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 9th Int. Conf. on Intelligent Sensors, Sensor Networks and Information Processing</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Particle swarm optimization: Hybridization perspectives and experimental illustrations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Thangaraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bouvry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">217</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5208" to="5226" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Diversity enhanced particle swarm optimization with neighborhood search</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rahnamayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">223</biblScope>
			<biblScope unit="page" from="119" to="135" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Particle swarm optimization with simple and efficient neighbourhood search strategies</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rahnamayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jiangand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Innovative Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="97" to="104" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Improving particle swarm optimization using multi-layer searching strategy</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">274</biblScope>
			<biblScope unit="page" from="70" to="94" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A multi-swarm cooperative multistage perturbation guiding particle swarm optimizer</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="77" to="93" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A novel multiswarm algorithm for optimization in dynamic environments based on particle swarm optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yazdani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nasiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Alireza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Meybodi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="77" to="93" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Enhanced comprehensive learning particle swarm optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">242</biblScope>
			<biblScope unit="page" from="265" to="276" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">A particle swarm optimization algorithm with rich social cognition</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 5th International Conference on natural computation</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="186" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Adaptive particle swarm optimization</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S H</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Systems, Man, and Cybernetics, Part B: Cybernetics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1362" to="1381" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">DEPSO: hybrid particle swarm with differential evolution operator</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">F</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. Systems, Man, and Cybernetics</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="3816" to="3821" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">A unified particle swarm optimization scheme</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Int. Conf. of Computational Methods in Sciences and Engineering</title>
		<meeting>of the IEEE Int. Conf. of Computational Methods in Sciences and Engineering</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="221" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Orthogonal learning particle swarm optimization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhi-Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu-Hui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="832" to="847" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">A modified particle swarm optimization with adaptive acceleration coefficients</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ziyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dingxue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Int. Conf. on Information processing</title>
		<meeting>of the IEEE Int. Conf. on Information processing</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="330" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Teaching-learning-based optimization with dynamic group strategy for global optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">273</biblScope>
			<biblScope unit="page" from="112" to="131" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
