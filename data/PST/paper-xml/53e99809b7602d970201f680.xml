<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Competitive Randomized Algorithms for Non-Uniform Problems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Anna</forename><forename type="middle">R</forename><surname>Karlin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><forename type="middle">S</forename><surname>Manasse</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lyle</forename><forename type="middle">A</forename><surname>Mcgeochj</surname></persName>
						</author>
						<title level="a" type="main">Competitive Randomized Algorithms for Non-Uniform Problems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2479959832317D26BD0E2B6A725ADAB1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competitive</head><p>analysis is concerned with comparing the performance of on-line algorithms with that of an optimal off-line algorithm.</p><p>For some problems, randomized on-line algorithms have yielded better performance ratios than deterministic on-line algorithms, assuming that the input sequences are generated by an adversary that has no knowledge about the results of the coin tosses made by the algorithm.</p><p>In this paper, we present new randomized on-line algorithms for snoopy-caching and the spin-block problem. These algorithms achieve strongly competitive ratios approaching e/(e -1) GZ 1.58, a surprising improvement over the best possible ratio in the deterministic case, which is 2. We also consider the situation when the request sequences for these' problems are generated according to an unknown probability distribution.</p><p>In this case, we show that deterministic algorithms that adapt to the observed request statistics also pay at most a factor of e/(e-1) more than the optimal off-line algorithm.</p><p>Finally, we show that for the 2-server problem on a 3-vertex isosceles triangle, there is a lower bound on the competitive ratio with a limit of e/(e -1). This is in contrast to the 2-server problem on an equilateral triangle where a strongly 3/2-competitive randomized algorithm is known.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Motivation and Results</head><p>The amortized analysis of on-line algorithms for processing sequences of tasks in dynamic systems has been a subject of great interest in recent years. The approach taken is to compare the performance of a strategy that operates with no knowledge of the future with that of an optimal, clairvoyant strategy, that has complete knowledge of the future and operates op- Susan Owicki* timally given that information.</p><p>A large number of problems have been studied from this point of view, cf [l, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 143.</p><p>On-line algorithms whose performance is within the smallest possible constant factor of the optimum offline are said to be strung/y compeailiue. More formally, let A be a (possibly randomized) on-line algorithm, let u be an input sequence to the algorithm, and let ECA(U) be the expected cost A incurs when processing input sequence b. Let Gopt(u) be the cost incurred by the optimal off-line algorithm in processing r~. We consider two types of adversaries.</p><p>Our first type of adversary is one that makes its request sequence without regard to the nondeterministic choices made by the on-line algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>An on-line algorithm</head><p>A is said to be c-competitive against a weak adversary if there is a constant a such that for any fixed input sequence 6, EC,&amp;) &lt; c ' C,,,(a) + a.</p><p>The constant c is known as the competitive factor.</p><p>The second type of adversary is one that can choose each input request depending on the choices made by the algorithm in servicing the previous requests. An on-line algorithm A is said to be c-competitive against a strong adversary if there is a constant u such that for any input sequence u generated in this way, ECA(U) 5 c . C,,,(u) + a.</p><p>Finally, an algorithm is strongly c-competitive against a weak (rasp. strong) adversary if c is the smallest constant attained by any on-line algorithm.</p><p>Observe that if the on-line algorithm is deterministic then a weak adversary can simulate a strong one.</p><p>A natural and interesting question is whether there are problems for which the best competitive factor is smaller against weak adversaries than against strong adversaries. Two dramatic results of this type have been obtained. The first, due to Borodin, Linial and Saks <ref type="bibr" target="#b4">[3]</ref> shows that for an n-state metrical task system where all states are unit distance apart the competitive factor can be improved from O(n) against a strong adversary to 2X, (= O(logn)) against a weak adversary. A similar result due to McGeoch and Sleator <ref type="bibr" target="#b13">[12]</ref> 1 slows that for the paging problem with memory size k (or equivalently a E-server problem with uniform distances), the competitive factor can be improved from k: to Xk. Fiat et al <ref type="bibr" target="#b8">[7]</ref> showed that this is the best possible competitive factor against a weak adversary.</p><p>In this paper we present new randomized algorithms for the snoopy-caching and spin-block problems. For both of these problems, it is not possible to construct an on-line algorithm with a competitive ratio better than 2 against a strong adversary. Our randomized algorithms have competitive ratios which approach e/(e -1) M 1.58. We also show that this is best possible against a weak adversary. An interesting fact about these results is that they are the first strongly-competitive algorithms against a weak adversary for a server problem on a non-uniform graph.</p><p>We also present a lower bound result for the a-server problem. It is known that for the a-server problem on a graph with all distances equal, there is a strongly 3/2-competitive algorithm against a weak adversary. We show that such a competitive ratio cannot be achieved on a graph with unequal distances. In particular for the 2-server problem on a 3-vertex isosceles triangle, there is a lower bound on the competitive ratio greater than 1.5 and tending to e/(e -1). We also show a lower bound greater than 1.54 on the competitive ratio for the 2-server problem on the 3-4-5 triangle.</p><p>Finally, we consider the question of how well a deterministic algorithm can perform if the input sequence is generated according to some unknown but time-independent probability distribution.</p><p>This question was motivated by the observation that in traces obtained for programs running on snoopy caching multiprocessor systems <ref type="bibr" target="#b7">[6]</ref>, different programs exhibit vastly different input characteristics (in this case write-run length). In particular, the inter-program input variability was extremely high, while the intraprogram input variability was extremely low. This suggests that an algorithm which adapts to the observed input statistics can potentially converge to near-optimal behavior. We show that adaptive deterministic algorithms of this type for snoopy-caching and for the spinblock problem achieve competitive ratios approaching e/(e -1) if the input sequence is generated accord- ing to a fixed probability distribution.</p><p>We further present a practical and simple version of the adaptive algorithm which is also 3-competitive against a strong adversary.</p><p>2 Snoopy Caching</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Model</head><p>A snoopy caching multiprocessor system is a system in which a set of processors each with its own (snoopy) cache are connected over a bus to each other and to a large shared memory. We will assume that the caches and large shared memory have infinite capacity. There is a single address space used by all of the processors; each location in this space is called a satiable. The memory space is partitioned into blocks, groups of variables of uniform size. We let p-1 denote the block size. We define the block snoopy caching model, as in <ref type="bibr" target="#b10">[9]</ref>.</p><p>All of a processor's memory requests are serviced by its cache. The cost of reading a variable depends on whether the block containing that variable is in the requesting cache or not. If it is, then the read is executed at no cost. If the block isn't in the cache, then the cache must send out a request for the appropriate block. This block is then broadcast on the bus by the cache currently containing the value of the block, and all other caches listen to the bus and retrieve it. The cost of this read is p bus cycles (one cycle for the address and one cycle for each variable in the block).</p><p>The cost of a write is either 1 or 0 bus cycles, depending on whether the block is shared or not. If the block is shared, the new value and address of the variable being written to must be broadcast on the bus to maintain cache consistency. We will assume that every write is preceded by a read, since if the cache is holding the block it wishes to write to, this read is free.</p><p>We call an on-line algorithm that decides when a block should be invalidated a snoopy-caching algo-tiZhm. The goal of this algorithm is to minimize the number of bus cycles used. For efficiency, if a block is shared, but only actively used by one cache, the other caches should invalidate that block in order to eliminate the cost of doing updates. On the other hand, there is a large penalty of p bus cycles for invalidating a block from a cache which shortly thereafter needs to access it. Previously, Karlin e2 al <ref type="bibr" target="#b10">[9]</ref> discovered a strongly Zcompetitive algorithm against a strong adversary. We will now show that it is possible to im-prove this ratio if the on-line algorithm is randomized We observe that the expected cost of algorithm A and t.he adversary is weak.</p><p>on sequence uk is Proof: Assume initially that the multiprocessor system consists of two caches and a single block B. We may assume that initially block B is shared by both caches, since all costs incurred prior to the time this state is reached can be bounded by a constant. Moreover, if the initial states are the same for the on-line and off-line algorithms, this constant is 0.</p><p>Let VI: be any sequence of requests consisting of k writes by one of the caches, interspersed with any number of reads by that same cache, to some variable in B, followed by a read by the other cache of some variable in B. We call such a sequence a write run of length k. Since any algorithm need not invalidate B from either cache until it is written to by the other cache, we can ignore any read subsequent to the one terminating a write run. Hence any sequence u of requests can be decomposed into subsequences of type UE and so a randomized algorithm that achieves a competitive factor of a on any sequence Bk achieves a competitive factor of &lt;y overall.</p><p>We construct a randomized algorithm for sequences of type bk with the best competitive factor. The choices available to the on-line algorithm for processing sequence flk can be described by enumerating a set of deterministic algorithms.</p><p>Let Ai be the deterministic algorithm that drops the block from the inactive cache after i updates by the active cache. A randomized algorithm is just a choice of a probability distribution ?r, where ?~i is the probability that the randomized algorithm chooses algorithm Ai on any write-run starting from the shared situation. Since the or; values were chosen so as to set Giequalities (*) to equalities, it is easy to verify that ECB(6k)</p><formula xml:id="formula_0">E(CA(Uk)) = c lri(p$- i) -i-(1 - c xi)).</formula><p>2 ECA(bk), After each write run, select another E as above to extend the sequence and complete the proof.</p><p>•I</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Randomized Algorithms for Limited Block Snoopy Caching</head><p>In this section, we extend the results for block snoopy caching to the more realistic model of finite directmapped caches. The slots that may contain blocks in a cache are calIed cache lines. A direct-mapped cache i uses a hash function hi(B) to determine the unique cache line in which a block B will reside. If hi(B) = h;(P), then cache i can contain at most one of the blocks B and B' at any time. Since different blocks can occupy the same cache line, a block that is read into a line may displace a block which was written to privately.</p><p>In this case, the line is dirty and must be written back to main memory at a cost of p. This model continues to assume that main memory has infinite capacity, a realistic assumption since it must be possible to have some clean copy of each shared variable.</p><p>In the limited block snoopy caching model, a cache grabs a block that is being read by another cache or being written back if and only if that block was the last to occupy its cache line; that is, only if the last operation on this cache line was to invalidate this block.</p><p>Making the assumption that the adversary has to use the same hash function as the on-line algorithm, we can prove a strengthening of Theorem 1.</p><p>Theorem 3 Consider a limited block snoopy caching multiprocessor system, with page sire p -1. There is an on-line randomized snoopy caching algorithm A with a competitive factor of e AL---+ ep -1 p4ooe-l against a weak adversary.</p><p>Proof: Without loss of generality we restrict our attention to a single cache line. In this case, a write run, Uk, is any sequence of requests consisting of k writes by one of the caches, c, interspersed with any number of reads by that same cache, to some variable in B, followed either by a read by any other cache of some variable in B or a read by c to a variable in a block that collides with B. Every sequence of requests can be decomposed into its write runs and its isolated reads, the latter being either the result of collisions or initial reads into a cache line. The optimal off-line algorithm and our on-line algorithm incur the same cost for all of the isolated reads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The on-line algorithm</head><p>A for the limited block model uses the same probabilities as the block snooping algorithm to determine how many updates to do in a write run before invalidating.</p><p>To show that this algorithm achieves the same competitive ratio, we map any sequence u on which it operates to a sequence u' in which the costs for u' and u have the same optimal cost in the limited block model, u' is at least as expensive as u for the on-line algorithm, and the costs of the write runs in u' are the same for both the block and limited block models. Each write run in Q which terminates due to a colliding read, is replaced in u' by the same write run followed by a read for the block by main memory. If the block was shared immediately before the colliding read, then main memory contains a valid copy of the block. Hence for both the off-line and on-line algorithms, the added read by main memory replaces the writeback; if it was necessary it costs p and if not, it's free. Now consider a write run in d which terminates with a read. If the line in the reading cache was dedicated to some other block, then this write run is augmented with p extra writes.</p><p>We claim that adding these writes does not change the optimal algorithm's cost. Indeed, since the terminating read causes that block to become revalidated by every cache that previously held it, the optimal strategy on this write run is to invalidate that block in all caches except for the writing cache. Since we have added extra requests, the on-line cost can not decrease, and since the write 3 Spin-Block</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.1</head><p>The problem Consider a process that is waiting for a lock. There are two choices for the actions that may be taken:</p><p>The process can spin, at a cost proportional to the length of time it spins, or it can block. The latter action has some large cost C reflecting the cost of restarting the process and restoring its state, usually referred to as the coniezGswiM cost. The difficulty in solving this problem is that the minimum-cost action depends on how long it will be before the lock is freed, information that is unavailable on-line. An on-line algorithm for the spin-block problem must decide how long a process should spin before it blocks.</p><p>It is fairly obvious that the spin-block problem is a continuous version of the 2-cache, l-block snoopy caching problem and as such it is trivial to construct a deterministic on-line algorithm with cost at most twice that of the optimal off-line algorithm-namely have the process spin for an amount of time equal to the cost of a context switch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem</head><p>6 There is no c-competitive algorithm for the spin-block problem for c &lt; 2 against a strong adversary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem</head><p>I There is a simple on-line randomized algorithm A for the spin-block problem which is strongly e/(e -1) -competitive against a weak adversary.</p><p>Proof: Let r(t) be the density function of the time before a process should block using algorithm A and let cr7 denote the situation where the lock remains held for time 7. Then the expected cost of the algorithm A that uses density function r(t) to determine how long a process should spin before blocking is</p><formula xml:id="formula_1">ECA(bT) = J T(t + C)n(t)dt + 7 O3 K(t)&amp;. 0 J T</formula><p>As in the case of snoopy caching, we would like to choose r(t) so that Setting the preceding inequalities to equalities and solving the differential equations that result from differentiating twice with respect to 7, we obtain</p><formula xml:id="formula_2">0 5 t 5 C otherwise</formula><p>The resulting competitive factor is easily calculated to be e/e -1. ~1</p><p>The same results that hold for the adaptive setting of snoopy caching hold for the adaptive setting of the spin-lock problem. As before, the adaptive algorithm collects statistics on spin-length times and chooses the algorithm that minimizes the expected cost. Proof:</p><p>The proof is identical to the proof of theorem 4 with summations replaced by integrals. q</p><p>The convergence of this algorithm to e/(e -1) competitive behavior depends on the fact that accurate statistics can be generated by keeping track of the entire history of lock-waiting times. A practical alternative to this algorithm, similar to that for snoopy caching, is one which only uses the last (or perhaps last few) lock-waiting times in order to determine what to do the next time a process requests a lock.</p><p>As in the snoopy caching case, the adaptive algorithm A for deciding how long a process should spin depends on the length of time 7 that the lock last remained held. If 7 &lt; C, then the process should spin for a time equal to C, otherwise the process should block immediately.</p><p>Note once again that this is an instance of choosing the algorithm that minimizes the expected cost, under the assumption that the lockwaiting time is equal to 7 with probability 1. Furthermore, algorithm A is 3-competitive against a strong adversary. The proof of this fact is virtually identical to the proof of theorem 5.</p><p>In practice, the most commonly implemented strategy is to block immediately if the lock is not available, always incurring cost C. It is desirable that an adaptive algorithm not cost substantially more than this simple strategy. Assuming a certain independence in the way processors acquire locks, we can show that competitive advantage can be traded off against a guarantee that the adaptive algorithm does not perform too much worse than the algorithm that always blocks.</p><p>We choose a constant Q, with 0 &lt; a 5 1, that determines the competitiveness and the bound on waiting time. As before, the time that a process spins before blocking depends on r. If 7 &lt; oC, then the process spins fcr a time equal to c&amp;, otherwise it blocks immediately. A large value of CY gives a more competitive algorithm, while a smaller value guarantees that the average waiting time is not much worse than C. Now assume that the distribution of waiting times is nonincreasing, that is, the probability of waiting between a and b time units is at least as large as the probability of waiting between a + k and b + k time units. This would be the case if the time of lock requests in one process are independent of the times when locks are held by other processes, which is likely to be nearly true in many applications.</p><p>Let f(t) be the density function for the distribution of waiting times, and on-line algorithm and ~)r times the cost of the off-line algorithm.</p><p>The variables in these inequalities are the probabiiities that A will be in a given state at a given time. The inequalities must all hold since otherwise the corresponding subsequence could be repeated to construct an infinitely long sequence with cost ratio greater than Q. Our lower bound is then obtained by minimizing cr subject to this set of linear constraints. The upper bound is achieved with an algorithm using the probabilities obtained from the minimization.</p><p>For isosceles triangles, inequalities can be derived as follows.</p><p>Suppose G is a triangle with vertices X, Y, and Z, where the distance between X and Y is one, and where 2 is distance d away from the other vertices. In order to calculate the cost of aIgorithms, we partition request sequences into phases. A new phase begins if the location of opt's servers is known and if one of those servers is on Z. By the argument above, we can assume that A's servers are in the same locations at the beginning of a phase. If A can achieve a competitive factor cy in general, then it must be able to achieve it in every phase. In discussing possible request sequences, we will never consider requests for vertices that A is covering with probability 1, because such requests can not increase the expected cost ratio between A and opt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>After each request an on-line algorithm</head><p>A must choose the probabilities with which it will cover the vertices. Such probabilities can not be based on the future. Furthermore, they need not consider requests that preceded the time when A and opt occupied the same vertices, because such requests can not affect the ratio of costs in later phases. So the probability that a particular vertex is covered depends only on the requests in the current phase.</p><p>Let pi be the probability that A is covering Z after the first i requests of a phase, assuming that Z has not yet been requested.</p><p>We can divide the analysis of costs into two parts. Let u(i) denote A's expected cost on a phase that has i requests of vertices X or Y before the first request at 2. If i &lt; 2d, the off-line optimal algorithm will shuttle a server between X and Y. When the request at Z arrives, opt is known to be covering Z and the previous request, and the phase ends. It has a total cost of i for the phase. Because opt's final configuration is known, A must also reach the same configuration.</p><p>A's expected cost for the phase must then be i-l E(c~(ai)) = 2d+pi(l -2d)+zPj-j=l Alternatively, if i 1 2d, opt will begin the phase by moving away from Z. When the request at Z arrives, opt will move one server to Z, leaving the other to cover whichever of X or Y is requested next. When that next request arrives, the location of opt's servers is known, and the phase ends. Algorithm opt has a total cost of 2d for the phase. After the first 2d requests of X or Y, we know that opt is covering X and Y, so algorithm A must cover the same vertices. Its total expected cost for the X and Y requests is When the request at Z finally arrives, A must cover it by moving from X or Y, at a cost of d. At this point, A can not know which vertex, X or Y, is covered by opt. To minimize the cost ratio for the worst-case choice, it must cover X and Y with equal probability. This gives it an expected cost of l/2 for the final request of the phase. A's total cost for the phase is </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>*</head><label></label><figDesc>DEC Systems Research Center, 130 Lytton Ave., Palo Alto, CA 94301</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>block snoopy caching mu&amp; tiprocessor system, with page site p -1. There is an on-line randomized snoopy caching algorithm A with a adversary.In fact, if all blocks start out shared, the expected cost of A' on any sequence equals ep/(ep -1) times the optimal cost.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>goal is to choose values for ?~i such that E(C&amp;k)) I (l+ a)k k I P E(CA(us)) &lt; (1 +")I' k &gt; P (*)and cr is minimized.Setting the preceding inequalities to equalities and solving the resulting difference equations, we obtain a* ( &gt; i-l ?ri = 0' P i = l...p otherwise Solving for Q by setting Cl,.i.., Xi = 1, we get analysis to multiple blocks, we take the on-Iine algorithm which treats each block independently as above. This yields an on-line algorithm A for which CA where c is a constant multiple of the discrepancy between the initial states of the on-line and off-line algorithms.Finally, we describe the on-line algorithm for k caches, which we call A'. At the beginning of each write run, algorithm A' selects a value i according to the probabilities Ai, It broadcasts updates until the write run exceeds i in length, and if this happens, invalidates the block in all other caches.To see that A' achieves the same competitive factor, we define a mapping between request sequences, u, on k caches and request sequences u' on 2 caches as follows. Partition u into subsequences r; consisting of operations by a single cache. The associated sequence u' consists of the concatenation of the sequences + where r,! is the same set of reads and writes as in rj, but with the requesting cache replaced by i (mod 2). Trivially CA'(u) 5 CA(J) and C,,,(a) &gt; C+(a'), and the theorem is proved. q Theorem 2 Let B be any on-line snoopy caching algorithm in a block snoopy caching multiprocessor system with page size p. Then there exists arbitrarily expensive sequences the result of executing algorithm B on a sequence of type Ok. Suppose that algorithm B has probability ai of dropping the block from the inactive cache after i writes. Take y and algorithm A as above. Let k be the smallest index for which c l&lt;i&lt;k ai 5 C15i&lt;k ri.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Theorem 8</head><label>8</label><figDesc>Let A* be the deterministic algorithm that minimizes the expected cost on lock-waiting time sequences u(P), where u(P) is generated according to a statistics of lockwaiting times in order to estimate the distribution P converges to e/(e -1) competitive behavior.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>2d-I E(CA(Qi)) = 2d + l/2 + C pj. j=l Using these costs, it follows that the following inequalities hold if algorithm A achieves a cost ratio of or on all request sequences: E(C&amp;)) _&lt; a. i i &lt; 2d E(C~(gii)) &lt; cy -2d i 2 2d To obtain the minimum possible LY, we set the preceding inequalities to equalities and solve the resulting equations, yielding Pi =(l-u)(&amp;)i+o and eZd---1 -k &amp; tr = (e2&amp;1 -1) -t $j ' This gives a lower bound on the competitive factor for the isosceles triangle. By using the probabilities obtained above, a randomized algorithm can achieve the same factor. q Theorem 10 Let B be any on-line probabilistic algorithm for the S-server problem on a 3 vertex triangle with distances 9, 4, and 5. Then there exists an infinite sequence of requests u for which EGW &gt; 1652 m 1.55. C,,,(u) -1069 Proof: Similar to previous theorem. •I</figDesc></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>run has length at least p, the cost of the write run in both models is equal to the number of steps for which the block is shared plus the cost of the re-read, p. 0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Adaptive Algorithms</head><p>Traces obtained for programs running on snoopy caching multiprocessor systems show that different programs exhibit vastly different write-run characteristics. Specifically, the programs analyzed in <ref type="bibr" target="#b7">[6]</ref> have the property that either write runs are very short (variables are actively being shared) or they are very long (there is very little sharing going on). In the first case, an algorithm like exclusive write (algorithm A1 above) performs best; in the second case, an algorithm like pack-rat (algorithm A,) performs best.</p><p>Motivated by these observations, we studied the following problem.</p><p>Suppose that the request sequence is generated according to some unknown probability distribution P. How well can an on-line algorithm do?</p><p>We begin by observing that the distribution P is completely characterized by knowing the probability that a write run has length Ic. If Ai is the deterministic algorithm that drops a block from the inactive cache after i consecutive writes by the active cache, then it is obvious that the best deterministic algorithm di to use is that subscripted by i for which ECA;(P(P)) is minimized, where a(P) is generated according to P. Call the algorithm that minimizes this expected cost A'.</p><p>Since in practice P is not known, the obvious approach is for the on-line algorithm to collect statistics on write-run lengths, and on the fly recompute which of the deterministic algorithms minimizes the cost. It is clear that if the sequence is generated from a timeindependent distribution, then the sample statistics will converge to their true values and the on-line algorithm will eventually become A*.</p><p>The following theorem characterizes the competitive ratio of A*. In practice, we feel that it should be sufficient to use the last few write runs as a sample, that is, if the last j write runs have lengths ir, iz,. . . , ii, then we will approximate P with the distribution P' consisting of sequences Ui,,Ui,,..., ucj, each with probability l/j. It is possible to show that the adaptive algorithm so obtained is still competitive against a strong adversary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem</head><p>5 Let A' be the deterministic, on-line algorithm that minimizes the expected cost for the distribution 'P' obtained by letting j = 1. Then A' is %competitive against a strong adversary.</p><p>Proof:</p><p>The algorithm obtained by adapting to the previous sample statistic is the following. Suppose that the last write run had length 1. Then the distribution P' assumes that write runs have length 1 with probab,ility 1. Consequently, the algorithm that minimizes the expected cost uses algorithm A, on the next write run if 15 p and algorithm A1 if 1 &gt; p.</p><p>To see that this algorithm is S-competitive, we simply observe that if Ap is used, then a ratio of 2 between on-line and offline costs is achieved <ref type="bibr" target="#b10">[9]</ref>. On the other hand, if A1 is used, then the previous write run had length greater than p, and consequently the adversary paid at least p for that write run. Hence, we can charge our cost on the current write run to the adversary's cost on the previous write run, yielding an overall competitive ratio of 3. 0</p><p>The larger the number of sample statistics used, the better the algorithm will perform.</p><p>In any case, we believe the combination of the strong-adversary competitiveness of this algorithm with its adaptiveness to the potential underlying request distribution makes it eminently practical.</p><p>CYC With probability p, the algorithm A, blocks immediately, and with probability 1 -p it spins for up to time ctC. Thus the expected cost of waiting is . . A natural question that arises is whether there is such an algorithm for the k-server problem where the distances are not uniform.</p><p>We answer this question in the negative by showing that for 2 servers on a 3-vertex nonequilateral triangle there is no 3/2-competitive algorithm.</p><p>Theorem 9 Let B be any on-line randomized algorithm for the &amp;server problem on a 3-vertex isosceles triangle with distances d, d, and 1. Then there exists an infinite sequence of requests u for which</p><p>There is a randqmized S-server algorithm that achieves this competitive factor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof:</head><p>Suppose A is the best on-line algorithm. The idea of the lower bound proof is to explore the tree of possible request sequences, maintaining for each node in the tree a vector in which the ith coordinate is the probability that A has a server at the ith vertex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>By constructing.</head><p>the optimal algorithm's cost using dynamic programming, we can determine positions in the tree where we know with certainty the locations of opt's servers. These are points for which the cost of being in some other state s is equal to the cost of being in the desirable state plus the cost to switch from the desirable state to the undesirable state. Call this set of positions I&lt;.</p><p>We claim that at each position in K, we may assume that the on-line algorithm A has its servers in the same locations as the off-line algorithm.</p><p>If not, it is possible to augment the sequence of requests terminating at such a position (in K) with a subsequence that makes the ratio between A's cost and opt's cost larger. Specifically, suppose that after each subsequence which ends at a position k E I&lt;, algorithm A is covering one of opt's vertices with probability less than one. By alternating requests for the vertices covered by opt, one of two situations will be reached. If there is always some E difference between the positions of A and opt, then A's cost will grow arbitrarily.</p><p>On the other hand, if A covers opt's vertices with probability approaching 1, then A's cost is eventually larger than if it had moved to that position immediately.</p><p>Request sequence trees for certain graphs (including isosceles triangles) have the property that every sufficiently long request sequence contains a subsequence beginning and ending with positions in K in which opt is known to be in the same state. Suppose that (Y is the competitive factor achieved by the on-line algorithm.</p><p>From each minimal subsequence in which opt's servers begin and end in the same state, we can derive an inequality between the expected cost of the</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Memory vs. randomization in on-line algorithms</title>
		<author>
			<persName><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Snir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ll Berman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Karloff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Tardos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First Annual A CM-SIAM Symposium on Discrete Algorithms</title>
		<imprint>
			<date type="published" when="1989-07">July 1989</date>
		</imprint>
	</monogr>
	<note>ICALP, Italy</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Amortized efto appear. ficiency of list update and paging rules</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Sleator</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Tarjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CAChI</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="202" to="208" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">An optimal online algorithm for metrical task systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Borodin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Linial</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saks</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m">Annual ACM Symposium on Theory of Computing</title>
		<meeting><address><addrLine>New York City, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987-05">May 1987</date>
			<biblScope unit="volume">37</biblScope>
		</imprint>
	</monogr>
	<note>3-382</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An optimal online algorithm for metrical task systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Borodin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Linial</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Submitted for publication</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">New results on server problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chrobak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Karloff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First Annual ACM-SIAM Symposium on Discrete Algorithms</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A new approach to the server problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chrobak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Larmore</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Manuscript</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Evaluating the performance of four snooping cache coherency protocols</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Eggers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 16th Annual International Symposium on Computer Architecture</title>
		<meeting>16th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Competitive paging aIgorilhms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fiat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Karp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Mcgeoch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Sleator</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Young</surname></persName>
		</author>
		<idno>CMU-CS-88- 196</idno>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
		<respStmt>
			<orgName>School of Computer Science, Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A competitive &apos;t-server algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rubinfeld</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Manuscript</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Karlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Manasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Sleator</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Competitive snoopy caching. Algoridhmica</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="119" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Competitive algortihms for on-line problems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Manasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Mcgeoch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Sleator</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 87th Annual ACM Symposium on Theory of Computing</title>
		<meeting>the 87th Annual ACM Symposium on Theory of Computing<address><addrLine>Chicago, Illinois</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988-05">May 1988</date>
			<biblScope unit="page" from="322" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Algorithms for Two Graph Problems</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Mcgeoch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A Strongly Competitive Randomized Paging Algorithm</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Mcgeoch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Sleator</surname></persName>
		</author>
		<idno>CMU-CS-89-122</idno>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
		<respStmt>
			<orgName>School of Computer Science, Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
