<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DTW-D: Time Series Semi-Supervised Learning from a Single Example</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yanping</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bing</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Eamonn</forename><surname>Keogh</surname></persName>
							<email>eamonn@cs.ucr.edu</email>
						</author>
						<author>
							<persName><forename type="first">Gustavo</forename><forename type="middle">E A P A</forename><surname>Batista</surname></persName>
							<email>gbatista@icmc.usp.br</email>
							<affiliation key="aff1">
								<orgName type="institution">Universidade de São Paulo-USP</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Riverside</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">KDD&apos;13</orgName>
								<address>
									<addrLine>August 11--14</addrLine>
									<postCode>2013</postCode>
									<settlement>Chicago</settlement>
									<region>Illinois</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DTW-D: Time Series Semi-Supervised Learning from a Single Example</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E35FA617CA8D9A94BEB88347FAE5EF1A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Systems]: Information Search and Retrieval -Information filtering</term>
					<term>Selection process Time Series</term>
					<term>Semi-Supervised Learning</term>
					<term>Classification ED</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Classification of time series data is an important problem with applications in virtually every scientific endeavor. The large research community working on time series classification has typically used the UCR Archive to test their algorithms. In this work we argue that the availability of this resource has isolated much of the research community from the following reality, labeled time series data is often very difficult to obtain. The obvious solution to this problem is the application of semisupervised learning; however, as we shall show, direct applications of off-the-shelf semi-supervised learning algorithms do not typically work well for time series. In this work we explain why semi-supervised learning algorithms typically fail for time series problems, and we introduce a simple but very effective fix. We demonstrate our ideas on diverse real word problems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>There has been an enormous interest in time series classification in the last two decades <ref type="bibr" target="#b2">[2]</ref>[6] <ref type="bibr" target="#b10">[10]</ref>. Two related conclusions have begun to emerge as a consensus in the community. First, while there is a plethora of classification algorithms in the literature, the nearest neighbor algorithm seems particularly suited to the unique structure of time series, and virtually all competitive attempts at time series classification use it <ref type="bibr" target="#b33">[33]</ref>. Second, while there is also a surfeit of possible distance measures for time series, Dynamic Time Warping (DTW), a technique from the dawn of computing, is exceptionally difficult to beat <ref type="bibr" target="#b6">[6]</ref>. In particular, a recent paper tested the most cited distance measures on 47 different datasets, and no method consistently outperforms DTW. Thus recent papers that claim improvements over DTW must resort to very powerful statistical tests to demonstrate tiny improvements in accuracy.</p><p>In the last decade, virtually all of the community has used the UCR Archive to test their algorithms <ref type="bibr" target="#b11">[11]</ref>. We believe that the availability of this (admittedly very useful) resource has isolated much of the research community from the following reality, labeled time series data is often very difficult to obtain. For example, in many situations, from medicine <ref type="bibr" target="#b20">[20]</ref> to astronomy <ref type="bibr" target="#b22">[22]</ref>, obtaining labeled data requires the time and attention of a busy domain expert.</p><p>The obvious solution to this problem may appear to be the application of semi-supervised learning; however, direct applications of off-the-shelf semi-supervised learning algorithms do not typically work well for time series. In this work we make two related contributions. We explain why semi-supervised learning algorithms typically fail for time series problems, and we introduce a simple but very effective fix. While we defer a detailed explanation of both until Section 4, we offer a simple three sentence preview here:</p><p>Under certain assumptions, unlabeled members of a circumscribed positive class may be closer to some unlabeled members of a diverse negative class than to the labeled positive data. This is true even under DTW. Nevertheless, unlabeled positive data tend to benefit more from using DTW than unlabeled negative examples. The amount of benefit from using DTW over Euclidean Distance (ED) is a meta-feature that can be exploited.</p><p>We illustrate this in Figure <ref type="figure" target="#fig_0">1</ref> where we show the hierarchical clustering of five objects under various measures. Two of the five objects are randomly chosen examples (red/bold) from class 3 of the Trace dataset <ref type="bibr" target="#b11">[11]</ref>. The other three objects are simply randomwalk time series (blue/light). As we can see, Euclidean Distance does poorly here. This is not surprising, since the Trace dataset is known to have classes that contain exemplars that are time-warped versions of a prototypical shape. Indeed, we see that DTW does manage to do better, reducing the distance between Trace-1 and Trace-2. However, this reduction is not enough; random-walk-3 is still closer to Trace-1 than Trace-2 is.</p><p>Our key observation is that moving from ED to DTW seems to help the true class data more than the random unstructured data. We can encode this difference/delta that DTW makes with DTW-D, the ratio of DTW over ED. And as we see in Figure <ref type="figure" target="#fig_0">1</ref>.right, this does produce the correct clustering, at least in this example.</p><p>Imagine that we had been doing semi-supervised learning in this dataset using just Trace-1 as our sole positive example. For both ED and DTW, the very first item we added to the positive set would have been a false positive, and it would be very difficult for any algorithm to recover from this. In contrast, DTW-D would have correctly suggested Trace-2 as the next item to add, and assuming only that we had good stopping criterion, we would have done very well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>In the past two decades, there has been an enormous interest in time series classification. Most research efforts leverage off the assumption that there are large amounts of labeled training data <ref type="bibr" target="#b24">[24]</ref> <ref type="bibr" target="#b29">[29]</ref>. In reality, the high cost of labeling the data may render such an assumption invalid. For example, it requires the time and expertise of a cardiologist to annotate individual heartbeats in an ECG data trace <ref type="bibr" target="#b3">[3]</ref>, but a single polysomnography (sleep study) test may produce up to 40,000 such heartbeats. Given that the acquisition of unlabeled data is trivial, there is abundance of unlabeled data readily available. For instance, PhysioBank contains over 36,000 recordings of digitized polysomnographic and other physiologic signals, only a tiny fraction of which are labeled <ref type="bibr" target="#b7">[7]</ref>; likewise there are tens of millions of books, images, maps and historical manuscripts available on the internet <ref type="bibr" target="#b9">[9]</ref>, many of which could be fruitfully mined in the time series space <ref type="bibr" target="#b26">[26]</ref> <ref type="bibr" target="#b32">[32]</ref>, if only we had more labeled data (cf. Section 6.2). Semi-supervised learning (SSL) is a learning paradigm useful in application domains in which labeled data are limited, but unlabeled data are plentiful <ref type="bibr" target="#b23">[23]</ref>[8] <ref type="bibr" target="#b4">[4]</ref>. The literature offers a plethora of SSL methods, among which, self-training is perhaps the most commonly-used <ref type="bibr" target="#b17">[17]</ref>[27][5] <ref type="bibr" target="#b34">[34]</ref>. Self-training is a general framework with very few underlying assumptions. In selftraining, a classifier is first trained with a small number of labeled data. It is then used to classify the unlabeled data, and adds the most confidently classified object into the labeled set. The classifier re-trains itself using the new labeled set and the procedure repeated until adding new objects to the labeled set does not increase the accuracy of the classifier or some other stopping criteria is met. This general review of SSL is necessarily brief; we refer the readers to <ref type="bibr" target="#b34">[34]</ref> and the references therein for more details.</p><p>Recently, some SSL techniques explicitly designed for time series have been proposed. To our best knowledge, thus far there are only three approaches <ref type="bibr" target="#b16">[16]</ref>[25] <ref type="bibr" target="#b19">[19]</ref>. The first paper <ref type="bibr" target="#b16">[16]</ref> proposed to iteratively expand the labeled set by adding the closest object that is classified as positive to the labeled set. The classifier considers all unlabeled data as negative, and uses the Euclidean Distance. As we shall show, and as has been noted elsewhere <ref type="bibr" target="#b6">[6]</ref> <ref type="bibr" target="#b33">[33]</ref>, the inferiority of Euclidean Distance to DTW is mitigated by large training set sizes. Conversely Euclidean Distance is much more brittle a measure than DTW for tiny datasets, which is of course exactly the situation we face here. Thus <ref type="bibr" target="#b25">[25]</ref> proposed to build a SSL classifier using DTW distance. Although moving from ED to DTW helps to improve the accuracy of the classifier, the algorithm is still not accurate enough in most real applications (cf. Section 6.1).</p><p>More recently, the authors of <ref type="bibr" target="#b19">[19]</ref> introduced a SSL technique that interleaves exemplar selection with feature selection, using the work of <ref type="bibr" target="#b16">[16]</ref> as a starting point. The method of <ref type="bibr" target="#b19">[19]</ref> improves the SSL algorithm, but still uses standard distance measures (Euclidean Distance). As such it is orthogonal to our contribution, which demonstrates that a subtle change in the distance measure dwarfs all possible changes in the algorithms.</p><p>In retrospect, only three research efforts on SSL for time series is a surprisingly small number, given that both SSL and time series classification are very popular research topics. In this work we venture to claim that we understand why progress in this area has been so slow. In brief, our claim is that there is little utility in tweaking the architecture of the SSL algorithms for time series, as they are all condemned to perform poorly if they use DTW or Euclidean Distance. The contribution of this work is to show a simple but effective fix that will allow the existing SSL methods to work very well for time series. It is important to recognize that we are not claiming a contribution to SSL algorithms per se. Rather we will show that changing the distance function used in SSL algorithms can produce a remarkable improvement for time series.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DEFINITIONS AND NOTATIONS</head><p>We begin by introducing all necessary notation and definitions. Although the algorithm presented in this work is applicable to all SSL methods, for ease of exposition, we present just the notations for Positive Unlabeled learning (PU learning), which is a collection of SSL methods that trains a classifier based on the positive (labeled) dataset and the unlabeled dataset only.</p><p>Definition 1: P is the set of training data, including all positively labeled objects. P initially contains only a small number of labeled objects from the positive class, perhaps as few as one. As learning proceeds, the size of P increases as some of the previously unlabeled objects in U are labeled as positive and moved to P. Thus, P eventually contains both the original labeled objects, as well as the objects chosen by the classifier from the unlabeled dataset.</p><p>Definition 2: U is the set of unlabeled data. Objects in dataset U can be from the positive class or the negative class. It is generally expected that the vast majority of U is from the negative class <ref type="bibr" target="#b34">[34]</ref>. The goal of SSL is to map all the objects in U to the correct class so that the classifier is accurately trained with the classified objects. We denote individual time series objects from these two sets with subscripts, thus the i th time series object in P is denoted P i .</p><p>Rather than making a onetime explicit decision as to which objects from U should be added to P, most algorithms simply iteratively add the next most likely candidate <ref type="bibr" target="#b27">[27]</ref> <ref type="bibr">[18][34]</ref>. This means that we must also specify a stopping criterion for the algorithm to predict that it has added all the unlabeled positive objects <ref type="bibr" target="#b34">[34]</ref>. The problem of finding a good stopping criteria is an open problem, with tentative solutions based on MDL, Bayesian information criterion, bootstrapping <ref type="bibr" target="#b28">[28]</ref> <ref type="bibr" target="#b34">[34]</ref>, etc. As this issue is somewhat orthogonal to our contribution, we simply gloss over it here. However, note that as we shall show in the empirical section, the difference our algorithm makes completely dwarfs any considerations of the optimal stopping criteria. That is to say, even if we did a post-hoc discovery of the optimal stopping criteria for the state-for-art rival, our method would have much higher accuracy for a huge range of "sub-optimal" stopping values.</p><p>For brevity, we do not explicitly define time series, Euclidean distance or Dynamic Time Warping, which in any case are rather well known. Instead we use the notation from <ref type="bibr" target="#b6">[6]</ref>, a heavily cited survey paper on these topics. We do note however the following useful fact, that the ED is an upper bound to the DTW. That is to say, for all x, y, we have DTW(x,y) ≤ ED(x,y).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">DTW-D</head><p>To explain our observations and our key insight, we consider a concrete example. Let us imagine that we have target class of objects that are defined by having three periods of a sine wave. The instances may be corrupted by warping, different dampening rates, noise, minor changes to the starting phases etc, but as shown in Figure <ref type="figure" target="#fig_1">2</ref> they are unambiguously recognizable to the human eye.</p><p>In this example the negative class consists of just a constant line with the same mean as the positive class<ref type="foot" target="#foot_0">1</ref> , corrupted by some noise. Suppose we ask any SSL algorithm to choose one object from U to add to P using the Euclidean distance. As we can see in Figure <ref type="figure">3</ref>, U 1 is much closer to P 1 than U 2 is, thus our SSL algorithm would do poorly here.</p><formula xml:id="formula_0">U 2 P 1 U 1 P 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3： The Euclidean distance between two time series is proportional to the length of the gray hatch lines. It is easy to see that ED(P 1 ,U 2 ) &gt; ED(P 1 ,U 1 ) .</head><p>In retrospect this is not surprising. The brittleness of Euclidean distance to even small amounts of warping is well known, and explains the ubiquity of DTW in most research efforts <ref type="bibr" target="#b13">[13]</ref>[6] <ref type="bibr" target="#b26">[26]</ref>. By finding the optimal "peak-to-peak/valley-to-valley" alignment between two time series before calculating the distances, DTW is largely invariant to warping, as shown in Figure <ref type="figure">4</ref>.</p><formula xml:id="formula_1">U 2 P 1 U 1 P 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4: The DTW distance between two time series is proportional to the y-axis length of the gray lines.</head><p>Unfortunately, while DTW helps significantly, as shown in Table <ref type="table">1</ref>, it is not enough: U 1 is still closer to P 1 than U 2 is, and the SSL algorithm would still pick the wrong object to move from U to P. Why did DTW not solve our problem? While DTW is invariant to warping, there are other differences between P 1 and U 2 , including the fact that the first and last peaks have different heights. DTW cannot mitigate this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1: The Distance Matrices for the Three Objects in [P,U], under both the ED and DTW Distances</head><formula xml:id="formula_2">ED DTW P 1 U 1 U 2 P 1 U 1 U 2 P 1 0 6.2 11 0 5.8 6.1 U 1 0 6.8 0 6.5 U 2 0 0</formula><p>Moreover, the problem is compounded by the fact that U 1 is a "simple" shape. As pointed out in a recent paper, simple shapes tend to be "close to everything" <ref type="bibr" target="#b2">[2]</ref>. Figure <ref type="figure">3</ref> gives a hint as to why this is true. The flat shape of U 1 means that no part of it is more than 0.5 away from any part of P 1 . In contrast where P 1 and U 2 are out of phase, and the Euclidean distance is forced to match a peak to a valley, the distance can be as much as 0.8. This is why smooth, flat or least very slowly changing time series tend to be (subjectively) surprisingly close to other objects <ref type="bibr" target="#b2">[2]</ref>. This is a grave disappointment  this seems to be a dataset for which DTW is ideally suited, yet DTW fails here.</p><p>However, an examination of distance matrices shown in Table <ref type="table">1</ref> does reveal an interesting fact. Moving from ED to DTW barely changed the distance between P 1 and U 1 , but it did greatly affect the distance between P 1 and U 2 . We can codify this with the following observation:</p><p>Observation 1: If a class is characterized by the existence of intra-class warping (possibly among other distortions <ref type="bibr" target="#b2">[2]</ref>), then we should expect that moving from ED to DTW reduces distances more for intra-class comparisons than interclass comparisons.</p><p>To see this more clearly, we can consider the ratio of distance under DTW and ED as shown in Table <ref type="table" target="#tab_0">2</ref>. </p><formula xml:id="formula_3">U 2 0 0</formula><p>Note that if we consider the DTW-D ratios, we finally have P 1 and U 2 appear closer than P 1 and U 1 .  <ref type="table">1</ref> and Table <ref type="table" target="#tab_0">2</ref> under complete linkage hierarchical clustering.</p><p>Note that there is one minor special case we need to consider. If the ED is zero, then DTW-D would give a divide-by-zero error. We simply define this special case as having a value of zero. If the ED distance (and therefore also the DTW distance) between two objects is zero, it would be perverse to call them anything but the same class. This is a moot point, as we never expect observe perfect duplicates for real-values objects.</p><p>We have now concretely seen the problem with using ED/DTW for SSL, and our suggested fix, on a toy problem. However, it is natural to ask when this phenomenon actually occurs in the realworld, and would be amenable to our DTW-D solution. In the next section, we explicitly discuss our assumptions about when our ideas can help.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Two Key Assumptions</head><p>We do not claim our ideas will help for all time series problems. In particular, we are making two explicit assumptions which we will enumerate and discuss below. We will later show that these assumptions are very often true in real world domains.</p><p>Assumption 1: The positive class (the target concept) contains time warped versions of some platonic ideal (some prototypical shape), possibly with other types of noise/distortions. Note that this assumption was true of our toy example in Figure <ref type="figure" target="#fig_0">1</ref>. While all members of the Trace dataset have some noise, as shown in Figure <ref type="figure" target="#fig_3">6</ref>, the most obvious variability between instances is in the timing of the onset of the "ramp-up" and the "oscillation" patterns. Dynamic time warping is able to compensate for and remove this variability. This ability of DTW to compensate for the inherent warping in this class can produce a dramatic difference in classification accuracy. In the UCR Archive dataset the four-class Trace data is provided with a 100/100 train test split. The ED error rate on this dataset is 0.24, whereas DTW has an error-rate of 0.0. Since the exact same splits and classification algorithm (1NN) were used, and zero parameters are tuned for either approach, all of this difference can be attributed to the superiority of DTW over ED.</p><p>Assumption 2: The negative class may be very diverse, and occasionally by chance produces objects close to a member of the positive class, even under DTW. Empirically, negative classes do tend to be diverse <ref type="bibr" target="#b15">[15]</ref>[30]. For example, there are only a limited number of ways an audio snippet can sound like a mosquito, but there are infinite ways a sound can be a non-mosquito (c.f. Section 6.1). Once again, this assumption was illustrated by our toy example in Figure <ref type="figure" target="#fig_0">1</ref>. The random walk class is naturally very diverse, and it can (and did) produce an instance that is closer to Trace-1 than the other member of the positive class (Trace-2).</p><p>It is central claim that if the two assumptions are true for a given problem, our novel scoring function DTW-D will be better than either ED or DTW. As these are the central assumptions, we will next consider when we might expect them to be true.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Observations on our Key Assumptions</head><p>In the following sections we consider the implications of our assumptions for the task at hand, and empirically investigate whether these assumptions are warranted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Assumption 1 is mitigated by large amounts of labeled data</head><p>If we have a large enough set of labeled examples, we expect that simple DTW or even ED will work very well. Our noted weakness of semi-supervised learning happens when the nearest instance to a labeled positive exemplar is a negative instance. With more labeled positive instances this becomes less and less likely to happen. To see this, we performed an experiment that generalizes the toy example in Figure <ref type="figure" target="#fig_0">1</ref>. We created an unlabeled dataset U that contains just one exemplar from Class 3 of Trace, and 200 random walks. We then consider the question of what is the probability that the first object added to the labeled dataset P is that sole true positive in U, for various sizes of P from 1 to 10 (i.e. P has 1 to 10 true members from Trace). To smooth out our estimate, we averaged over 1,000 runs. As we can see in Figure <ref type="figure" target="#fig_4">7</ref>, this probability does indeed increase as |P| gets larger.</p><p>This plot suggests that if we had a large enough P, then DTW-D would offer only a small advantage over ED, and a barely perceptible improvement over DTW. However when P is small, DTW-D is dramatically better than both ED/DTW, supporting our assumption. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Assumption 2 is compounded by a large negative dataset</head><p>In a sense this observation is a direct corollary of the above. If the negative class is random and/or diverse, then the larger the negative class is, the more likely it is that it will produce an instance that just happens to be close to a labeled positive item.</p><p>To see this, we again perform an experiment that generalizes our toy example. We created a dataset P that contains just one exemplar from Class 3 of Trace. Once again U contains a single true positive, but this time we vary the number of random walks from 100 to 1,000. As before we measure the probability that the first object added to P is the true positive, averaged over 1,000 runs. Figure <ref type="figure" target="#fig_5">8</ref> shows the results.</p><p>In most semi-supervised settings, we expect |U| to be many orders of magnitude larger than the |P|, thus this assumption is almost always true in real settings. Again this figure strongly supports our assumption. When we have relatively few true negatives, all methods work well. However, as the number of true negatives in U increases, ED rapidly deteriorates. In contrast, DTW deteriorates more slowly. Remarkably, however, DTW-D is completely unaffected by a surfeit of true negatives, maintaining perfect accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Assumption 2 is compounded by low complexity negative data</head><p>Our final observation requires us to define what is meant by the "complexity" of a time series. Our remarks here are inspired by <ref type="bibr" target="#b2">[2]</ref>, which makes a similar observation, but in a very different context. As noted in <ref type="bibr" target="#b2">[2]</ref>, while a "complex" time series is hard to define, it is something we can intuitively understand. For our purposes, let us say that a complex time series is one that is not well approximated by few DFT coefficients or by a low degree polynomial.</p><p>The problem caused by low complexity data is that it is "close to everything", and as such, the chances that at least one instance from the negative class is closer to an exemplar from P than a true positive is much greater if some or all the negative data has low complexity.</p><p>To see this we can repeat the experiment shown in Figure <ref type="figure" target="#fig_0">1</ref> after replacing the random walk series by randomly generated third-degree polynomials. The results here are visually jarring. It is important to emphasize that this is not the result of an error, contriving of the data, or crippling the ED/DTW in any way. It is simply the case that low complexity time series have a tendency to have a small distance to all other objects.</p><p>Apart from <ref type="bibr" target="#b2">[2]</ref>, other works have indirectly noted this phenomenon. For example, <ref type="bibr" target="#b12">[12]</ref> notes that if we average all subsequences in a long time series, we will get a constant line, which is surely the least complex time series under any definition. Implicitly, this means that a constant line is the time series with minimal expected distance to any randomly chosen time series.</p><p>Thus, if the negative class is complex, we should expect the DTW or even ED will work well for semi-supervised learning. To see this, we can repeat the experiment shown in Figure <ref type="figure" target="#fig_0">1</ref>/Figure <ref type="figure" target="#fig_6">9</ref> after replacing negative class with pure random vectors. Note that while we may consider random vectors as "noisy", it is incidental to the point that they are complex. Figure <ref type="figure" target="#fig_7">10</ref> demonstrates that when the unlabeled data are complex, even ED has little trouble in grouping the positive class.</p><p>Beyond the visual evidence shown in Figure <ref type="figure" target="#fig_6">9</ref> and Figure <ref type="figure" target="#fig_7">10</ref>, we can test our observation with another simple experiment. Once more we perform an experiment that generalizes our toy example. We created a labeled dataset P that contains just one exemplar from Class 3 of Trace. This time U contains one true positive and 200 random time series that are approximated by k non-zero DFT coefficients, with k ranging from 5 to 20. Figure <ref type="figure" target="#fig_8">11</ref> shows some examples of series that are approximated by 5 and 20 nonzero DFT coefficients respectively. As before we measure the probability that the first object added to P is a true positive, averaged over 1,000 runs. Figure <ref type="figure" target="#fig_1">12</ref> shows the results.</p><p>Once again this experiment strongly supports our hypothesis. Low complexity items in the negative class make SSL more difficult for all distance measures, but using DTW-D does greatly mitigate the problem. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Implications of observations/assumptions</head><p>The observations and experiments in the previous sections tell us when we should expect the DTW-D method to help. We should not expect DTW-D to help with the classic time series classification problems as exemplified by the UCR archive <ref type="bibr" target="#b11">[11]</ref>. These datasets typically do have a relatively large set of label positive data (at least dozens), and typically do not have one class with much lower complexity and/or much higher diversity than the other classes.</p><p>In contrast, it is easy to see that all our assumptions mesh perfectly with most SSL assumptions <ref type="bibr" target="#b28">[28]</ref>[27] <ref type="bibr" target="#b23">[23]</ref>:  We do have very small (as few as one) positive examples (cf. Section 4.2.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>We do have relatively large amounts of negative data. For example, when trying to learn the vacuum-cleaning concept. (cf. Section 6.3), we must expect that most people spend less than 0.01% of their time vacuuming. Likewise, if we monitor audio streams, most sounds we hear are not insects (cf. Section 6.1) etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>We do have at least some low complexity negative instances (cf. Section 4.2.3). This is true because the negative class is usually highly variable. For human activity monitoring, there are likely moments when a person is sitting still, producing very low complexity data (cf. Section 6.3) As we shall show in Section 6, SSL problems in very diverse domains fit into our assumptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">ALGORITHM DETAILS</head><p>While we believe that our ideas can be applied to essentially any time series SSL learning framework, simply by replacing the ED or DTW distance calculations with DTW-D. However, for concreteness, in this section we will explicitly define the exact SSL algorithm used in our experiments. Note that we took pains to choose a simple SSL algorithm here, because as we noted before, we are not claiming a contribution to SSL per se. Rather, our contribution is a simple but effective fix to a problem that will otherwise plague any attempt at SSL for time series. Our focus in this work is to demonstrate the effectiveness of our ideas, even with a simple SSL algorithm.</p><p>Note that we are assuming that whatever "flavor" of SSL is, the underlying classification algorithm will use Nearest Neighbor (NN) <ref type="bibr" target="#b6">[6]</ref>. This is because, in spite of two decades of experimentation with neural networks, decision trees, Bayesian methods <ref type="bibr" target="#b29">[29]</ref> etc., there is strong empirical evidence that nearest neighbor algorithms are the best approach for time series (see <ref type="bibr" target="#b33">[33]</ref>, and the references therein and thereof).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">DTW-D Algorithm</head><p>As hinted in Section 4, our proposed distance measure DTW-D is accomplished with a simple equation:</p><formula xml:id="formula_4">- (1)</formula><p>Where is an extremely small positive quantity used to avoid divide-by-zero error. We reiterate that is not parameter of our system, it is device to enable a terser definition.</p><p>As shown in Table <ref type="table" target="#tab_1">3</ref>, the computation of DTW-D can be achieved on two series x and y using one line of matlab code: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Training the Classifier</head><p>The classifier used is a one-class classifier <ref type="bibr" target="#b30">[30]</ref>. The training dataset contains only the objects from the positive class. The goal of the classifier is to accurately extract all the positive class objects from the unlabeled dataset <ref type="bibr" target="#b15">[15]</ref>.</p><p>The data used to train the classifier includes a labeled dataset P and an unlabeled dataset U. In the beginning, there is as few as one labeled object in P. As shown in Table <ref type="table" target="#tab_2">4</ref>, the classifier trains itself through the following steps:</p><p>Step 1: The classifier is trained on the initial labeled dataset, which contains as few as only one object from the positive class. Note that the labeled dataset is augmented gradually during the training process.</p><p>Step 2: For each object in the unlabeled dataset U, we compute its distance to the labeled dataset using DTW-D (Line 10 to Line 13). An object's distance to the labeled dataset is the distance of the object to its nearest neighbor in the labeled dataset.</p><p>Step 3: Among all the unlabeled objects, the one we can most confidently classify as positive is the object that is closest to the labeled dataset (Line 3). The object is added into the labeled dataset (Line 4) and removed from the unlabeled dataset (Line 5). With the labeled dataset being adjusted, we return to Step 1 to retrain the classifier. The procedure repeated until some stopping criterion is met.</p><p>The intuition behind the algorithm is straightforward. The labeled dataset defines the concept space for the positive objects. The object closest to the labeled dataset is deemed to have the highest probability to belong to the positive class. At the first blush, our algorithm to train the classifier seems quite similar to the algorithm used in <ref type="bibr" target="#b16">[16]</ref>. However, a more careful introspection would reveal that they are fundamentally different. The classifier used in <ref type="bibr" target="#b16">[16]</ref> is a binary classifier, with all the unlabeled objects regarded as training examples from the negative class, whereas our classifier is a one-class classifier with no training examples from the negative class. The advantage of our classifier is that it makes much more realistic assumptions about how SSL work in practice. As noted elsewhere, the negative class is typically not a single well-defined concept as <ref type="bibr" target="#b16">[16]</ref> and others assume, rather it tends to be an extremely heterogeneous class. To give an example in a domain we consider, there are very limited ways humans can perform vacuum cleaning, but there are an infinite number of possible human activities that are not vacuum cleaning.</p><p>As noted above, in this work we gloss over the orthogonal problem of finding a good stopping criterion. In our experimental section, the training process stops when the unlabeled dataset U is exhausted of true positives by DTW-D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluating the Classifier</head><p>To evaluate the accuracy of all classifiers, we test the classifier using data that is "hidden" during the training stage. The test (holdout) dataset contains some positive class objects and many other objects. The goal of the classifier is to accurately extract all the positive class objects from the test dataset. We use the classic notion of precision and recall <ref type="bibr" target="#b31">[31]</ref> to measure the performance of the classifier. If an instance in the test dataset is top K closest to the labeled dataset, the instance is classified as positive, otherwise it is negative. K is the number of positive objects in the test dataset. Thus we can count the number of true positives out of K classifications.</p><p>Note that with this evaluation method, the value of recall equals to the value of precision (because the number of false negatives is the same as the number of false positives). For brevity, we report only the precision here. The computation of precision is shown in Equation ( <ref type="formula">2</ref>), where N positive denotes the number of true positives among the top K closest instances.</p><formula xml:id="formula_5">positive N precision K  (2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EXPERIMENTAL EVALUATION</head><p>We begin by noting that all experiments (including all the figures above) are completely reproducible. All experimental code and data (and additional experiments omitted for brevity) are archived in perpetuity at <ref type="bibr" target="#b36">[36]</ref>.</p><p>For all experiments, we divide the data into two mutually exclusive datasets: the learning dataset and the holdout dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>Learning dataset: The learning dataset is used in the SSL process to train the classifier. It is divided into the labeled dataset P and the unlabeled dataset U. The labeled dataset includes a single positive example, which is a randomly selected true positive object from the learning dataset. The rest of objects in the learning dataset are regarded as unlabeled objects and are included in U.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>Holdout dataset: The holdout dataset is used to test the accuracy of the learned classifier. Objects in the holdout dataset are hidden from the SSL process. The performance of the trained classifier can be sensitive to the initial training (labeled) example. To mitigate this sensitivity, for each experiment, we repeat the training process by each time starting from a different training example. In particular, we allow each positive object in the learning dataset to be used as the initial training example once, and average the accuracy of the classifier over all runs.</p><p>To show the changes in the performance of the classifier as the labeled dataset P is gradually augmented, we show the average accuracy for each size of P. That is, we evaluate the classifier using the holdout dataset each time an unlabeled object is added to P. Thus all figures shown below show the holdout accuracy.</p><p>For each experiment, we compare the performance of three different classifiers, the classifier using ED, the classifier using DTW, and the classifier using DTW-D. All three classifiers are trained using the same SSL algorithm as shown in Table <ref type="table" target="#tab_2">4</ref>. The only difference among them is the distance function used. As we shall show, by simply changing the distance function from ED or DTW to DTW-D, we can improve the performance of SSL algorithms for time series by a significant amount.</p><p>In all our experiments, DTW-D learns from a single positive example. There is nothing about our technique that requires this. We simply wish to show we can learn under the most hostile assumptions.</p><p>We also compare our idea with rival time series SSL approaches <ref type="bibr" target="#b16">[16]</ref> <ref type="bibr" target="#b25">[25]</ref>. In order to be scrupulously fair to the rival approaches, we allow them to "cheat" by starting with more training examples. As we shall show, even given this severe disadvantage, our algorithm still significantly outperforms the rival approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Insect Wingbeat Sound Detection</head><p>In this experiment, we would like to detect insect wing-beat sounds from unstructured audio streams. The insect used in this experiment is Culex quinquefasciatus female. The wingbeat sounds are acquired using the sensors described in <ref type="bibr" target="#b1">[1]</ref>, and the data stream also contains diverse negative data, including speech/music etc.</p><p>For this experiment, we randomly select 1,000 insect sounds and 4,200 non-insect segments. The length of each sound snippet is 0.1 second. All the sound data are first converted into "time series" using DFT <ref type="bibr" target="#b1">[1]</ref>. Based on entomological advice, we preserve only the coefficients corresponding to the frequency range between 200 and 2,000, because all other coefficients are unlikely to be the result of insect activity.</p><p>We divide the time series dataset into two parts: a learning dataset with 500 insect sounds and 2000 non-insect sounds, and a holdout dataset with 500 insect sounds and 2,200 radio sounds.</p><p>The SSL process is repeated 500 times, each time starting with a different training example. For each run, we trained three classifiers, the NN classifier using ED distance, the NN classifier using DTW and the NN classifier using DTW-D. The average performance of the three classifiers over 500 runs for each size of P is shown in Figure <ref type="figure" target="#fig_10">13</ref>. The results are impressive, given that the default accuracy is just 20%. With DTW-D, we can converge on greater than 95% accuracy. The DTW-D classifier consistently outperforms the other two classifiers across the entire range of values for P. Note that, after the size of P reaches 150, the accuracy of the ED classifier begins to decrease. As we might expect, the DTW classifier's invariance to warping allows it both to start from a higher baseline, and keep improving for a longer time. However it too is doomed to eventually add true negatives into P and begin a rapid decrease in performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Why is DTW-D better?</head><p>While DTW-D is clearly better than its rivals, Figure <ref type="figure" target="#fig_10">13</ref> does not tell us why. In particular we may ask if it is because: DTW-D generally selects better labeled objects during the SSL process, or because DTW-D selects better top K nearest neighbors from the holdout dataset in the classifier's evaluation process (recall that K is the number of true positives in the holdout dataset).</p><p>To answer this question, we conducted a combinatorial experiment in which we crippled DTW-D independently in each phase (training/evaluating).</p><p>For example, to see if DTW-D selects better labeled objects than DTW, we train two NN classifiers, one using DTW-D and one using DTW. We then evaluate both classifiers using the same holdout dataset. In the evaluation process, we use the same distance function (DTW) to find the top K nearest neighbors for both classifiers. In this way, we ensure that the only difference between the two classifiers is the use of two different distance functions in the training process.</p><p>The experiment to see if DTW-D is better at selecting the top K nearest neighbors during evaluation process is similar. This time, we train only one classifier, the NN classifier using DTW. In the evaluating process, we use two different distance functions, DTW and DTW-D, to find the top K nearest neighbors for this classifier. In this experiment, the labeled dataset learned from the training process is the same. The only difference is the use of different distance functions in the evaluation process.</p><p>Figure <ref type="figure" target="#fig_11">14</ref> shows the results of the combinatorial experiment for this dataset. The results show that DTW-D is superior to ED and DTW in both the training (exemplar choosing) and evaluation (the later classification) processes. The results shown in Figure <ref type="figure" target="#fig_11">14</ref> are generally true for all the experiments done in this work. For brevity, we omit these results for the following applications, but archive them in <ref type="bibr" target="#b36">[36]</ref> for interested readers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Comparison to rival methods</head><p>We compare our algorithm with the widely-used rival approaches that are specially designed for time series <ref type="bibr" target="#b16">[16]</ref> <ref type="bibr" target="#b25">[25]</ref>. In the comparison, we favor our rival approaches by offering them with fifty more initial labeled examples. That is, through the entire range of comparison, our rivals always have fifty more labeled objects in their labeled dataset than our method. Recall that our algorithm starts with a single labeled example, thus the rival methods have a fiftyfold advantage here. Figure <ref type="figure" target="#fig_13">15</ref> shows the results for this dataset.  As we can see, our method was not as good as the rivals at the beginning. This is hardly surprise given that the rival methods had fifty times as many labeled objects. However, using DTW-D, our method intelligently selects objects from the unlabeled dataset U to expand the labeled set P. After adding just nine objects, we beat Wei's method. This is very impressive because this happened when we have only ten labeled objects while our rivals have sixty. In other words, we evaluate our classifier with the holdout dataset with only ten labeled objects while our rivals have sixty labeled objects. We are doing better here because while both methods have added nine objects, DTW-D made better choices of what to add. Ratana's method is beaten after adding 21 objects.</p><p>In addition, as can be seen from Figure <ref type="figure" target="#fig_13">15</ref>, our method continues to do better after we beat the rivals, which implies that whatever stopping criterion is used, we will always do better. In this example, Wei's method stops after adding 103 objects. Ratana's method stops after adding 62 objects. No matter if we stop at 62 or 103 or any other position greater than 21, we are always better than the rivals.</p><p>It might be imagined that the two rival methods <ref type="bibr" target="#b16">[16]</ref>[25] do (eventually) make better decisions about which objects to add, but are crippled by too conservative a stopping criteria. However, to be clear, this is not the case. When the two algorithms terminate, they have labeled everything in the learning dataset. Thus, there are no actions (wise or unwise) left for them to perform.</p><p>In addition to <ref type="bibr">[16][25]</ref>, there is only one other semi-supervised approach for time series that we are aware of. In <ref type="bibr" target="#b19">[19]</ref>, the authors introduce a technique that interleaves exemplar selection with feature selection. We do not compare to this work for the following reasons: The work assumes that the positive class objects are similar to each other, and the negative class objects are similar to each other. For this reason they test on a subset of the UCR archive datasets, with one class acting as P and another class acting as U. This is in sharp contrast to our more relaxed assumption that only positive class objects are similar to each other. We make no such assumptions about the negative class. Our initial attempts to test their algorithm with our assumptions (the authors generously donated their code), yielded very poor results, but in fairness, the authors made no claims about the utility of their ideas for our problem statement/assumptions.</p><p>The comparison results shown in Figure <ref type="figure" target="#fig_13">15</ref> are generally true for all experiments done here. For brevity, we omit these results for the following applications, but archive them in <ref type="bibr" target="#b36">[36]</ref> for interested readers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Historical Manuscript Mining</head><p>We can apply "time series" SSL to detect particular image patches in historical manuscripts <ref type="bibr" target="#b32">[32]</ref>. These manuscripts often are hand colored over years, thus some warping is needed to detect the similarity of the ("drifting") color distributions, as shown in Figure <ref type="figure" target="#fig_14">16</ref>.</p><p>The task in this application is to detect examples of the Fugger of the Deer heraldic shield from a huge manuscript <ref type="bibr" target="#b35">[35]</ref>. Data used in this experiment includes 67 positive Fugger shields and 828 negative patches selected from the same manuscript <ref type="bibr" target="#b35">[35]</ref>. Each image patch is converted to a RGB color histogram, which is normalized using sum-to-one normalization to eliminate the variability of image size. Figure <ref type="figure" target="#fig_14">16</ref>.right shows two examples of the converted color histograms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Red</head><p>Green Blue Again, we first divide the data into two datasets: a learning dataset with 16 positive objects and 207 negative ones, and a holdout dataset with 51 positive objects and 621 negative ones. We repeat the SSL process 16 times, each time starting from a different training seed. Figure <ref type="figure" target="#fig_16">17</ref> shows the averaged holdout accuracy of the three classifiers for different sizes of P.  The default holdout accuracy is 51/672, which is about 7.6%. With DTW-D, we can achieve more than 90% accuracy. The performance of the DTW classifier is much better than the ED classifier, which is not surprising since, as we noted before, there is clearly some warping in the color distributions of objects belonging to a same class.</p><p>Note that in Figure <ref type="figure" target="#fig_16">17</ref>, there is a rapid decrease in the accuracy of the ED classifier when the size of P reaches 12. With inspection we find this decrease is caused by the first false positive that is added into P at the point (on average). This false positive object in P corrupts the concept of the positive class, resulting in more negative objects added to P, and thus, decreasing the classifier's accuracy. Although the DTW classifier's invariance to warping enables it to have a higher accuracy as well as to keep improving for a longer time, it too experiences a rapid decrease when the size of P reaches 14, where it (on average) mistakenly accepts its first true negative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Activity Recognition</head><p>We finally consider a widely studied benchmark dataset that contains data of 18 different activities, such as running, ropejumping, ironing, vacuum-cleaning, performed by 9 subjects wearing 3 inertial measurement units (IMUs) <ref type="bibr" target="#b21">[21]</ref>. We randomly pick one such activity as the positive class and treat the rest as negative.</p><p>Figure <ref type="figure" target="#fig_18">18</ref> shows the results for an example experiment where vacuum cleaning is considered as the positive activity. We randomly select 400 positive segments and 1,600 negative ones from the dataset, and divide the selected data into two datasets, the learning dataset with 100 positive objects and 400 negative objects, and the holdout dataset with 300 positive objects and 1,200 negatives. The SSL process is repeated 100 times, each time starting from a different training seed. The results show that the DTW-D classifier both starts from a higher baseline and continues to improve over the entire range of values. In contrast, both ED and DTW start from a lower baseline and eventually get worse.</p><p>We remind the reader that as with all experiments in this work, the three lines in this figure are based on identical data, identical conditions and identical algorithms. The only difference is the distance measure used, thus we can safely attribute all improvement observed to DTW-D.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSION AND FUTURE WORK</head><p>We have introduced a simple idea that dramatically improves the quality of SSL in time series domains. We have conducted our experiments such that all improvements observed can be only attributed to the use of DTW-D.</p><p>Our work has the following advantages: It is completely parameter-free, and thus requires no tuning/tweaking. It allows the use of existing state-of-the-art indexing methods and fast similarity search methods <ref type="bibr" target="#b6">[6]</ref>. The time and space overhead are inconsequential, as is the coding effort; requiring only a single line of code to be changed. While we choose the simplest SSL method to demonstrate our ideas, they can trivially used with any SSL algorithm.</p><p>Future work includes revisiting the stopping criteria issue in light of DTW-D, and considering other avenues where DTW-D may be useful.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A complete linkage hierarchical clustering of two items from the Trace dataset with three random walks. From left to right, Euclidean distance (ED), Dynamic Time Warping (DTW) and Dynamic Time Warping-Delta (DTW-D), our proposed technique.As we can see, Euclidean Distance does poorly here. This is not surprising, since the Trace dataset is known to have classes that contain exemplars that are time-warped versions of a prototypical shape. Indeed, we see that DTW does manage to do better, reducing the distance between Trace-1 and Trace-2. However, this reduction is not enough; random-walk-3 is still closer to Trace-1 than Trace-2 is.Our key observation is that moving from ED to DTW seems to help the true class data more than the random unstructured data. We can encode this difference/delta that DTW makes with DTW-D, the ratio of DTW over ED. And as we see in Figure1.right, this does produce the correct clustering, at least in this example.Imagine that we had been doing semi-supervised learning in this dataset using just Trace-1 as our sole positive example. For both ED and DTW, the very first item we added to the positive set would have been a false positive, and it would be very difficult for any algorithm to recover from this. In contrast, DTW-D would have correctly suggested Trace-2 as the next item to add, and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: top) A labeled dataset P that consists of a single object P 1 . bottom) The unlabeled dataset consist of a single true negative U 1 and a single true positive U 2 .Suppose we ask any SSL algorithm to choose one object from U to add to P using the Euclidean distance. As we can see in Figure3, U 1 is much closer to P 1 than U 2 is, thus our SSL algorithm would do poorly here.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 Figure 5 :</head><label>55</label><figDesc>Figure 5: A visualization of the three distance matrices shown in Table 1 and Table 2 under complete linkage hierarchical clustering.Note that there is one minor special case we need to consider. If the ED is zero, then DTW-D would give a divide-by-zero error. We simply define this special case as having a value of zero. If the ED distance (and therefore also the DTW distance) between two objects is zero, it would be perverse to call them anything but the same class. This is a moot point, as we never expect observe perfect duplicates for real-values objects.We have now concretely seen the problem with using ED/DTW for SSL, and our suggested fix, on a toy problem. However, it is natural to ask when this phenomenon actually occurs in the realworld, and would be amenable to our DTW-D solution. In the next section, we explicitly discuss our assumptions about when our ideas can help.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The two examples from "Trace" shown in Figure 1 compared under ED and DTW. In this plot, the distances are proportional to the variance of the y-axis lengths of the hatch lines. Thus the longer and shorter hatch lines in ED contribute to its large distance, whereas the y-axis lengths for DTW are almost the same, producing a small distance.This ability of DTW to compensate for the inherent warping in this class can produce a dramatic difference in classification accuracy. In the UCR Archive dataset the four-class Trace data is provided with a 100/100 train test split. The ED error rate on this dataset is 0.24, whereas DTW has an error-rate of 0.0. Since the exact same splits and classification algorithm (1NN) were used, and zero parameters are tuned for either approach, all of this difference can be attributed to the superiority of DTW over ED.Assumption 2: The negative class may be very diverse, and occasionally by chance produces objects close to a member of the positive class, even under DTW. Empirically, negative classes do tend to be diverse[15][30]. For example, there are only a limited number of ways an audio snippet can sound like a mosquito, but there are infinite ways a sound can be a non-mosquito (c.f. Section 6.1). Once again, this assumption was illustrated by our toy example in Figure1. The random walk class is naturally very diverse, and it can (and did) produce an instance that is closer to Trace-1 than the other member of the positive class (Trace-2).It is central claim that if the two assumptions are true for a given problem, our novel scoring function DTW-D will be better than either ED or DTW. As these are the central assumptions, we will next consider when we might expect them to be true.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The probability that the first object added to P is a true positive as the number of labeled objects increases, for three distance measures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: The probability the first object added is a true positive as the number of true negatives in U increases.Again this figure strongly supports our assumption. When we have relatively few true negatives, all methods work well. However, as the number of true negatives in U increases, ED rapidly deteriorates. In contrast, DTW deteriorates more slowly. Remarkably, however, DTW-D is completely unaffected by a surfeit of true negatives, maintaining perfect accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: The experiment shown in Figure 1 after replacing the three random walks with three random third-degree polynomials.The results here are visually jarring. It is important to emphasize that this is not the result of an error, contriving of the data, or crippling the ED/DTW in any way. It is simply the case that low complexity time series have a tendency to have a small distance to all other objects.Apart from<ref type="bibr" target="#b2">[2]</ref>, other works have indirectly noted this phenomenon. For example,<ref type="bibr" target="#b12">[12]</ref> notes that if we average all subsequences in a long time series, we will get a constant line, which is surely the least complex time series under any definition. Implicitly, this means that a constant line is the time series with minimal expected distance to any randomly chosen time series.Thus, if the negative class is complex, we should expect the DTW or even ED will work well for semi-supervised learning. To see this, we can repeat the experiment shown in Figure1/Figure9after replacing negative class with pure random vectors. Note that while we may consider random vectors as "noisy", it is incidental to the point that they are complex.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: The experiment shown in Figure 1/Figure 9 after replacing the negative class with random vectors.Figure10demonstrates that when the unlabeled data are complex, even ED has little trouble in grouping the positive class.Beyond the visual evidence shown in Figure9and Figure10, we can test our observation with another simple experiment. Once more we perform an experiment that generalizes our toy example. We created a labeled dataset P that contains just one exemplar from Class 3 of Trace. This time U contains one true positive and 200 random time series that are approximated by k non-zero DFT coefficients, with k ranging from 5 to 20. Figure11shows some examples of series that are approximated by 5 and 20 nonzero DFT coefficients respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: left) Two time series examples that are created using 5 non-zero DFT coefficients. right) Two time series examples that are created using 20 non-zero DFT coefficients. Clearly the latter are more complex.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>20 Figure 12 :</head><label>2012</label><figDesc>Figure 12: The probability the first object added is true negative as the negative objects increase in complexity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: The average accuracy of the three classifiers for different size of P, evaluated using the holdout dataset.The results are impressive, given that the default accuracy is just 20%. With DTW-D, we can converge on greater than 95%</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: top) Comparison of DTW-D with DTW / DTW-D with ED, to see if DTW-D helps the training process by selecting better exemplars. bottom) Comparison of DTW-D with DTW / DTW-D with ED, to see if DTW-D helps the evaluating process by selecting better top K nearest neighbors.The results show that DTW-D is superior to ED and DTW in both the training (exemplar choosing) and evaluation (the later classification) processes. The results shown in Figure14are generally true for all the experiments done in this work. For brevity, we omit these results for the following applications, but archive them in<ref type="bibr" target="#b36">[36]</ref> for interested readers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Gray curve: The algorithms have stopped adding objects to the labeled set</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 15 :</head><label>15</label><figDesc>Figure 15: Comparison of our SSL method using DTW-D with two rival methods in the literature. The curves show the average performance of classifiers over 100 runsAs we can see, our method was not as good as the rivals at the beginning. This is hardly surprise given that the rival methods had fifty times as many labeled objects. However, using DTW-D, our method intelligently selects objects from the unlabeled dataset U to expand the labeled set P. After adding just nine objects, we beat Wei's method. This is very impressive because this happened when we have only ten labeled objects while our rivals have sixty.In other words, we evaluate our classifier with the holdout dataset with only ten labeled objects while our rivals have sixty labeled objects. We are doing better here because while both methods have added nine objects, DTW-D made better choices of what to add. Ratana's method is beaten after adding 21 objects.In addition, as can be seen from Figure15, our method continues to do better after we beat the rivals, which implies that whatever stopping criterion is used, we will always do better. In this example, Wei's method stops after adding 103 objects. Ratana's method stops after adding 62 objects. No matter if we stop at 62 or 103 or any other position greater than 21, we are always better than the rivals.It might be imagined that the two rival methods<ref type="bibr" target="#b16">[16]</ref>[25] do (eventually) make better decisions about which objects to add, but are crippled by too conservative a stopping criteria. However, to be clear, this is not the case. When the two algorithms terminate, they have labeled everything in the learning dataset. Thus, there are no actions (wise or unwise) left for them to perform.In addition to[16][25], there is only one other semi-supervised approach for time series that we are aware of. In<ref type="bibr" target="#b19">[19]</ref>, the authors introduce a technique that interleaves exemplar selection with feature selection. We do not compare to this work for the following reasons: The work assumes that the positive class objects are similar to each other, and the negative class objects are similar to each other. For this reason they test on a subset of the UCR archive datasets, with one class acting as P and another class acting as U. This is in sharp contrast to our more relaxed assumption that only positive class objects are similar to each other. We make no such assumptions about the negative class. Our initial attempts to test their algorithm with our assumptions (the authors generously donated their code), yielded very poor results, but in fairness, the authors made no claims about the utility of their ideas for our problem statement/assumptions.The comparison results shown in Figure15are generally true for all experiments done here. For brevity, we omit these results for the following applications, but archive them in<ref type="bibr" target="#b36">[36]</ref> for interested readers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: left) A page from a 16th century text [35] shows three heraldic shields including that of Fugger vom Reh (Fugger of the Deer) granted to Andreas Fugger in 1464. right) Two additional examples of the shield from the same text have been converted to RGB color histograms and compared using DTW.Again, we first divide the data into two datasets: a learning dataset with 16 positive objects and 207 negative ones, and a holdout dataset with 51 positive objects and 621 negative ones. We repeat the SSL process 16 times, each time starting from a different training seed. Figure17shows the averaged holdout accuracy of the three classifiers for different sizes of P.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: The average accuracy of the three classifiers for different size of P, evaluated using the holdout dataset.The default holdout accuracy is 51/672, which is about 7.6%. With DTW-D, we can achieve more than 90% accuracy. The performance of the DTW classifier is much better than the ED classifier, which is not surprising since, as we noted before, there is clearly some warping in the color distributions of objects belonging to a same class.Note that in Figure17, there is a rapid decrease in the accuracy of the ED classifier when the size of P reaches 12. With inspection we find this decrease is caused by the first false positive that is added into P at the point (on average). This false positive object in P corrupts the concept of the positive class, resulting in more negative objects added to P, and thus, decreasing the classifier's accuracy. Although the DTW classifier's invariance to warping enables it to have a higher accuracy as well as to keep improving for a longer time, it too experiences a rapid decrease when the size of P reaches 14, where it (on average) mistakenly accepts its first true negative.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 18 :</head><label>18</label><figDesc>Figure 18: The average accuracy of the three classifiers for different size of P, evaluated using the holdout dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 : The Ratio of the ED and DTW Distances Shown in Table 1. This ratio is called DTW-D</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell>DTW/ED</cell><cell></cell><cell cols="3">DTW-D = DTW/ED</cell></row><row><cell>P 1</cell><cell>U 1</cell><cell>U 2</cell><cell>P 1</cell><cell>U 1</cell><cell>U 2</cell></row><row><cell>P 1 0</cell><cell cols="2">5.8/6.2 6.1/11</cell><cell>0</cell><cell>0.93</cell><cell>0.55</cell></row><row><cell>U 1</cell><cell>0</cell><cell>6.5/6.8</cell><cell></cell><cell>0</cell><cell>0.95</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 : Our Proposed Distance Measure function</head><label>3</label><figDesc></figDesc><table><row><cell>distance = DTW-D(x, y)</cell></row><row><cell>distance = DTW(x,y) / (ED(x,y) + eps);</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 : Time Series Semi-supervised Learning Algorithm Function</head><label>4</label><figDesc></figDesc><table><row><cell>Input:</cell><cell>P, the initial training dataset with a single training object</cell></row><row><cell></cell><cell>U, the unlabeled dataset</cell></row><row><cell></cell><cell>distance, the distance function</cell></row><row><cell></cell><cell>N, the number of objects to be moved from U to P</cell></row><row><cell>Output:</cell><cell>a trained classifier (for a NN classifier, it is the learned P)</cell></row><row><cell>1</cell><cell>function P = Train_Classifier ( P, U, distance, N)</cell></row><row><cell>2</cell><cell>for iterations = 1 : N</cell></row><row><cell>3</cell><cell>NNObject = findUnlabeledNN( P, U, distance);</cell></row><row><cell>4 5 6 7 8 9 10 11 12 13</cell><cell>P = [P, NNObject]; U = U -NNObject ; return P; end end function NNObject = findUnlabeledNN ( P, U, distance) // update P // update U Dist = zeros(1, |U|); for i = 1 : |U| Dist (i) = min j = 1,…|P| distance(U i ,P j ); end</cell></row></table><note><p>P = Train_Classifier (P, U, distance, N)</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In Figure</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>the objects are shown to the same scale. They are not normalized for visual clarity. However, our analysis can be demonstrated for z-normalization, min/max normalization etc.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We gratefully acknowledge funding from NSF IIS-1161997, Vodafone, FAPESP-2012/07295-3, and all the data donors.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<author>
			<persName><forename type="first">G</forename><surname>Batista</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mafra-Neto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rowton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD demo: Sensors and Software to allow Computational Entomology, an Emerging Application of Data Mining</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="761" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">G</forename><surname>Batista</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">A Complexity-Invariant Distance Measure for Time Series</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="699" to="710" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>SDM</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automatic classification of heartbeats using ECG morphology and heartbeat interval features</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chazal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>O'dwyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Reilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Biomed Eng</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="1196" to="1206" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Particle swarm optimization based semisupervised learning on Chinese text categorization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Qin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">CEC</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Effective Self-Training for Parsing</title>
		<author>
			<persName><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Eugene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johnson</forename><surname>Mark</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="152" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Querying and mining of time series data: experimental comparison of representations and distance measures</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Trajcevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Scheuermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1542" to="1552" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Goldberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PhysioToolkit, and PhysioNet: New Research Resource for Complex Physiologic Signals</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page">2000</biblScope>
		</imprint>
	</monogr>
	<note>Circulation</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Multimodal semi-supervised learning for image classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="902" to="909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Google&apos;s Total Library: Putting the World&apos;s Books on the Web</title>
		<author>
			<persName><forename type="first">M</forename><surname>Herwig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<title level="m">Time Series Classification under More Realistic Assumption, SDM</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Ratanamahatana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename></persName>
		</author>
		<title level="m">The UCR Time Series Classification/Clustering Homepage</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Clustering of time-series subsequences is meaningless: implications for previous and future research</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KAIS</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="154" to="177" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">LB_Keogh Supports Exact Indexing of Shapes under Rotation Invariance with Arbitrary Representations and Distance Measures</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vlachos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="882" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Lenser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Veloso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Non-Parametric Time Series Classification</title>
		<imprint>
			<biblScope unit="volume">ICRA</biblScope>
			<biblScope unit="page" from="3918" to="3923" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learning to classify text using positive and unlabeled data</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">IJCAI</biblScope>
			<biblScope unit="page" from="587" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Semi-supervised time series classification</title>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>ACM SIGKDD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gene identification in novel eukaryotic genomes by self-training algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lomsadze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6494" to="6506" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A self-trained ensemble with semisupervised SVM: An application to pixel classification of remote sensing imagery</title>
		<author>
			<persName><forename type="first">U</forename><surname>Maulik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chakraborty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="615" to="623" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Positive unlabeled learning for time series classification</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">2011</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visualization of Multivariate Time Series Data in a Neonatal ICU</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ordóñez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Physical Activity Monitoring for Aging People</title>
		<author>
			<persName><surname>Pamap</surname></persName>
		</author>
		<ptr target="www.pamap.org/demo.html" />
		<imprint>
			<date type="published" when="2012-05-12">2012-05-12</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Discovering arbitrary event types in time series</title>
		<author>
			<persName><forename type="first">D</forename><surname>Preston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Protopapas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Brodley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Analysis and Data Mining</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="396" to="411" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Semi-supervised learning of compact document representations with deep networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Szummer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">ICML</biblScope>
			<biblScope unit="page" from="792" to="799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Raptis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wnuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<title level="m">Flexible Dictionaries for Action Recognition, MLVMA/ECCV</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Stopping Criterion Selection for Efficient Semi-supervised Time Series Classification</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Ratanamahatana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wanichsan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SNPD</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2008">2012. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Rath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Word Image Matching Using Dynamic Time Warping</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="521" to="527" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Semi-Supervised Self-Training of Object Detection Models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schneiderman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">WACV</biblScope>
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semi-supervised Semantic Pattern Discovery with Guidance from Unsupervised Pattern Clusters</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">COLING</title>
		<imprint>
			<biblScope unit="page" from="1194" to="1202" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Bayesian time series classification</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sykacek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Roberts</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="937" to="944" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">One-class classification: Concept-learning in the absence of counter-examples</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M J</forename><surname>Tax</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>Butterworths</publisher>
			<pubPlace>London, England</pubPlace>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Annotating Historical Archives of Images</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Shelton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJDLS</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="59" to="80" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Fast time series classification using numerosity reduction</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Shelton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Ratanamahatana</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">ICML</biblScope>
			<biblScope unit="page" from="1033" to="1040" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Semi-Supervised Learning Literature Survey</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<idno>no. 1530</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Computer Sciences, University of Wisconsin-Madison</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Das</forename><surname>Ehrenbuch Der Fugger</surname></persName>
		</author>
		<title level="m">The secret book of honour of the Fugger) -BSB Cgm 9460</title>
		<meeting><address><addrLine>Augsburg, ca</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="1545" to="1548" />
		</imprint>
	</monogr>
	<note>mit Nachträgen aus späterer Zeit</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<ptr target="https://sites.google.com/site/yanpingdtwd/" />
		<title level="m">Supporting webpage</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
