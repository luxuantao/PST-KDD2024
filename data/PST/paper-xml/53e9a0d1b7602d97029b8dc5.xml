<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Collaboration Over Time: Characterizing and Modeling Network Evolution</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jian</forename><surname>Huang</surname></persName>
							<email>jhuang@ist.psu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information Sciences and Technology</orgName>
								<orgName type="institution">Pennsylvania State University University Park</orgName>
								<address>
									<postCode>16802</postCode>
									<region>PA, US</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ziming</forename><surname>Zhuang</surname></persName>
							<email>zzhuang@ist.psu.edu</email>
							<affiliation key="aff1">
								<orgName type="department">College of Information Sciences and Technology</orgName>
								<orgName type="institution">Pennsylvania State University University Park</orgName>
								<address>
									<postCode>16802 US</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
							<email>jiali@psu.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">Pennsylvania State University University Park</orgName>
								<address>
									<postCode>16802</postCode>
									<region>PA, US</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">C</forename><forename type="middle">Lee</forename><surname>Giles</surname></persName>
							<email>giles@ist.psu.edu</email>
							<affiliation key="aff3">
								<orgName type="department">College of Information Sciences and Technology</orgName>
								<orgName type="institution">Pennsylvania State University University Park</orgName>
								<address>
									<postCode>16802</postCode>
									<region>PA, US</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Collaboration Over Time: Characterizing and Modeling Network Evolution</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3746F740D2E08F228C5A1BDF5C673E8A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.5.1 [Pattern Recognition]: Models-statistical ; H.3.7 [Information Storage and Retrieval]: Digital Libraries Algorithms</term>
					<term>Experimentation</term>
					<term>Measurement Social Network Analysis (SNA)</term>
					<term>network evolution</term>
					<term>stochastic network modeling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A formal type of scientific and academic collaboration is coauthorship which can be represented by a coauthorship network. Coauthorship networks are among some of the largest social networks and offer us the opportunity to study the mechanisms underlying large-scale real world networks. We construct such a network for the Computer Science field covering research collaborations from 1980 to 2005, based on a large dataset of 451,305 papers authored by 283,174 distinct researchers. By mining this network, we first present a comprehensive study of the network statistical properties for a longitudinal network at the overall network level as well as for the intermediate community level. Major observations are that the database community is the best connected while the AI community is the most assortative, and that the Computer Science field as a whole shows a collaboration pattern more similar to Mathematics than to Biology. Moreover, the small world phenomenon and the scale-free degree distribution accompany the growth of the network. To study the individual collaborations, we propose a novel stochastic model, Stochastic Poisson model with Optimization Tree ( Spot), to efficiently predict any increment of collaboration based on the local neighborhood structure. Spot models the non-stationary Poisson process by maximizing the log-likelihood with a tree structure. Empirical results show that Spot outperforms Support Vector Regression by better fitting collaboration records and predicting the rate of collaboration.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>We study the evolution of real-world networks by characterizing and modeling a specific type of social network, the scientific collaboration network. Scientific collaboration leverages the intellectual and material resources in academia and research and greatly benefits the community. Because a predominant form of scientific collaboration is coauthorship, a collaboration network can be portrayed by vertices representing researchers and edges corresponding to coauthored papers. Over time, the evolution of such a network records and reflects the growth of an academic field, shedding light on its future development.</p><p>Our work investigates three levels of analysis of networks at different scales. The highest network level analysis characterizes the pattern of network evolution using various network statistics. Such measurements enable us to show that the underlying growth pattern manifests the wellknown small world phenomenon. At the intermediate community level, we study the evolution of the structure of autonomously-formed connected components. Visualization of topical communities reveals the distinctive collaboration patterns in each community. At the lowest individual level, we propose a novel stochastic model, Stochastic Poisson model with Optimization Tree ( Spot), to efficiently predict future collaboration between individuals based on their local neighborhood structure. Contributions: Our contributions are as follows:</p><p>Table <ref type="table">1</ref>: Comparison of the statistical properties of several coauthorship networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Network</head><p>CiteSeer NCSTRL comprehensive and focused study of the large-scale scientific collaboration network in Computer Science. It investigates networks at three different granularities and provides insights into the distinct collaboration patterns in six topical communities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">A novel stochastic model (Spot) is proposed for</head><p>individual collaboration prediction, which shows superior performance over Support Vector Regression <ref type="bibr" target="#b30">[30]</ref>. Spot is efficient by exploiting local neighborhood information and is generalizable to other types of networks.</p><p>Organization: We first briefly review related work, and present our findings on the static and dynamic properties of the Computer Science collaboration network on both the network level and the community level. We then focus on the individual level, proposing the Spot model to investigate how the collaboration between a particular pair of authors evolves over time. Finally we conclude with plans for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Static properties of various social networks have been studied in the context of epidemiological networks <ref type="bibr" target="#b17">[17]</ref>, online newsgroups <ref type="bibr" target="#b5">[5]</ref>, blogs and photo sharing websites <ref type="bibr" target="#b13">[13]</ref>, citation networks <ref type="bibr" target="#b14">[14]</ref>, the database research community <ref type="bibr">[9]</ref>, etc. Many of these networks follow a power-law degree distribution and exhibit the "small world phenomenon" <ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b2">2]</ref>. Recent studies <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b14">14]</ref> on the network dynamics and evolution reveal some interesting growth patterns, e.g. a gradually shrinking diameter and degree densification in the citation networks which can be explained by the Forest Fire model <ref type="bibr" target="#b14">[14]</ref>. Social capital can be quantified for predicting event participation in a friendship-event network <ref type="bibr" target="#b16">[16]</ref>.</p><p>Recently, Newman applied modern network analysis techniques to study the static network properties of several coauthorship network, such as MEDLINE (biomedicine), SPIRES (high energy physics), NCSTRL (Computer Science preprints) <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b25">25]</ref>. Barabási et al <ref type="bibr" target="#b4">[4]</ref> studied the dynamics of coauthorship networks using the Maths and Neuroscience networks as prototypes <ref type="bibr" target="#b4">[4]</ref>. These studies however only focused on the macroscopic network properties. Other studies on these networks have also revealed some distinctive properties, e.g. the mixing pattern (i.e. positive or negative assortativity, which indicates the tendency of nodes linking to others that have a similar or dissimilar degree distribution) <ref type="bibr" target="#b24">[24]</ref>. The component structure of such networks represents smaller research communities of different sizes, and communities can be discovered through clustering <ref type="bibr" target="#b29">[29]</ref>.</p><p>Preferential attachment <ref type="bibr" target="#b3">[3]</ref> (i.e. the tendency of a new node connecting to an existing node in the network is proportional to its degree) is probably the best known mechanism for depicting the scale-free networks. For collaboration (coauthorship) networks, Barabási et al <ref type="bibr" target="#b4">[4]</ref> extended preferential attachment to model the web of science. Although the proposed model can simulate networks in terms of global network statistics (e.g. exponents) by only taking into account node degrees, one can not generally infer the probability that a pair of nodes in the network will in the future collaborate. Recently, Newman found that the probability of scientists to collaborate increases with the number of common collaborators and there is a positive correlation between the number of past collaborations and future (repeat) collaborations <ref type="bibr" target="#b20">[20]</ref>. Liben-Nowell and Kleinberg <ref type="bibr" target="#b15">[15]</ref> formalized this as the link prediction problem, and studied the effect of various network proximity measures for predicting the addition of edges in the coauthorship network. These informative structural features in the node's neighborhood, combined with the available exogenous extracted information in our datasets, will be used in the statistical model for predicting the number of collaborations in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DATA COLLECTION</head><p>We studied the evolution of scientific collaboration using data drawn from the CiteSeer Digital Library<ref type="foot" target="#foot_0">1</ref> . CiteSeer is a popular digital library with a focus on computer and information sciences and consists of more than 700,000 academic papers. From CiteSeer, we extracted the metadata of these papers <ref type="bibr" target="#b10">[10]</ref>, including titles, authors, affiliations, physical/email addresses, publication years, etc. To minimize the impact of the author name ambiguity problem, we used the author disambiguation techniques proposed in <ref type="bibr" target="#b11">[11]</ref> so that each vertex in this network represents a distinct author. We obtain a large dataset (denoted by CS ) consisting of 283,174 unique authors and 451,305 papers published between 1980 and 2005 (Figure <ref type="figure" target="#fig_0">1</ref>:left). In Table <ref type="table">1</ref> we compare our network with several other coauthorship networks in the literature <ref type="bibr" target="#b1">[1]</ref>. To study collaboration in a more fine-grained fashion, we decomposed and mapped the data into six topical datasets (Table <ref type="table" target="#tab_0">2</ref>): Artificial Intelligence (ai), Applications (app), Architecture (arch), Database (db), System (system), and Theory (theory). We obtained a list of representative conferences in each topic from Computer Science Conference Rankings 2 . We matched the names of these conferences with the venue information extracted from the paper metadata and constructed six datasets. Each dataset contains papers published in the representative conferences corresponding to a particular topic. For consistency, we intentionally selected approximately 1,700 papers for each topic, yielding 11,820 authors and 10,195 papers in total.</p><p>To capture the dynamics of the growing network, we used a "snowball sampling" approach. Using the publication timestamps of the papers, we generated a series of 25 yearby-year snapshots for the CS dataset. Each snapshot at time t is represented by G(t) = (V, E), where every vertex v ∈ V represents an author, and a pair of authors u and v are connected by an edge u, v ∈ E if and only if they have coauthored one or more papers. For any given timestamp t, G(t) contains all the vertices and edges that have appeared up to time t. For example, the snapshot G(2001) contains all the authors who have published between 1980 and 2001, and G(2005) represents all the author and paper information in the CS dataset.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CHARACTERIZING NETWORK EVOLUTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">More Collaboration in a Smaller World</head><p>Collaboration among authors becomes increasingly popular as evidenced in our 25 snapshots (Figure <ref type="figure" target="#fig_0">1</ref>:right). Over the past 25 years, the average number of collaborators per author has been steadily increasing, and so has the average number of authors per paper but at a much slower pace (from 2 authors per paper in 1980 to 2.55 in 2005).</p><p>The growth pattern of the network can be also investigated by examining the diameter and the average distance between a pair of authors in the collaboration network over time. Distance is defined here as the number of hops from one vertex to another and diameter as the longest distance between two vertices. As shown in Figure <ref type="figure" target="#fig_1">2</ref>, the average distance between pairs of authors continuously decreases from 9.3 in 1994 to 7.1 in 2005, which is another evidence of scientific collaboration gaining popularity. On the other hand, the network diameter fluctuates around 26, with two dips in G(1997) and G(2003) which we believe are due to the merge of the giant components which we further explore in the next subsection.</p><p>Further investigation reveals the intrinsic growth pattern of the network. First of all, the coauthorship network manifests the small world phenomenon <ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b2">2]</ref>. As shown in Table <ref type="table">1</ref>, all the coauthorship networks show a very high clustering coefficient compared to Erdös-Rényi random networks of the same size, suggesting that there is strong local clustering in these networks. This partially explains why the coauthorship network grows through the addition of edges between a pair of nodes having a common node that forms a closed triangle. In other words, the introduction between authors by the same coauthor accounts for the increasing number of collaborations. Also, despite the stringent definition of coauthorship, the CS network has average distance 7, implying that the famous six degrees of separation can also be valid in the scientific world. Less obviously, the average distance scales logarithmically with respect to the number of researchers in the network:</p><formula xml:id="formula_0">logN log &lt; k &gt; = 7.32 ≈ l real (1)</formula><p>further confirming that the coauthorship network is a growing small world. The scale-free degree distribution also characterizes the network growth pattern. Figure <ref type="figure" target="#fig_2">3</ref> shows the degree distribution in G(2005) <ref type="foot" target="#foot_1">3</ref> . Qualitatively, the degree distribution follows the power law especially in the middle degree region. Similar to other coauthorship networks <ref type="bibr" target="#b4">[4]</ref>, the counts in small degrees are substantially lower and the curve tapers off more quickly in the large degrees resembling an exponential distribution. The best fit for the (scale-free) degree distribution in the middle region is obtained by minimizing the sum of squares criterion and is (as shown with the straight line) <ref type="foot" target="#foot_2">4</ref> :</p><formula xml:id="formula_1">p(k) ∼ (0.8 + k) -2.45</formula><p>(2)</p><p>In Table <ref type="table">1</ref> we compare our findings on G(2005) with existing work on the coauthorship networks in other domains, e.g. biology, physics, and maths. Based on these metrics, the way in which computer scientists collaborate is much more similar to that of mathematicians and physicists than to biologists. For instance, the average distance of the computer science collaboration network lies between that of mathematics and physics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Shrinking Assortativity and Reciprocity</head><p>Two interesting findings are made regarding the assortativity and reciprocity of the network. The first one is a quantitative measure of the tendency for vertices to be connected to other nodes that are similar (or dissimilar). In our particular case of the collaboration network, we consider assortativity mixing by degree -the tendency of nodes to link to others that have a similar degree distribution (e.g. researchers with many collaborators tend to coauthor with other researchers who also have many collaborators). This is defined in <ref type="bibr" target="#b24">[24]</ref> as:</p><formula xml:id="formula_2">a = i jiki -N -1 i ji i k i [ i j 2 i -N -1 ( i ji) 2 ][ i k 2 i -N -1 ( i k 2 i )]<label>(3)</label></formula><p>where ji and ki are the excess in-degree and out-degree of the vertices that the i th edge leads into and out of respectively, and N is the total number of edges. Note that we consider the collaboration network as symmetric and ignore the order of authorship.</p><p>We measure reciprocity of the network as the tendency for a pair of coauthors to exchange their positions in the authors list, formally defined as:</p><formula xml:id="formula_3">r = e t vu e t uv ,<label>(4)</label></formula><p>where e t ∈ Gt, e t ∈ G t , u, v ∈ Gt, t &lt; t . Intuitively, it is the fraction of directional edges &lt; v, u &gt; such that &lt; u, v &gt; also exists in the graphs with earlier time-stamps. Shown in Figure <ref type="figure" target="#fig_3">4</ref> are assortativity and reciprocity from 1984 to 2005. The positive assortativity could be corroborated by the observation <ref type="bibr" target="#b2">[2]</ref> [26] that real-world social networks, unlike most artificial networks, are usually strongly assortative. Assortativity eventually dropped to 0.28 in G2005, smaller than that of the Physics community (see Table <ref type="table" target="#tab_1">3</ref>). Reciprocity was also significantly lower than those observed in online social network: the reciprocity in G2005 was 0.0055 in sharp contrast to 0.702 in the Flickr social network and 0.84 in the Yahoo 360 social network <ref type="bibr" target="#b13">[13]</ref>, as actors in these online social networks generally exchange links and linking back is much less costly than that in coauthorship networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">COLLABORATION AT THE COMMUNITY LEVEL</head><p>In this section, we present our findings as we scale down the level of analysis to the community level, with focus on two different types of communities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Component Structure Evolution</head><p>The first type of communities are those autonomously  Let |C| denote the size of a component C. We are interested in three types of components:</p><formula xml:id="formula_4">• Giant components represent the large (|C| ≥ τ ,</formula><p>where τ is a threshold) groups of researchers who are connected to each other either directly as coauthors or indirectly through a chain of collaborators.</p><p>Collectively, the giant components form the "core of productivity" in the network, usually containing the most prolific and active collaborators. The largest component (Figure <ref type="figure" target="#fig_4">5</ref>) typically covers a significant portion of the <ref type="bibr" target="#b25">[25]</ref>. In our case the largest component in G( <ref type="formula">2005</ref>) covers about 65.95% of the network.</p><p>• Singletons are the individuals who never publish with other researchers. They are the loners in the community, represented by vertices with zero degree. About 7.2% of the vertices in G(2005) are singletons.</p><p>• Middle region is the remaining section in the collaboration spectrum, typically consisting of relatively isolated groups of researchers who seldom collaborate with outsiders. In G(2005) the middle region comprises about 26.85% of the authors.</p><p>The dynamics of how components of different sizes evolve over time are even more interesting (Figure <ref type="figure" target="#fig_5">6</ref>). The band at the top represents the giant components (τ = 10 3 ) and the bottom band corresponds to the singletons. The remaining bands constitute the middle region. Most notably, the number of vertices that belong to the middle region drops significantly, and then quickly reaches a steady state where the width of each band remains almost constant since G(1989). The components of sizes between 100 and 999 (the green band) disappear after 1987 and we find that they merged with the giant components <ref type="foot" target="#foot_3">5</ref> . Similar patterns of connected component evolution were also observed in other types of social networks <ref type="bibr" target="#b13">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Collaboration in Topical Communities</head><p>The second type of communities correspond to different research topics. We study the collaboration in topical communities using the six topical datasets described earlier and present the findings in Table <ref type="table" target="#tab_2">4</ref>. One interesting observation is that the database community has the best connected collaboration network, with the lowest average distance between pairs of authors and the highest average betweenness. Its component structure (see Figure <ref type="figure" target="#fig_6">7</ref>) has the fewest components and the largest component covers a significant portion (∼ 60%) of the network. Compared with other topics, database researchers also have the largest number of collaborators on average, and are more reciprocal to coauthors <ref type="bibr" target="#b13">[13]</ref>. On the other hand, AI researchers have the weakest tendency to reciprocate in publication. They however have the largest assortativity among all six topics (Table <ref type="table" target="#tab_2">4</ref>), showing the strongest tendency to collaborate with someone who are in the same league, i.e. researchers with many collaborators tend to coauthor with other researchers who also have many collaborators. Figure <ref type="figure" target="#fig_6">7</ref> shows a comparison between the database and the applications community. The much lower betweenness of the applications topic might be due to the fact that it contains authors from several rather disjoint communities, such as multimedia research and information retrieval, and is thus more heterogeneous than the other topics.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">SCIENTIFIC COLLABORATION BETWEEN INDIVIDUALS</head><p>We now investigate how a collaboration between a pair of authors evolves over time, which serves as the finest level collaboration in the network. Specifically, a fundamental research question is: given a pair of authors vi and vj with existing collaboration ei,j, what is the probability that they will collaborate k times within the next Δt time interval.</p><p>As shown above, real world social networks (coauthorship networks in particular) are typically very large in terms of the number of vertices |V |, but are very sparse in terms of the number of edges |E|, i.e. |E| |V | 2 . Algorithms that examine all pairs of vertices in the network result in the computational complexity Ω(|V | 2 ), and as such are generally intractable for large |V |. Nonetheless, we can model the microscopic collaboration patterns between all pairs of vertices with existing edges, due to the sparsity of the edges in such networks. In the coauthorship network, existing edges represent previous collaboration between a pair of authors. Intuitively, past collaboration patterns between two authors and the structural information in the neighborhood of the vertices involved would suffice for the prediction of future collaboration. Hence, we propose a novel and efficient (Θ(|E| log(|E|))) method for learning and predicting the collaboration patterns between author pairs with existing collaboration and without resorting to the rest of the network.</p><p>We note that there is a related yet separate question: how does a new collaboration appear in the network? The answer to this depends highly on the macroscopic network characteristics. For instance, artificial networks are usually dissortative <ref type="bibr" target="#b24">[24]</ref>, whereas preferential linking is common in social networks for which the well known Barabási-Albert (BA) model <ref type="bibr" target="#b3">[3]</ref> can be used to predict P {e i,j }. Also, in real world scenarios, there is usually insufficient information in the data to predict intercollegiate or interdisciplinary collaboration.</p><p>We first propose the Stochastic Poisson model with Optimization Tree (Spot) method, consisting of a stochastic model for collaboration over time and an Optimization Tree for optimizing the model. Then we evaluate the performance of the model on longitudinal coauthorship network data. Although we derive the model in the coauthorship network, our learning algorithm can be readily generalized to other types of evolutionary networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">A Stochastic Poisson Model for Collaboration</head><p>We denote an evolutionary collaboration network by a series of discrete time snapshots {G(t)}(t = 0, 1, 2, ...). In the graph G(t), an existing collaboration between authors vi and vj is denoted by an edge ei,j(t), associated with its weight equal to the number of collaborations Ni,j(t) up to time t. Since N (t) is discrete and represents the cumulative number of collaborations, N (t) is a counting process. The Poisson process <ref type="bibr" target="#b28">[28]</ref> is a prominent stochastic model for counting processes, appearing in many real world phenomena. In the time invariant Poisson process with rate λ, the probability of the number of events k, occurring in the Δt time interval, is given by:</p><formula xml:id="formula_5">P r λ {N (t + Δt) -N (t) = k} = e -λΔt (λΔt) k k!<label>(5)</label></formula><p>In our case, however, the stationary Poisson rate condition typically does not hold for scientific collaboration due to various influencing factors. For example, collaborating with prolific authors may lead to a faster rate. Thus this requires the use of the more general nonstationary (nonhomogenous) Poisson process <ref type="bibr" target="#b28">[28]</ref>, where the rate is a variant function rather than a constant. As noted above, the local collaboration structure provides valuable information for determining the underlying rate function. For instance, while international or intercollegiate collaboration is not uncommon, two authors may collaborate more when they work in the same laboratory; authors collaborated assortatively before are likely to collaborate in the same way in the future. Specifically, for an existing collaboration ei,j(t) at time t, the subgraph G(ei,j(t)) is defined as the neighborhood of ei,j(t), consisting of the author pairs (vi, vj ), their immediate neighbors (coauthors) and the associated edges. A feature vector a = (a1, ..., ap) is computed with respect to the neighborhood G(ei,j(t)). For instance, features concerning the local neighborhood can be the fraction of the number of shared coauthors to the total number of collaborators for each author, the collaboration rate in the previous snapshot, the cumulative number of publications, etc. Therefore, for a specific edge ei,j(t), the collaboration rate λ is defined as a function of the feature vector of the neighborhood, i.e. λ(ei,j(t)) = f (ai,j(t)). Our goal is to learn the optimal function f from the past collaboration patterns for the prediction of future collaboration.</p><p>We obtain a training instance for each edge between two adjacent snapshots ei,j(t) and ei,j(t+Δt). We then compute the increment of publication by ki,j = N (t + Δt) -N (t) and the feature vector ai,j(t) from the neighborhood G(ei,j(t)). For simplicity of notation, we let P r λ(e i,j (t)) {ki,j} denote P r λ(e i,j (t)) {N (t + Δt) -N (t) = ki,j|ei,j(t0)} <ref type="bibr" target="#b6">(6)</ref> Note that the probability conditions on the existence of an edge (denoting collaboration) prior to the counting process.</p><p>Once the counting process starts, it is modeled as a nonhomogeneous Poisson process and thus in any time interval Δt the increment ki,j can be any non-negative number. We also assume Δt to be one unit of time in the sequel. Given the observations, the optimal function f should maximize the log-likelihood with respect to the training instances:</p><formula xml:id="formula_6">f * = argmax f log e i,j (t) P r λ(e i,j (t)) {ki,j} = argmax f e i,j (t) log P r λ(e i,j (t)) {ki,j} = argmax f e i,j (t) [ki,j log(λ(ei,j(t))) -λ(ei,j(t)) -log ki,j!] = argmax f e i,j (t)</formula><p>[ki,j log(f (ai,j(t)))f (ai,j(t))] ( <ref type="formula">7</ref>)</p><p>where the function f is plugged into Eq. ( <ref type="formula">7</ref>) and the factorial terms ki,j! are dropped as they are not related to the maximization. In general, there is no closed-form solution for Eq. <ref type="bibr" target="#b7">(7)</ref>. We now propose a nonparametric solution to this optimization problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">The Optimal Tree for Estimating the Rate Function</head><p>In an evolutionary network, we model the collaboration, or more generally the addition of weights to the edges, as a non-stationary Poisson process. The collaboration rate function depends on the neighborhood structure. We refrain from making a priori parametric assumptions about the rate function, as such our model can be applied to a wide variety of real-world networks. Furthermore, we opt to solve the optimization problem using a nonparametric approach, the Optimization Tree, inspired by decision tree methods such as CART <ref type="bibr" target="#b6">[6]</ref>.</p><p>Similar to decision trees, the Optimization Tree is grown in a top-down and best-first fashion. Our goal is to derive the decision rule criterion in each split in order to find the function f * in Eq. <ref type="bibr" target="#b7">(7)</ref>. Each internal node in the tree represents a decision: aj ≤ h, where aj is the jth attribute and h is the splitting value. Geometrically, a splitting hyperplane is orthogonal to an axis in the feature space and splits the feature space into hypercubes (regions). As such it dramatically reduces the search space and consequently the training time as well. We note that the terms in the summation in Eq. <ref type="bibr" target="#b7">(7)</ref> are not related to one another. Thus for any internal node, the optimal decision rule should maximize the log-likelihood in the two sub-regions:</p><formula xml:id="formula_7">(R1, R2) * = arg max R 1 ∪R 2 =R e i,j (t)∈R 1 [ki,j log f (ai,j(t)) -f (ai,j(t))] + e i,j (t)∈R 2 [ki,j log f (ai,j(t)) -f (ai,j(t))]<label>(8)</label></formula><p>Since all the instances in a node are assumed to be drawn from an identical Poisson distribution, the optimal estimate for the rate which maximizes the log-likelihood for the training samples in region R is the mean:</p><formula xml:id="formula_8">λR = e i,j (t)∈R ki,j R<label>(9)</label></formula><p>Substituting Eq. ( <ref type="formula" target="#formula_8">9</ref>) into Eq. ( <ref type="formula" target="#formula_7">8</ref>), we derive the optimal splitting criterion for the region R:</p><formula xml:id="formula_9">(R1, R2) * = arg max R 1 ∪R 2 =R [ e i,j (t)∈R 1 ki,j log λR 1 + e i,j (t)∈R 2 ki,j log λR 2 -λR 1 R1 -λR 2 R2 ] = argmax R 1 ∪R 2 =R [ R 1 ki,j log λR 1 + R 2 ki,j log λR 2 ] (<label>10</label></formula><formula xml:id="formula_10">)</formula><p>where the linear terms in Eq.( <ref type="formula" target="#formula_9">10</ref>) are dropped, since they sum up to e i,j (t)∈R ki,j and thus are not related to the optimization.</p><p>In each step of growing the Optimization Tree, the internal node, which when split causes the maximum increment in the log-likelihood, is selected as the splitting node. Techniques used in training decision trees can also be adopted here for efficient implementation. For instance, training instances can be sorted by feature value beforehand and a linear search can be performed per feature to obtain the maximum in Eq. <ref type="bibr" target="#b10">(10)</ref>. After the tree is grown, each leaf in the Optimization Tree corresponds to a fixed rate Poisson distribution and can therefore be used for prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Remarks on the Optimization Tree Method</head><p>Before turning to the experimental studies, it is worthwhile to remark on the proposed Optimization Tree method. We first offer an alternative viewpoint of the Optimization Tree method as entropy maximization. Substituting λ in Eq. ( <ref type="formula" target="#formula_8">9</ref>) into Eq. ( <ref type="formula" target="#formula_9">10</ref>), we note that with proper normalization each term in Eq. ( <ref type="formula" target="#formula_9">10</ref>) can be regarded as a proxy of the entropy of the corresponding sub-region. Therefore, although we aim to maximize the log-likelihood, the Optimization Tree method can in fact be regarded as maximizing the proxy of the entropy of the samples in a greedy fashion.</p><p>Although the proposed Optimization Tree method shares some structural similarities with decision trees, we emphasize the key differences between them. First, the Optimization Tree aims to estimate a probability distribution or more precisely its parameters with respect to the input feature vector, rather than solving a classification or regression problem as in classification or regression trees. Second, the Optimization Tree solves the optimization problem by maximizing the log-likelihood of the training instances, Neighborhood -The fraction of shared collaborators to all the collaborators of author vi times the fraction of that of author vj -The fraction of publication with shared collaborators to all publication of vi times the fraction of that of vj instead of using the impurity function such as Gini index <ref type="bibr" target="#b6">[6]</ref> to determine the decision rules. We formally derive the functional form of the decision rule in each split which is fundamentally different from the impurity functions as used in classification/regression trees. Despite these differences, the Optimization Tree shares some advantages with other decision tree methods. First, the Optimization Tree can be regarded as a smoothing technique for samples within a region, as such it dampens the effect of outliers in the training data. Moreover, since Spot learns from a non-homogeneous Poisson process rather than a fixed distribution, it has the effect of smoothing evolving data over time. Second, with a linear region boundary the Optimization Tree provides a simple and stable model for estimating the rate function. Also, the training computation complexity is O(p |E| log |E|), where p is the dimension of the feature space. It is thus more efficient than other methods such as SVMs. These features are highly desirable for our problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Empirical Studies on the Collaboration Model</head><p>To evaluate the accuracy of the prediction, we collected a total of 105,122 collaboration records in 1997 to 2000 and 2001 to 2003 from the CS dataset. The goal is then to predict the increment in collaboration between the snapshots 6 . Table <ref type="table" target="#tab_3">5</ref> shows the different features used in each collaboration record. These features are organized in three levels: the first level relates to the individual author per se, the second level concerns with pairwise collaboration information and the third level pertains to the collaboration structure in the neighborhood. Since we only use local information, an efficient solution can be easily achieved. Although Table <ref type="table" target="#tab_3">5</ref> is not a complete list of all possible features, we intentionally select the most informative features in each level to showcase the prediction power of our method.</p><p>We use two models for comparison. The Past Collab- 6 Publications have been aggregated into a three year interval.</p><p>The increment in publications between the intervals ranges from 0 to 42. We did not choose a one year interval since the number of publications by two authors is relatively small and unstable.</p><p>oration Rate model is used as a baseline which predicts the number of collaborations to be the same as that in the previous time interval, regardless of other information. In <ref type="bibr" target="#b20">[20]</ref>, Newman has shown by using a relative probability that the number of past collaborations is a good indicator of the probability of future collaboration. We also choose Support Vector Machines <ref type="bibr" target="#b30">[30]</ref> as a sophisticated model for comparison, due to its efficacy in various classification and regression problems. Specifically, given the feature vectors and the corresponding number of collaborations as training samples, Support Vector Regression (SVR)<ref type="foot" target="#foot_4">7</ref>  <ref type="bibr" target="#b30">[30]</ref> is used as a strong baseline comparator to learn the regression model. The SVR model then predicts the number of collaborations in the test data.</p><p>Note that the above two baselines are however inherently different from Spot, which predicts the number of collaboration with a Poisson probability distribution. In practice, it is desirable to obtain a discrete value as the number of collaborations. The mean of the Poisson distribution is a natural choice, since it maximizes the log-likelihood in the training data. In the sequel, we use the Poisson mean corresponding to the distribution predicted by the Spot method to compare with the values predicted with the baseline methods. To give an actual example, rules of the following form could be condensed from the tree for predicting the distribution: IF (total collaboration is between 9 and 18) AND (collaboration rate in the previous interval is lower than 7) AND (fraction of shared authors among author i's coauthors times that among author j's is lower than 0.025) ... THEN IF (fraction of shared papers in author i's papers times that in author j's is lower than 0.0124) THEN predict rate=2.38 ELSE predict rate=3.51</p><p>Thus in the example above, the leaf nodes predict the collaboration rate. If the predicted rate is 2.38 for the respective Poisson distribution, the probabilities of incremental collaborations of 0, 2 and 3 are 0.093, 0.262 and 0.208 respectively.</p><p>We evaluate the performance of these models by measuring two goodness of fit statistics for the data. The sample correlation coefficient (Pearson correlation coefficient) measures the linear relationship between the predicted and the true number of collaboration. Let y i and ỹi (i = 1, ..., n) denote the true and predicted increment of collaboration, the sample correlation coefficient is defined as,</p><formula xml:id="formula_11">ryỹ = i (yi -y)(ỹi -ỹ) (n -1)sysỹ<label>(11)</label></formula><p>where y and ỹ are sample means, sy and sỹ are sample standard deviations. The correlation coefficient is between -1 and 1, and the higher the absolute value the stronger the linear relationship between the predicted and true value. We also measure the absolute magnitude of the residuals (the difference between the predicted and the true value) with </p><formula xml:id="formula_12">n = i (ỹi -yi) 2 n (<label>12</label></formula><formula xml:id="formula_13">)</formula><p>Lower RMSE indicates a better fit to the data as the predicted values deviate less from the true values. We held out a portion of the training data to determine the parameters in the methods. The only parameter in Spot is the number of internal nodes which determines the size of the tree. Experiments on the hold-out datasets suggest that a tree with 75 internal nodes fits the data well. This parameter is relatively insensitive as the correlation coefficient ranges from 0.73 to 0.82 in the hold out dataset. Similarly, we determine the parameters C=10 and γ=0.001 (with RBF kernel) in the SVR model using the same holdout dataset.</p><p>We conducted 10-fold cross validation in the remaining data in all our experiments, namely, parameters are trained on 90% of the samples and tested on the remaining data in a rotation manner. The results are summarized in Table <ref type="table" target="#tab_4">6</ref>. The baseline Past Collaboration model scores only 0.227 coefficient correlation, while both Spot and SVR score much higher, suggesting that there is significant information in the neighborhood structure that can be used for prediction. Using the Poisson mean as the predicted value, Spot increases the correlation coefficient by 18.7% compared to SVR. Considering the contribution of other complicating factors in future collaboration, Spot's high correlation coefficient (0.782) suggests that there is strong correlation between the predicted and true value and thus Spot can be a good predictor. Similar results are found in the RMSE metric. The RMSE is 4.74 when using only the number of collaboration in the previous time interval for prediction. SVR and Spot significantly outperforms the baseline by accounting for the information existed in the neighborhood. Compared to SVR, Spot incurs 8.4% less RMSE. These results demonstrate that Spot fits a better model for collaboration than SVR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS AND FUTURE WORK</head><p>This work adds to the literature of social network analysis of collaborating authors by characterizing and modeling the growth of a large Computer Science collaboration network over a period of 25 years. By conducting a longitudinal analysis at the network and the community levels, our study presents the first comprehensive picture of the evolving trends of collaboration in the field. In addition, we also quantify, compare and contrast the distinctive collaboration patterns in six topical communities. On the individual level, we proposed a new model, the Spot method, for learning and predicting collaborations between pairs of authors. In an evolutionary network, we model the col-laboration as a non-stationary Poisson process and propose the Optimization Tree method to learn the collaboration rate function. Since only local neighborhood information is used, our model is able to learn from a heterogeneous network, is efficient, and is flexible to the set of features. Our experimental results show that Spot outperforms the popular SVR method for collaboration prediction.</p><p>There are several opportunities for future studies. For instance, one could study the creation and evolution of bridge nodes in different topical communities since they serve as brokers of information between different research areas. The identification of such nodes will further our understanding of the interaction between collaborations at the individual level and community level. Another direction, as alluded earlier, is to extend our model with the Bayes formula to predict the joint probability P {N (t+Δt)-N (t) = k, e i,j } for new edges, where the prior of new edges may be modeled by topological and topical information such as cyclic closure and focal closure <ref type="bibr" target="#b12">[12]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Left: number of authors and papers from 1980 to 2005. Right: the increasing trend of collaboration.</figDesc><graphic coords="3,31.44,119.01,258.19,106.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The average distance of the network gradually decreases over time, indicating that the collaboration "world" in fact gets smaller over time.</figDesc><graphic coords="3,356.76,54.09,159.40,106.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The degree distribution of the CiteSeer co-authorship network in 2005.</figDesc><graphic coords="4,101.16,53.82,144.40,146.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Assortativity and reciprocity are both shrinking over time.Note that assortativity dropped significantly.</figDesc><graphic coords="4,344.52,53.85,183.60,153.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The largest component of G(2005), enlarged on the left, visually forms the core of the network shown in the bottom-right inset. Edges showing collaborations in different topics are rendered in different colors. Visualization is performed by the Large Graph Layout (LGL) package.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The evolution of component structure, shown as the fraction of vertices in components of different sizes.The middle region gradually lost ground as the giant components came into dominance. The percentages became constant after reaching a steady state.</figDesc><graphic coords="5,41.64,53.88,265.50,187.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The database community (right) is more cohesive than the applications community (left), and its largest component forms a significantly larger core in the network.</figDesc><graphic coords="6,50.16,182.83,244.87,125.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 : Overview of the six topical datasets.</head><label>2</label><figDesc></figDesc><table><row><cell cols="4">2 http://www-static.cc.gatech.edu/∼guofei/CS ConfRank.htm</cell></row><row><cell>Topic</cell><cell>Representative venues</cell><cell cols="2">#Authors #Papers</cell></row><row><cell>ai</cell><cell>AAAI, IJCAI, NIPS, KDD ...</cell><cell>2,105</cell><cell>1,666</cell></row><row><cell>app</cell><cell>WWW, SIGGRAPH, SIGIR ...</cell><cell>2,087</cell><cell>1,548</cell></row><row><cell>arch</cell><cell>DAC, MICRO, HPCA ...</cell><cell>2,589</cell><cell>1,740</cell></row><row><cell>db</cell><cell>SIGMOD ,VLDB, ICDE ...</cell><cell>1,559</cell><cell>1,755</cell></row><row><cell>system</cell><cell>SIGCOMM, PODC, SOSP ...</cell><cell>1,733</cell><cell>1,785</cell></row><row><cell>theory</cell><cell>STOC, FOCS, COLT ...</cell><cell>1,747</cell><cell>1,701</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 : Assortativity coefficient in Computer Science and other research domains.</head><label>3</label><figDesc></figDesc><table><row><cell>Metric</cell><cell cols="4">Biology Comp. Sci. Maths Physics</cell></row><row><cell>Assortativity</cell><cell>0.13</cell><cell>0.28</cell><cell>0.12</cell><cell>0.36</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 : Summary statistics of the six topical communities. Cells with particularly high/low values are highlighted in bold font.</head><label>4</label><figDesc></figDesc><table><row><cell>Dataset</cell><cell cols="8">Connectivity avg. dist. betweenness #comp. largest comp. singleton papers/author collaborator Component structure Collaboration patterns reciprocity</cell><cell>assortativity</cell></row><row><cell>ai</cell><cell>5.5</cell><cell>0.5 × 10 -2</cell><cell>574</cell><cell>11.1%</cell><cell>6.6%</cell><cell>1.9</cell><cell>2.7</cell><cell>1.7 × 10 -3</cell><cell>0.61</cell></row><row><cell>app</cell><cell>3.5</cell><cell>0.1 × 10 -2</cell><cell>593</cell><cell>4.9%</cell><cell>6.3%</cell><cell>2.0</cell><cell>3.0</cell><cell>2.8 × 10 -3</cell><cell>0.29</cell></row><row><cell>arch</cell><cell>8.3</cell><cell>1.9 × 10 -2</cell><cell>603</cell><cell>21.1%</cell><cell>4.1%</cell><cell>1.9</cell><cell>3.4</cell><cell>3.6 × 10 -3</cell><cell>0.44</cell></row><row><cell>db</cell><cell>5.3</cell><cell>5.9 × 10 -2</cell><cell>205</cell><cell>55.9%</cell><cell>2.9%</cell><cell>3.6</cell><cell>4.7</cell><cell>7.3 × 10 -3</cell><cell>0.35</cell></row><row><cell>system</cell><cell>6.0</cell><cell>1.7 × 10 -2</cell><cell>415</cell><cell>24.2%</cell><cell>4.7%</cell><cell>2.6</cell><cell>3.0</cell><cell>1.9 × 10 -3</cell><cell>0.25</cell></row><row><cell>theory</cell><cell>6.5</cell><cell>1.9 × 10 -2</cell><cell>461</cell><cell>31.8%</cell><cell>8.4%</cell><cell>2.3</cell><cell>2.8</cell><cell>5.2 × 10 -3</cell><cell>0.37</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 : Features used for collaboration prediction.</head><label>5</label><figDesc></figDesc><table><row><cell>Level</cell><cell>Feature</cell></row><row><cell>Individual</cell><cell>-Total number of publications of author vi -Total number of publications of author vj</cell></row><row><cell></cell><cell>-Whether author vi and vj belong to</cell></row><row><cell></cell><cell>the same affiliation</cell></row><row><cell>Pairwise</cell><cell>-Total number of collaboration by time t</cell></row><row><cell></cell><cell>-Total number of shared collaborators</cell></row><row><cell></cell><cell>by author vi and vj</cell></row><row><cell></cell><cell>-Collaboration rate between vi and vj</cell></row><row><cell></cell><cell>in the previous snapshot</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 : Comparison of prediction performance of Past Collaboration (baseline), Spot and SVR using 10-fold cross validation.</head><label>6</label><figDesc></figDesc><table><row><cell>Method</cell><cell>Correlation</cell><cell>Root Mean Squared</cell></row><row><cell></cell><cell>Coefficient (r)</cell><cell>Error (RMSE)</cell></row><row><cell>Past Collaboration</cell><cell>0.227</cell><cell>4.74</cell></row><row><cell>SVR</cell><cell>0.673</cell><cell>1.53</cell></row><row><cell>Spot</cell><cell>0.782</cell><cell>1.42</cell></row><row><cell cols="3">the Root Mean Squared Error (RMSE),</cell></row><row><cell>RMSE =</cell><cell>i err 2 i</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The CiteSeer Digital Library: http://citeseer.ist.psu.edu.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>To reduce the effect of outliers in the middle and high degrees, we use the median of a window of five points (the median is resilient to outliers) to plot the degree distribution.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>The curve may be better fitted with a piece-wise scale-free distribution with lower exponent for low degrees and larger exponent for high degrees.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>We note the merging effect may be confounded by the relatively low availability of online publication in the 1980s; the constitution since mid 1990s corresponding to the majority of papers in CiteSeer, however, remains relatively stable.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4"><p>The classical implementation -SVR in LIBSVM<ref type="bibr" target="#b7">[7]</ref> is used in our experiments.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">ACKNOWLEDGMENTS</head><p>This work was partially supported by the National Science Foundation (NSF).</p><p>The authors would like to thank Réka Albert and Isaac Councill for insightful discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Statistical mechanics of complex networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barabási</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cond-mat/0106096v1</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Classes of small-world networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="11149" to="11152" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Emergence of scaling in random networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Barabási</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Albert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="page" from="509" to="512" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Evolution of the social network of scientific collaborations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Barabási</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ravasz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Neda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vicsek</surname></persName>
		</author>
		<idno>Cond-mat/0104162</idno>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Exploring the community structure of newsgroups</title>
		<author>
			<persName><forename type="first">C</forename><surname>Borgs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mahdian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saberi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 10th ACM SIGKDD Conf. Knowledge Discovery and Data Mining</title>
		<meeting>of 10th ACM SIGKDD Conf. Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Classification and Regression Trees</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Olshen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<pubPlace>Wadsworth</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">LIBSVM: a library for support vector machines</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Doreian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">N</forename><surname>Stokman</surname></persName>
		</author>
		<title level="m">Evolution of Social Networks. Gordon and Breach</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On six degrees of separation in DBLP-DB and more</title>
		<author>
			<persName><forename type="first">E</forename><surname>Elmacioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="33" to="40" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic document metadata extraction using support vector machines</title>
		<author>
			<persName><forename type="first">H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Manavoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE Joint Conference on Digital Libraries (JCDL)</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Efficient name disambiguation for large scale databases</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ertekin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)</title>
		<meeting>the 10th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Empirical analysis of an evolving social network</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kossinets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Watts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="page" from="88" to="90" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Structure and evolution of online social networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tomkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 12th ACM International Conf. on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>of the 12th ACM International Conf. on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="611" to="617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Graphs over time: Densification laws, shrinking diameters and possible explanations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 11th ACM SIGKDD Conf. Knowledge Discovery and Data Mining</title>
		<meeting>11th ACM SIGKDD Conf. Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="177" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The link-prediction problem for social networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liben-Nowell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1019" to="1031" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Social capital in friendship-event networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Licamele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Sixth IEEE International Conference on Data Mining (ICDM)</title>
		<meeting>Sixth IEEE International Conference on Data Mining (ICDM)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="959" to="964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sexual networks: implications for the transmission of sexually transmitted infections</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liljeros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Edling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Amaral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Microbes and Infection</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="189" to="196" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The small-world problem</title>
		<author>
			<persName><forename type="first">S</forename><surname>Milgram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology Today</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="61" to="67" />
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Who is the best connected scientist? a study of scientific coauthorship networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page">16132</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Clustering and preferential attachment in growing networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters E</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<date type="published" when="2001">025102. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Scientific collaboration networks: I. network construction and fundamental results</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Revivew E</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Scientific collaboration networks: II. shortest paths, weighted networks, and centrality</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Revivew E</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The structure of scientific collaboration networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="404" to="409" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Mixing patterns in networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page">26126</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Coauthorship networks and patterns of scientific collaboration</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="5200" to="5205" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Why social networks are different from other types of networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page">36122</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Citation statistics from more than a century of physical review</title>
		<author>
			<persName><forename type="first">S</forename><surname>Redner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">APS Meeting Abstracts</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Introduction to Probability Models</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Ross</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Identification and evaluation of weak community structures in networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of National Conference on Artificial Intelligence (AAAI)</title>
		<meeting>National Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">The Nature of Statistical Learning Theory</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
