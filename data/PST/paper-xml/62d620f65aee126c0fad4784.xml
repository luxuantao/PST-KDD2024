<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Software Artifact Mining in Software Engineering Conferences: A Meta-Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-07-18">18 Jul 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zeinab</forename><forename type="middle">Abou</forename><surname>Khalil</surname></persName>
							<email>zeinab.abou-khalil@inria.fr</email>
							<affiliation key="aff0">
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stefano</forename><surname>Zacchiroli</surname></persName>
							<email>stefano.zacchiroli@telecom-paris.fr</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">LTCI</orgName>
								<orgName type="institution" key="instit2">T?l?com Paris</orgName>
								<address>
									<settlement>Institut Polytechnique de Paris Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Software Artifact Mining in Software Engineering Conferences: A Meta-Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-07-18">18 Jul 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3544902.3546239</idno>
					<idno type="arXiv">arXiv:2207.08436v1[cs.SE]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>software artifacts</term>
					<term>mining software repository</term>
					<term>systematic mapping</term>
					<term>meta-analysis</term>
					<term>research trends</term>
					<term>academic conferences</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Background: Software development results in the production of various types of artifacts: source code, version control system metadata, bug reports, mailing list conversations, test data, etc. Empirical software engineering (ESE) has thrived mining those artifacts to uncover the inner workings of software development and improve its practices. But which artifacts are studied in the field is a moving target, which we study empirically in this paper.</p><p>Aims: We quantitatively characterize the most frequently mined and co-mined software artifacts in ESE research and the research purposes they support.</p><p>Method: We conduct a meta-analysis of artifact mining studies published in 11 top conferences in ESE, for a total of 9621 papers. We use natural language processing (NLP) techniques to characterize the types of software artifacts that are most often mined and their evolution over a 16-year period (2004-2020). We analyze the combinations of artifact types that are most often mined together, as well as the relationship between study purposes and mined artifacts.</p><p>Results: We find that: (1) mining happens in the vast majority of analyzed papers, (2) source code and test data are the most mined artifacts, (3) there is an increasing interest in mining novel artifacts, together with source code, (4) researchers are most interested in the evaluation of software systems and use all possible empirical signals to support that goal.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Software development is a human activity that results in the production of different types of software artifacts. While source code is the most common artifact we tend to think of, other results of software production include: binary code, version control system (VCS) metadata, bug reports, developer conversations happening via several media (mailing lists, forums, Q&amp;A websites, chats), code reviews, test data, and documentation (design-, developer-and user-oriented).</p><p>Empirical Software Engineering (ESE) <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b29">30]</ref> research in general, and even more so Mining Software Repository <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25]</ref> (MSR) specifically, have analyzed software artifacts in increasingly large quantities over the last decades, as a way to understand and improve software development practices.</p><p>Which artifacts are studied in the field is however a moving target, affected by factors like research trends, data availability, and increased availability of large-scale datasets and analysis platforms <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b26">27]</ref>. This shift over time has led researchers in the field to regularly conduct "introspective" studies <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b27">28]</ref> that use meta-research <ref type="bibr" target="#b15">[16]</ref> techniques to analyze published ESE scientific papers and report back to the community.</p><p>Contributions. The present work fits the tradition of (automated) meta-analyses <ref type="bibr" target="#b10">[11]</ref> on empirical software engineering papers, addressing and reporting back to the community on the under-explored angle of which software artifacts are mined, their co-occurrence in studies, their relationship with study purposes, and the evolution of their mining over time. Specifically, we address the following research questions: RQ 1. What are the most frequently mined software artifacts in ESE research, and how has their popularity evolved over time? RQ 2. What are the combinations of software artifacts that are frequently mined together in ESE research? RQ 3. What are the most popular research purposes of studies that mine software artifacts in ESE research, and how do they relate to the type of mined artifacts? (Intuitively: which software artifacts support which research purposes in the field?)</p><p>By answering these research questions, we aim to provide a comprehensive view of how, how much, and why software artifacts are used in ESE research, with a quantitative and longitudinal (over time) angle. Doing so will not only inform the community about the evolution of research trends but also guide research policy decisions. In particular, the knowledge that more, or simply other, types of artifacts are in high demand for ESE research can motivate fellow scholars to produce needed and hence impactful open datasets; the knowledge that specific types of artifacts are used together can help in producing datasets that are mutually consistent across different artifact types, reducing threats to validity due to the use of inconsistent datasets; realizing that highly used software artifacts types are not being long-term archived can drive digital preservation initiatives <ref type="bibr" target="#b7">[8]</ref> that aim to support study repeatability/reproducibility/replicability <ref type="bibr" target="#b3">[4]</ref> to focus their efforts on them.</p><p>To answer the stated research questions, we mine the textual content of 9621 from 11 top conferences in (empirical) software engineering, covering a period of <ref type="bibr">16 years (2004-2020)</ref>. We use NLP techniques to identify frequently mined software artifacts and map papers to them. We then study the evolution of detected artifact mentions over time, the co-occurrence of artifacts types in papers, and the relationship between paper purposes (also mined from paper texts) and artifact types.</p><p>Paper structure. A comparison with related work is conducted next in Section 2. Section 3 describes our experimental methodology. Section 4 presents experimental results, breaking them down by research question. We discuss the implications of our findings in Section 5 and threats to their validity in Section 6. Section 7 summarizes the paper and outlines directions for future work. Data availability. A complete replication package for this paper is available from Zenodo <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Demeyer et al. <ref type="bibr" target="#b6">[7]</ref> mined the complete corpus of MSR conference papers at the time (2004-2012) using n-gram analysis, to investigate how the research field on mining software repositories had evolved. They focused on: (i) trendy (and outdated) research topics, (ii) most (and least) frequently cited cases, (iii) popular/emerging mining infrastructures, and (iv) software engineering state-of-thepractice. They considered only papers published at MSR, so their results cannot be generalized to other venues. Our work addresses this problem by covering a much larger set of venues. They used pdftotext, 1 for text extraction, a tool that introduces artifacts in the extracted text, that the authors had to clean up manually. The tool we used, CERMINE, has been shown to be more reliable <ref type="bibr" target="#b31">[32]</ref>. Also, they only excluded bibliography sections, whereas we have verified that other sections (e.g., related work and appendix), can also skew the result; we excluded them from analysis too. Finally, as no link between n-grams and papers was kept in the study, it was not possible to explain outliers in occurrence frequencies.</p><p>Novais et al. <ref type="bibr" target="#b25">[26]</ref> conducted a systematic study of software evolution visualization technologies over 125 papers. They studied the types of data used to visualize and analyze software evolution. They found that there is no study combining "BTS data" and "Source Code", and that "SCM data" is the key data source for software evolution visualization. Their results are specific to software evolution visualization, whereas we conduct a broader analysis covering software artifact mining across top ESE venues.</p><p>Farias et al. <ref type="bibr" target="#b5">[6]</ref> performed a systematic mapping study on 107 papers published over 5 editions of the MSR conference (2010-2014). They manually investigated papers, collecting data about software analysis goals (purpose, focus, and object of the analysis), 1 https://www.xpdfreader.com/pdftotext-man.html, accessed 2022-04-27 data sources, evaluation methods, tools, and how the field is evolving. They found that "comprehension of defects" and "code" were, respectively, was the most common purpose and analysis object (i.e., artifact). They defined a taxonomy organizing artifacts into structured (e.g., source code) and unstructured (e.g., mailing lists) ones. They found that structured artifacts tend to be more explored than unstructured ones, but that the number of approaches using unstructured ones had been increasing over the last three years (at the time). Other software engineering artifacts were starting to come into use at the time, such as comments and emails. They were being analyzed either alone or together with metrics extracted from structured data sources to understand quality issues in software projects. Their study is limited to 5 editions of MSR, which are now more than 5 years old. Our study is more general in terms of both venues and time period. We adopt their taxonomy of study purposes to answer RQ 3.</p><p>Amann et al. <ref type="bibr" target="#b1">[2]</ref> reviewed studies published at top software engineering conferences to describe the current (in 2013) state of the art, trends in mined artifacts, pursued goals and study reproducibility. For the specific purpose of identifying mined artifacts they only considered papers published at the MSR conference. They identified 15 distinct artifact "sources" including: CVS, git, mercurial, GitHub, SVN, jazz, bug, commit, patch, message, StackOverflow, email, Twitter, blog, and tutorials. Similar to <ref type="bibr" target="#b6">[7]</ref>, authors included only MSR in their analysis and excluded only paper bibliographies from their analyses. Also, they focus their analysis on the top 10 terms in papers and use product names (e.g., Mercurial) rather than artifact types. In the present study, we investigate artifacts mining in a much larger body of conferences, longer period, and additionally focus on the co-occurrence of artifact types and study purposes to inform data policy decisions.</p><p>Hemmati et al. <ref type="bibr" target="#b13">[14]</ref> analyzed 117 full papers published at MSR between 2004 and 2012. They extracted 268 comments from these papers, categorized them using a grounded theory methodology, and extracted high-level research themes. They codified a set of guidelines, tips, and recommendations, as well as a set of best practices, which can be used and updated continuously as the MSR community matures and advances.</p><p>Vasilescu et al. <ref type="bibr" target="#b33">[34]</ref> curated a dataset of 11 well-established software engineering conferences containing historical data about accepted papers, program committee members, and the number of submissions for the 1994-2012 period. The dataset is intended to assist steering committees or program committee chairs in their selection process (e.g., the change in PC members), help potential authors decide where to submit their work to, and study the number of conference newcomers over time. They used DBLP records to retrieve paper data and extracted PC members and the number of submissions from event websites and online proceedings.</p><p>Kotti et al. <ref type="bibr" target="#b18">[19]</ref> conducted a study of data papers published at MSR between 2005 and 2018 to determine how often (frequency), by whom (user), and for what purpose researchers reuse associated artifacts. They found that 65% of data papers have been used in other studies, but they are cited less often than technical papers at the same conference. Their findings highlight that data papers provide useful foundations for subsequent studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>Figure <ref type="figure" target="#fig_0">1</ref> gives an overview of our data collection and analysis approach. We detail each step in the remainder of this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Venue selection</head><p>Novel results in software engineering tend to be first published in scientific conferences and later (and not always) consolidated in journal articles. Consistently with previous work <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b33">34]</ref>, we focus in this paper on conferences, which we posit to closely capture research trends in ESE at a given point in time.</p><p>The most representative conference for research based on software artifacts is Mining Software Repositories (MSR), established in 2004 as the primary conference for mining-based empirical software engineering, and has successfully continued ever since. But mining-based ESE studies are also published in other reputable software engineering conferences; so one cannot only consider MSR papers. The list of conferences we have analyzed in this study is given in Table <ref type="table" target="#tab_0">1</ref>, with details about the considered editions and the number of papers initially obtained from each of them.</p><p>To settle on this list of conferences, we started from the list of venues used in previous work <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b33">34]</ref> and retained only conferences that explicitly welcome and/or frequently publish empirical studies based on software artifact mining.</p><p>11 top conferences in (empirical) software engineering were retained. Some have a broad scope (e.g., ICSE), while others are focused on specific subdomains of software engineering (e.g., MSR, ICSME). Regarding selected conference years, we started from papers published in 2004-the year MSR was first held as an international workshop, in response to the increasing interest in this field, denoting the beginning of a more established field-and stopped at 2020 (because 2021 was still incomplete at the time of data collection). In total, 9621 papers have been considered over a period spanning 16 years.</p><p>In reading Table <ref type="table" target="#tab_0">1</ref>, note that some conferences merged and/or changed name names during the observation period: ICSM renamed to ICSME; WCRE and CSMR merged into SANER. In the rest of the analysis, we hence merged ICSM and ICSME papers, as well as WCRE, CSMR and SANER papers (referred to as "venue merging" in the following).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Paper filtering and retrieval</head><p>To obtain the list of papers for the selected conferences and years, we used DBLP <ref type="bibr" target="#b19">[20]</ref>, the reference bibliographic database for computer science publications. The entire DBLP dataset is released publicly in XML format; we retrieved the most recent DBLP data dump available at the time of analysis. <ref type="foot" target="#foot_0">2</ref>As DBLP indexes studies in all fields of computer science, we first selected papers from venues and editions that match Table <ref type="table" target="#tab_0">1</ref>, obtaining 9621 bibliographic records. We then further filtered records applying the following exclusion criteria (ECs) (matching any one of them is enough for excluding a paper from further analysis):</p><p>EC1 The paper must not be short (including position papers, data papers, and challenge papers, e.g., those corresponding to the yearly MSR mining challenge). The rationale for this criterion is that full papers present more mature and established results, rather than exploratory ideas that might not bear fruit. As such, full papers better capture the state of the field <ref type="bibr" target="#b5">[6]</ref>.</p><p>To implement this criterion, we discarded papers shorter than 6 pages, according to DBLP metadata. EC2 The paper must describe primary research rather than secondary or tertiary one. (Secondary research is based on published data and information gathered from previous studies. Tertiary research is meta-research based on secondary studies, such as systematic reviews of secondary studies.) The rationale for this choice is that secondary and tertiary studies (e.g., systematic literature reviews, systematic mappings, and literature surveys) would over-represent research trends that are already popular in the field.</p><p>To implement this criterion, we exclude papers that contain strings like the following in their titles: "literature review", "systematic mapping", "systematic review", "replication study", "survey", "replicating" (see replication package <ref type="bibr" target="#b0">[1]</ref> for details). The impact of each filtering step is shown as a Sankey diagram in the leftmost part of Figure <ref type="figure">2</ref>. We started from 9621 papers, 4141 of which were short, and 28 were non-primary studies. After filtering, 5452 remained.</p><p>For all remaining papers, we retrieved DOIs (Digital Object Identifiers) from either DBLP records (for the most part) or using the Crossref search engine<ref type="foot" target="#foot_1">3</ref> (for about 100 papers, for which DBLP lacked DOI information). We then retrieved digital copies, in PDF format, of selected papers using the PyPaperBot paper retrieval tool. <ref type="foot" target="#foot_2">4</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Text extraction</head><p>Once we obtained all papers in PDF format, we converted them to plain text for ease of further processing.</p><p>Several open source tools exist for this task. Tkaczyk et al. <ref type="bibr" target="#b31">[32]</ref> conducted an evaluation of 10 such tools, showing that GROBID (GeneRation Of BIbliographic Data) <ref type="foot" target="#foot_3">5</ref> and CERMINE <ref type="bibr" target="#b32">[33]</ref> (Content ExtRactor and MINEr) perform best. Among the two, CERMINE is a comprehensive tool for the automatic extraction of paper metadata and content. Most importantly, CERMINE returns the paper's full text structured in sections and subsections. As in the following, we need to discriminate paper text based on the section it appears in, we used CERMINE for PDF-to-text conversion.</p><p>As shown in Figure <ref type="figure">2</ref>, we could not parse 79 (out of 5452 remaining thus far), due to few PDF files containing pages encoded as bitmaps rather than structured content. After removing them, 5373 remained for textual analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Textual analysis</head><p>We performed a series of preparation and cleaning steps on the XML files produced by CERMINE before further analysis.</p><p>First, we retrieved the top used section headers from all papers for manual inspection. Then we eliminated from the extracted paper texts all content belonging to sections like References, Related Work,  Background, Acknowledgement(s), Bibliography, Future Work, and Limitations (we used various variants of this section names, based on the results of popular headers; see the replication package <ref type="bibr" target="#b0">[1]</ref> for full details). The rationale for this choice is that these sections are meta w.r.t. the main content of the paper; whether a paper is mining software artifacts or not will be primarily determined by naming those artifacts in other sections than these. Once we obtained this corpus of relevant text from the papers, we applied classical NLP (Natural Language Processing) cleanup steps to reduce noise and improve the corpus quality. We started by tokenizing: splitting the text stream into words, symbols, punctuation, and postfixes using the Natural Language Toolkit Python library. <ref type="foot" target="#foot_5">6</ref> Then, all upper case characters were converted to lower case. Next, we removed non-alphabetic tokens, and removed stop words. Finally, we applied lemmatization <ref type="bibr" target="#b17">[18]</ref>, in order to use one canonical representation per term (e.g., "codes" becomes "code") and avoid under-counting popular terms that occur in different forms.</p><p>Searching for individual words is often insufficient in text search because abstract terms are often represented as word sequences, such as "bug report" or "source code" <ref type="bibr" target="#b23">[24]</ref>. To solve this issue, computational linguistics commonly uses n-gram analysis-where an n-gram is a sequence of ? contiguous words-to analyze large document corpora in order to identify combinations of words that frequently appear together <ref type="bibr" target="#b21">[22]</ref>. Soper and Turel <ref type="bibr" target="#b30">[31]</ref> suggested that using n-gram analysis allows computer scientists and scholars to gain insights into vast document corpus, as ours.</p><p>We conducted an n-gram analysis on the paper corpus as filtered thus far. We limited the n-grams analysis to a length of a maximum of 2 (i.e., 1-grams and 2-grams) as longer n-grams are rarely repeated in texts. At the end of the process, we obtained a set of 1,2-grams with the number of occurrences for each paper.</p><p>We transformed all n-grams with associated origin information (i.e., the papers they occur in) to a list of records and saved them to a CSV file. Each record consist of the following fields: {ngram, frequency, year, DOI, acronym}. For example {"bug report", 12, 2018, "10.1145/xxx.xxx", "MSR"} means: the n-gram "bug report" occurred 12 times in the (filtered) text of a paper published at MSR 2018 whose DOI is "10.1145/xxx.xxx".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Detection of mined artifacts</head><p>We manually inspected the top-150 1-and 2-grams mined from the paper corpus and partitioned them into a taxonomy of 8 classes of software artifacts, namely: (1) bug data, (2) source code, (3) mail data (e.g., mailing list discussions), (4) code review, (5) commit metadata, (6) test data, <ref type="bibr" target="#b6">(7)</ref> forum data (encompassing discussions on Web forums, Q&amp;A websites like StackOverflow, microblogging Table <ref type="table" target="#tab_1">2</ref> shows an excerpt of the top 2-grams mined from paper texts together with the associated artifact types. For the most part, 1-grams were too generic (e.g., "software" and "data" are the first two 1-grams) to denote the use in papers of specific artifact types, with the exception of "twitter" and "reddit" which we mapped to "forum" (not shown in Table <ref type="table" target="#tab_1">2</ref>). The complete mapping table from n-grams to artifact classes is included in the replication package <ref type="bibr" target="#b0">[1]</ref>.</p><p>To automatically associate papers to mined artifact types, we searched paper texts (searching only within the non-excluded sections discussed before) for the n-grams in the n-gram/artifact mapping table. Papers containing at least 3 occurrences of 2-grams in the mapping table (respectively: at least 4 occurrences of 1-grams) were considered as analyzing the corresponding artifact type. The use of thresholds is meant to avoid stray mentions of n-grams (e.g., a paper mentioning "twitter" only once is more likely to be pointing to a single Twitter profile than mining developer microblogging messages); the difference in thresholds is due to the higher popularity of shorter n-grams in natural language texts. Validation. To evaluate the accuracy of the n-gram-based detector of artifacts mined in analyzed papers, we manually inspected 200 randomly selected papers (3.7% of parsable papers in the dataset). Authors have read each paper, noting down which software artifacts (if any) were mined in the described study.</p><p>Table <ref type="table" target="#tab_2">3</ref> summarizes the precision and recall obtained for each artifact type. Each paper can mine different types of artifacts. Precision for an artifact type hence refers to the proportion of studies that were correctly assigned to a given artifact type; recall refers to the proportion of studies that were correctly assigned to a given artifact type, among those that truly (based on manual inspection) mine artifacts of the given type. On average, both precision and recall are satisfactory, validating the findings discussed in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Detection of study purposes</head><p>To automatically detect paper purposes, we followed the same approach used for artifact detection, with the following differences. We adopted the taxonomy of paper purposes from Farias et al. <ref type="bibr" target="#b5">[6]</ref>,</p><p>Table <ref type="table">4</ref>: Taxonomy of study purposes (from <ref type="bibr" target="#b5">[6]</ref>) and associated n-grams (excerpt). which was developed to classify MSR study purposes using the approach of Basili et al. <ref type="bibr" target="#b2">[3]</ref>. Table <ref type="table">4</ref> recalls the purpose taxonomy and gives an example of n-grams associated with each of them; the full mapping from n-grams to purposes is included in the replication package <ref type="bibr" target="#b0">[1]</ref>. To associate papers to purposes, we analyzed top ngrams extracted only from abstracts, as abstracts generally state explicitly what the study purpose is and are (for purpose detection) less noisy than the rest of the paper text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>We present in this section our experimental results, answering in order the research questions stated in Section 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">RQ 1: most popular software artifacts</head><p>This research question aims to establish which software artifacts are mined the most in software engineering conference papers, and how their amounts evolve over time. We answer this question for the 8 types of artifacts identified in Table <ref type="table" target="#tab_1">2</ref>. By searching for enough occurrences (after threshold verification) of the corresponding ngrams in the relevant sections of 5373 parsable papers, we found that 3367 (62% of parsable papers) mine software artifacts of one or more of the selected types. Software artifact mining happens in the vast majority, almost 2/3, of the papers we have analyzed. Different venues exhibit different ratios of software artifact mining, though. Figure <ref type="figure">3</ref> provides a breakdown by conference of the total number of papers analyzed together with the ratio of papers detected as mining software artifacts by venue. Note how more generalist conferences (ICSE, FSE, ASE) contribute a higher number of papers to the corpus, but have a lower ratio of papers mining software artifacts. Those ratios are high nonetheless, above 50%; it appears that software artifact mining is a foundational research technique in software engineering, popular also in generalist venues. The ratios of papers mining software artifacts are even higher in specialized conferences, such as MSR, ICPC, SCAM and, to a lesser extent, ICSME and SANER.</p><p>Regarding the time dimension of RQ 1, Figure <ref type="figure" target="#fig_2">4</ref>(a) shows the percentages of studies mining each type of artifact, over the years and for the entire corpus. Note that, as the same paper can mine multiple types of artifacts, percentages do not add up to 100%. Artifacts + -Figure <ref type="figure">3</ref>: Total number of papers per conference (after venue merging), with breakdown of papers detected as mining at least one kind of software artifacts (denoted with "+") v. papers detected as not mining any kind of artifacts ("-").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ICSE</head><p>"Source code" is the most mined software artifact, being ranked first throughout the entire period, with a percentage range fluctuating between 64.3-78.9%. It is followed by "test data", consistently ranked second, within a 24.6-39.7% range. Source code and test data are the most mined software artifacts in analyzed studies, and the interest in them by the community has been quite stable over the past 16 years. The interest in analyzing "bug data" comes third. It started to increase in 2008, culminated at 19.9% of yearly papers in 2012, then started decreasing. The number of "commit metadata" studies was negligible before 2005 and increased over time after that. Most notably, in both 2016 and 2019, the relative interest in commit metadata was either the same or slightly superior to that in bug data. The number of studies concerned with analyzing unstructured artifacts (e.g., mailing list) increased slightly over time starting from 2006, consistently to what Farias et al. <ref type="bibr" target="#b5">[6]</ref> observed for a shorter time period, however, it still corresponds to a very small percentage of all analyzed studies.</p><p>Given that the MSR conference was launched as a venue dedicated to mining software repositories studies, which is the main theme of our meta-analysis, we zoom into papers published at MSR with Figure <ref type="figure" target="#fig_2">4(b)</ref>. Comparing Figures <ref type="figure" target="#fig_2">4(a</ref>  more so than in the entire corpus. However, already starting in 2005, MSR papers exhibit a larger variety of mined artifacts. Bug data and commit metadata are taking turns in being the second most mined software artifacts. We also notice in MSR papers higher percentages of unstructured software artifacts being analyzed: mailing list but also code review, which are the second most cited artifact type in MSR 2015 papers. Due to space limitations, in Figure <ref type="figure" target="#fig_2">4</ref> we only highlight results for selected conferences; results for all conferences individually are included in the paper replication package <ref type="bibr" target="#b0">[1]</ref>. By comparing conferences, we notice that source code is even more prominent in ICPC and SCAM papers (Figure <ref type="figure" target="#fig_2">4</ref>(c)), reaching 100% of papers in multiple editions of each conference. Conversely, source code is (relatively) less prominent at more foundational software engineering conferences like ICSE (Figure <ref type="figure" target="#fig_2">4</ref>(d)), FSE, and ASE; it still remains the most referenced artifact type, but in specific years it is overtaken by test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">RQ 2: software artifact combinations</head><p>To answer RQ 2 we consider the papers detected as mining more than one type of software artifacts. 28.5% of the considered papers do so; the rest either do not reference any type of detectable software artifacts or only mention a single artifact type.</p><p>Figure <ref type="figure">5</ref> provides a breakdown of the most popular (top-14) artifact combinations found in the paper corps. The most common combination is of the two types of artifacts which are also the most common ones (individually) that we have identified answering RQ 1: source code &amp; test data. The second combination is source code &amp; bug data, less than half as popular as the first combination, followed by a more smooth decrease. After the top-10 combinations, artifact combinations become increasingly more marginal in popularity, with percentages lower than 0.3%.</p><p>Source code is present in most of the top combinations-all except: bug data &amp; test data, ranked 5th, and test data &amp; code review, ranked 14th-reinforcing the observation that source code is the most relevant software artifact in empirical software engineering 2.49% 2.17% 1.57% 1.25% 0.92% 0.83% 0.77% 0.50% 0.45% 0.24% 0.21% 0.21% 0.18% 0.18% 0.18% 0.18% 0.18% (ESE). Test data, while very popular (6 combinations out of 14) appears to be on more equal footing with bug data (5 combinations) and commit metadata (4 packages) than it appeared to be for RQ 1.</p><p>The topmost combination (ranked 6th) of more than two artifact types mined together is source code &amp; bug data &amp; test data, followed by source code &amp; commit metadata &amp; test data (8th). Other popular combinations of at least three artifact types include permutations of these three artifact types and code reviews. The fact that these four artifact types are also well supported by state-of-the-art social coding platforms like GitHub and GitLab is hardly a coincidence: ESE researchers study, for the most part, data that is made accessible by modern coding technology. In particular, we observe that social coding platforms have increased the availability of code review and bug data, and that seems to correlate with increased research interest in studying those artifacts.</p><p>Figure <ref type="figure">6</ref> focuses on the four most popular artifact types and their intersections. It shows a Venn diagram of the studies (each paper is an element in one of the four sets) that references source code, test data, bug data, and/or commit metadata. Each paper contributes a Looking at the intersections, one can notice that more than half of the studies interested in bug data also consider source code. That ratio goes up to more than 81% for studies looking into commit metadata, which also consider source code. Presumably, studies located in those intersections could not have been conducted by looking solely at non-source-code artifacts. Once again, source code appears to be key for most ESE studies.</p><p>The general theme emerging from our answers to RQs 1 and 2 appears to be that while there is an increasing interest over time in mining novel software artifacts, it is complementing rather than replacing the need for mining source code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">RQ 3: study purposes and software artifacts</head><p>Figure <ref type="figure" target="#fig_5">7</ref> shows a breakdown of papers mining software artifacts by detected study purpose, among those of Table <ref type="table">4</ref>. The category "evaluation" is the highest represented with 1/3 of the studies, followed by "comprehension" (25.9%). "Prediction" comes next (16.7%), followed by "localization" (14.1%). The remaining five purposes represent in total less than 10% of all studies.</p><p>Overall, ESE studies are most concerned with the evaluation of software systems, followed by comprehension (most likely: code comprehension, due to the prevalence of source code in our answers to previous RQs), and property prediction and localization (most likely: defect prediction and bug localization, due to the importance of bug data in previous results).</p><p>To study the relationship between study purposes and mined software artifacts, we show in Figure <ref type="figure" target="#fig_6">8</ref> a bubble chart of the two dimensions. The size of each point in it indicates the number of studies with a given purpose that mine a given type of software artifacts. Note that only papers for which we could detect at least one type of mined software artifacts are included in the chart.</p><p>The most relevant artifact/purpose combination is the use of source code to go after system comprehension. This is consistent with the relevance, both in software engineering at large and in our paper corpus, of sub-fields and venues like program comprehension/ICPC. Looking at both the artifact and purpose axes centered at this particular combination in Figure <ref type="figure" target="#fig_6">8</ref>, we observe that source code is referenced by papers with all purposes except process improvement and, orthogonally, that program comprehension is pursued referencing all types of software artifacts. It seems that researchers are looking for all possible empirical signals in the long-running quest of understanding software systems. Conversely, source code is pervasively exploited to pursue most purposes in ESE research.</p><p>Outside of the over-represented column of source code, noteworthy columns are those of test data (used the most for localization and evaluation) and bug data (prediction, localization and, interestingly, evaluation, likely as a measure of software quality). Commit metadata are most used for prediction studies, likely to predict defects, considering that prediction is also the largest entry in the bug data column.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>Comparison with previous findings. As discussed in Section 2, the most similar previous works to ours are <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. Farias et al. <ref type="bibr" target="#b5">[6]</ref> performed a systematic mapping study on 107 papers from the MSR conference. They found that "comprehension of defects" and "[source] code" were the most common purpose and mined artifact, respectively. They also found that structured artifacts were more mined than unstructured ones, but that the latter's use was increasing. On a larger and more diverse corpus, we have confirmed that source code is the most mined artifact in empirical software engineering (ESE) research. However, we find that comprehension of source code (rather than defects) is the most common study purpose/artifact combination.</p><p>Demeyer et al. <ref type="bibr" target="#b6">[7]</ref>, based on an analysis of papers published at MSR, predicted that the trend to mine more and more unstructured artifacts would continue in the short term. We have shown that this has not happened, neither at MSR nor across our full corpus.</p><p>We have also established that unstructured software artifacts are, for the most part, looked at in conjunction with structured ones.</p><p>In summary, our findings on a larger corpus of ESE papers only partly replicate previous findings on MSR papers <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. MSR trends cannot be extrapolated to all ESE studies in our corpus, and some short-term trends there did not continue as initially predicted.</p><p>Implications of the findings. Source code emerges as the most used and perennial artifact of interest in ESE research. It is the top artifact across all analyzed conference papers, in almost every conference edition; it also supports almost all study purposes in the field. As such, any research support initiative meant to either increase the availability of source code or facilitate mining is worth pursuing to help ESE researchers. In this sense, the emergence of open source software in the 90s and collaborative social coding <ref type="bibr" target="#b4">[5]</ref> in the 2010s have supported ESE research for more than a decade now. Largescale analysis platforms (e.g., <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b20">21]</ref>) and datasets (e.g., <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b26">27]</ref>) for both FOSS source code and related artifacts (commit metadata, bug, etc., which were all mined in the vast majority of analyzed papers) all go in the right direction to support future ESE research. It would be interesting to investigate as future work if the availability of increasingly larger datasets and platforms is resulting in an actual increase of the size of the software artifact corpora that ESE researchers analyze, or if instead we still analyze same-sized ones (e.g., a relatively small sample of GitHub repositories, extrapolating from there).</p><p>The high reliance on software artifacts we have observed poses reliability challenges, particularly for replicability. All analyzed artifacts must be (1) made available and (2) archived in the long-term for as long as replicability is pertinent (possibly forever). Presentday accessibility of artifacts mined in ESE papers remains to be explored in future work, but the diversity of analyzed artifacts is enough to reveal a challenge: we need long-term platforms capable of both archiving and referencing with persistent identifiers a variety of artifact types, both structured and unstructured. The cost of doing so will go up with the size of the analyzed corpora.</p><p>We can also deduct insights for producers of open datasets meant to be used in ESE research. While the usefulness of such datasets has been established <ref type="bibr" target="#b18">[19]</ref>, based on the need to join together multiple types of artifacts for conducting ESE research which we have observed, we speculate that the importance of having mutuallyconsistent datasets will increase in the future. For example, source code datasets that cannot be easily aligned with the corresponding bug and code review data will be less useful (and hence less impactful) than datasets that can. Addressing this problem will require either making sure that ESE datasets provide stable identifiers that permit to easily cross-reference artifacts across heterogeneous datasets, or producing larger "horizontal" datasets that include all artifact types from the software systems of interest, e.g., all GitLab data for a given software ecosystem in a consistent snapshot, as opposed to a set of Git dumps and a separate database dump for social coding events.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">THREATS TO VALIDITY</head><p>We discuss below threats to our findings validity, as well as applied mitigations, following the structure of Runeson and Hoes <ref type="bibr" target="#b28">[29]</ref>.</p><p>Construct validity. The main threat to construct validity is that we categorize papers automatically based on n-gram occurrences rather than manually verifying all of them. We have quantified the impact of this risk by manually verifying 200 papers, obtaining a satisfactory accuracy (see Section 3). We have nevertheless taken steps to mitigate this threat: putting thresholds on the number of n-gram occurrences to avoid incidental references, as well as excluding paper sections where those references are common. Relying on n-grams is also consistent with the state-of-the-art of meta-analyses in ESE <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>In our n-gram analysis, we could have also have missed some n-grams that would denote mining of software artifacts of interest, leading to paper misclassification. We partly mitigated this by spotchecking papers for which we did not detect any artifact, iterating on the association between paper classes and n-grams in Tables <ref type="table" target="#tab_1">2</ref> and<ref type="table">4</ref> until convergence.</p><p>Internal validity. We relied on CERMINE to extract textual content from PDF files. The choice of this tool is based on a third-party quality assessment <ref type="bibr" target="#b32">[33]</ref> pertinent to our use case and on specific functional requirements (e.g., we needed to break down papers by section) and non-functional requirements (e.g., we wanted the tool to be open source to ease replicability). In addition to the documented 79 papers we could not parse, conversion errors might have occurred and influenced obtained results. We mitigated this risk by conducting spot checks on a random subset of papers in the corpus without noticing any relevant issues.</p><p>External validity. We conducted a systematic mapping of papers mining software artifacts, without focusing on a specific venue. We did, however, select both specific conferences and years (Table 1), basing our choices on similar selections performed in related work and on an investigation of which venues welcome and/or regularly publish empirical software engineering (ESE). We might have overlooked studies or entire venues that did not match our selection criteria but should have been included. We do not claim full generality of our findings for the ESE field. But we expect them to capture software artifact mining trends and observe that our choices are consistent with (and our corpus generally larger than) analogous studies in the literature.</p><p>We relied on DBLP as ground truth for papers published in a given venue and year. We could have missed papers that DBLP either lacks or has incorrectly indexed. Given the preeminence of DBLP in computer science and that of its dataset for meta-analyses in the field, we consider this risk to be low. Also, considering the large number of papers retained after filtering, we believe the results we report about to still be valid and of interest.</p><p>Reliability. To mitigate reliability risks, we complement the description of our experimental methodology in Section 3 with a complete replication package <ref type="bibr" target="#b0">[1]</ref>. We encourage replication of our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>Paper summary. We have mined 9621 papers from 11 top conferences that publish papers in the field of empirical software engineering (ESE) with NLP techniques, and n-gram analyses in particular, to map the use of software artifacts in the field over a period of 16 years. We map the most mined software artifacts in ESE studies, finding that the majority of papers in our corpus conspicuously mine at least one type of software artifacts.</p><p>Source code is stably the most frequently mined artifact, followed by test data; the use of other artifact types is more varied, both over time and across conferences. The combined mining of different types of artifacts are significant: about 1/3 of all papers do that, with source code almost always being mined together with other artifacts. Comparing study purposes with mined artifacts, we find that source code analysis supports all study purposes in ESE and that system comprehension is a major interest in the community, supported by the mining of all sorts of artifacts. Our findings imply that increased care should be put into publishing open datasets that mix together different types of artifacts as consistent snapshots, and that digital preservation initiatives should diversify the type of artifacts they allow to archive and reference, in order to better support study replicability.</p><p>Future work. Several directions remain to be explored as future work. Our long-term goal with this work is to assess the degree of repeatability of ESE studies. Establishing which types of artifacts are needed was a necessary first step, to be followed by an analysis of where artifacts come from (e.g., which collaborative coding platform) and an empirical assessment of their present-day availability-either as part of replication packages, at their original locations (if properly documented in studies), or from long-term digital archives. We plan to explore the artifact origin and artifact availability dimensions next.</p><p>Second, we would like to characterize the scale at which ESE studies are conducted or, equivalently, the size of the datasets being used. It is not clear neither if the increasing availability of larger and larger datasets and analysis platforms are really helping the community in conducting larger and larger empirical studies, nor if such studies are actually needed to move the state-of-the-art forward. They are both important questions for the ESE community that we intend to answer next.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of the methodology as a sequence of the following steps: venue selection, paper retrieval and filtering, text extraction, text cleanup, textual analysis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>) and 4(b), we can see that source code is the dominating software artifact at MSR as well, even</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: Percentages of papers mining specific types of software artifacts over time, for the entire corpus. Note that, as each paper can mine multiple types of artifacts, percentages may add up to more than 100%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>s o u r c e c o d e &amp; te s t d a ta s o u r c e c o d e &amp; b u g d a ta s o u r c e c o d e &amp; c o m m it m e ta d a ta s o u r c e c o d e &amp; fo r u m s o u r c e c o d e &amp; c o d e r e v ie w b u g d a ta &amp; te s t d a ta s o u r c e c o d e &amp; b u g d a ta &amp; c o m m it m e ta d a ta s o u r c e c o d e &amp; b u g d a ta &amp; te s t d a ta s o u r c e c o d e &amp; m a il d a ta s o u r c e c o d e &amp; c o m m it m e ta d a ta &amp; te s t d a ta s o u r c e c o d e &amp; c o m m it m e ta d a ta &amp; c o d e r e v ie w s o u r c e c o d e &amp; u m l d ia g r a m s o u r c e c o d e &amp; te s t d a ta &amp; fo r u m s o u r c e c o d e &amp; te s t d a ta &amp; c o d e r e v ie w te s t d a ta &amp; c o d e r e v ie w b u g d a ta &amp; fo r u m s o u r c e c o d e &amp; b u g d a ta &amp; fo r u m m a il d a ta &amp; fo r u m s o u r c e c o d e &amp; b u g d a ta &amp; m a il d</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Figure 5: Ratio of the number of papers that mine more than one type of software artifacts, by decreasing order of mined artifact combination, across all venues.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Ratio of papers pursuing a specific purpose.</figDesc><graphic url="image-15.png" coords="8,341.98,83.69,192.20,156.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure8: Study purposes v. type of mined software artifacts, shown as a bubble chart for the entire corpus. Each bubble denotes the total number of papers detected as having a given purpose and mining a given type of artifact.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table><row><cell>2014-2020</cell><cell>636</cell></row></table><note><p><p><p>Selected software engineering conferences and periods, with number of papers considered for each (before any filtering and venue merging).</p>Acronym</p>Full name Period Papers ASE IEEE/ACM International Conference on Automated Software Engineering 2004-2020 1702 ESEC/FSE ACM SIGSOFT Symposium on the Foundations of Software Engineering 2004-2020 1503 ICPC IEEE International Conference on Program Comprehension 2006-2020 635 ICSE International Conference on Software Engineering 2004-2020 2082 ICSM IEEE International Conference on Software Maintenance 2004-2013 810 ICSME International Conference on Software Maintenance and Evolution</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Excerpt of the top 2-grams extracted from the paper corpus, with software artifact types they are associated to.</figDesc><table><row><cell cols="2">Rank N-gram</cell><cell cols="2">N. of papers Artifact type</cell></row><row><cell>0</cell><cell>(source, code)</cell><cell>1926</cell><cell>source code</cell></row><row><cell>1</cell><cell>(test, case)</cell><cell>771</cell><cell>test data</cell></row><row><cell>2</cell><cell>(test, suite)</cell><cell>494</cell><cell>test data</cell></row><row><cell>3</cell><cell>(line, code)</cell><cell>391</cell><cell>source code</cell></row><row><cell>4</cell><cell>(bug, report)</cell><cell>350</cell><cell>bug data</cell></row><row><cell>6</cell><cell>(code, change)</cell><cell>293</cell><cell>source code</cell></row><row><cell>7</cell><cell>(bug, fix)</cell><cell>262</cell><cell>bug data</cell></row><row><cell>13</cell><cell>(code, snippet)</cell><cell>199</cell><cell>source code</cell></row><row><cell>15</cell><cell>(code, fragment)</cell><cell>194</cell><cell>source code</cell></row><row><cell>16</cell><cell>(source, file)</cell><cell>193</cell><cell>source code</cell></row><row><cell>22</cell><cell>(code, clone)</cell><cell>167</cell><cell>source code</cell></row><row><cell>23</cell><cell>(unit, test)</cell><cell>166</cell><cell>test data</cell></row><row><cell>35</cell><cell>(code, review)</cell><cell>124</cell><cell>code review</cell></row><row><cell>41</cell><cell>(commit, message)</cell><cell>113</cell><cell>commit metadata</cell></row><row><cell>43</cell><cell>(code, file)</cell><cell>110</cell><cell>source code</cell></row><row><cell>45</cell><cell>(test, data)</cell><cell>108</cell><cell>test data</cell></row><row><cell>46</cell><cell>(test, execution)</cell><cell>104</cell><cell>test data</cell></row><row><cell>49</cell><cell>(stack, overflow)</cell><cell>102</cell><cell>forum</cell></row><row><cell>50</cell><cell>(pull, request)</cell><cell>102</cell><cell>commit metadata</cell></row><row><cell>54</cell><cell>(code, smell)</cell><cell>99</cell><cell>source code</cell></row><row><cell>55</cell><cell>(fault, localization)</cell><cell>99</cell><cell>bug data</cell></row><row><cell>81</cell><cell>(defect, prediction)</cell><cell>84</cell><cell>bug data</cell></row><row><cell>106</cell><cell>(mail, list)</cell><cell>75</cell><cell>mail data</cell></row><row><cell>110</cell><cell>(java, code)</cell><cell>74</cell><cell>source code</cell></row><row><cell>116</cell><cell>(class, diagram)</cell><cell>72</cell><cell>uml diagram</cell></row><row><cell>144</cell><cell>(change, code)</cell><cell>67</cell><cell>source code</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Accuracy of the detector of artifacts mined in analyzed papers, based on a ground truth of 200 papers (3.7% of parsable papers) manually reviewed by the authors. UML diagrams (including other diagram languages for describing software systems). While we applied our own judgment and domain knowledge to come up with this taxonomy, what we obtained is consistent with, and in fact a subset of, the taxonomy developed by Farias et al.<ref type="bibr" target="#b5">[6]</ref>.</figDesc><table><row><cell>Artifact type</cell><cell cols="7">TP FP TN FN Accuracy Precision Recall</cell></row><row><cell>bug data</cell><cell>17</cell><cell cols="3">1 167 15</cell><cell>0.92</cell><cell>0.94</cell><cell>0.53</cell></row><row><cell>mail data</cell><cell>5</cell><cell cols="2">2 192</cell><cell>1</cell><cell>0.98</cell><cell>0.71</cell><cell>0.83</cell></row><row><cell>source code</cell><cell cols="2">68 21</cell><cell cols="2">88 23</cell><cell>0.78</cell><cell>0.76</cell><cell>0.75</cell></row><row><cell>code review</cell><cell>2</cell><cell cols="2">2 194</cell><cell>2</cell><cell>0.98</cell><cell>0.50</cell><cell>0.50</cell></row><row><cell>forum</cell><cell>4</cell><cell cols="2">6 188</cell><cell>2</cell><cell>0.96</cell><cell>0.40</cell><cell>0.67</cell></row><row><cell cols="2">commit metadata 10</cell><cell cols="3">0 176 14</cell><cell>0.93</cell><cell>1.00</cell><cell>0.42</cell></row><row><cell>test data</cell><cell cols="3">26 17 154</cell><cell>3</cell><cell>0.90</cell><cell>0.60</cell><cell>0.90</cell></row><row><cell>uml diagram</cell><cell>2</cell><cell cols="2">0 197</cell><cell>1</cell><cell>1.00</cell><cell>1.00</cell><cell>0.67</cell></row><row><cell>Average</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.931</cell><cell>0.738</cell><cell>0.658</cell></row><row><cell cols="4">platforms and Reddit), and (8)</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>We retrieved the dataset from https://dblp.uni-trier.de/xml/ in April 2021; specifically, we used the data dump named dblp-2021-04-01.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://search.crossref.org/, accessed 2022-01-18</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>https://github.com/ferru97/PyPaperBot, accessed 2022-01-06. We slightly modified the tool to store PDFs locally using DOIs as filenames. Our modified version is included in the replication package<ref type="bibr" target="#b0">[1]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>https://github.com/kermitt2/grobid, accessed 2022-01-18</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9621" xml:id="foot_4"><p>research papers 4141 short papers 5480 full papers 5452 primary studies 3367 2006 5373 parseable papers 28 Non-primary study Software artifacts not detected 79 Non-parseable papers Software artifacts related papers</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>https://www.nltk.org/, accessed 2022-01-07</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Zeinab</forename><surname>Abou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khalil</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Zacchiroli</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.5877778</idno>
		<ptr target="https://doi.org/10.5281/zenodo.5877778" />
		<title level="m">Software Artifact Mining in Software Engineering Conferences: A Meta-Analysis -Replication Package</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Software Mining Studies: Goals, Approaches, Artifacts, and Replicability</title>
		<author>
			<persName><forename type="first">Sven</forename><surname>Amann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katja</forename><surname>Kevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harald</forename><forename type="middle">C</forename><surname>Gall</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-28406-4_5</idno>
		<idno>LASER 2013-2014</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-28406-4_5" />
	</analytic>
	<monogr>
		<title level="m">Software Engineering -International Summer Schools</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Bertrand</forename><surname>Meyer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Nordio</surname></persName>
		</editor>
		<meeting><address><addrLine>Elba, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8987</biblScope>
			<biblScope unit="page" from="121" to="158" />
		</imprint>
	</monogr>
	<note>Revised Tutorial Lectures</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Building knowledge through families of experiments</title>
		<author>
			<persName><forename type="first">Forrest</forename><surname>Victor R Basili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filippo</forename><surname>Shull</surname></persName>
		</author>
		<author>
			<persName><surname>Lanubile</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="456" to="473" />
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Incentivizing reproducibility</title>
		<author>
			<persName><forename type="first">Ronald</forename><forename type="middle">F</forename><surname>Boisvert</surname></persName>
		</author>
		<idno type="DOI">10.1145/2994031</idno>
		<ptr target="https://doi.org/10.1145/2994031" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Social coding in GitHub: transparency and collaboration in an open software repository</title>
		<author>
			<persName><forename type="first">Laura</forename><surname>Dabbish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colleen</forename><surname>Stuart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Tsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jim</forename><surname>Herbsleb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM 2012 conference on computer supported cooperative work</title>
		<meeting>the ACM 2012 conference on computer supported cooperative work</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1277" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A systematic mapping study on mining software repositories</title>
		<author>
			<persName><forename type="first">M?rio</forename><surname>Andr? De Freitas Farias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renato</forename><surname>Lima Novais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Methanias</forename><surname>Cola?o J?nior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silva</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manoel</forename><forename type="middle">G</forename><surname>Mendon?a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodrigo</forename><forename type="middle">Oliveira</forename><surname>Sp?nola</surname></persName>
		</author>
		<idno type="DOI">10.1145/2851613.2851786</idno>
		<ptr target="https://doi.org/10.1145/2851613.2851786" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Annual ACM Symposium on Applied Computing</title>
		<editor>
			<persName><forename type="first">Sascha</forename><surname>Ossowski</surname></persName>
		</editor>
		<meeting>the 31st Annual ACM Symposium on Applied Computing<address><addrLine>Pisa, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016-04-04">2016. April 4-8, 2016</date>
			<biblScope unit="page" from="1472" to="1479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Happy birthday! a trend analysis on past MSR papers</title>
		<author>
			<persName><forename type="first">Serge</forename><surname>Demeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Murgia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Wyckmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Lamkanfi</surname></persName>
		</author>
		<idno type="DOI">10.1109/MSR.2013.6624049</idno>
		<ptr target="https://doi.org/10.1109/MSR.2013.6624049" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Working Conference on Mining Software Repositories, MSR &apos;13</title>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Zimmermann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Massimiliano</forename><surname>Di Penta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sunghun</forename><surname>Kim</surname></persName>
		</editor>
		<meeting>the 10th Working Conference on Mining Software Repositories, MSR &apos;13<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2013-05-18">2013. May 18-19, 2013</date>
			<biblScope unit="page" from="353" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Software Heritage: Why and How to Preserve Software Source Code</title>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cosmo</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Zacchiroli</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-01590958/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Digital Preservation, iPRES</title>
		<meeting>the 14th International Conference on Digital Preservation, iPRES</meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Boa: A language and infrastructure for analyzing ultra-large-scale software repositories</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anh</forename><surname>Hoan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hridesh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tien</forename><forename type="middle">N</forename><surname>Rajan</surname></persName>
		</author>
		<author>
			<persName><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 International Conference on Software Engineering</title>
		<meeting>the 2013 International Conference on Software Engineering</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="422" to="431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<idno type="DOI">10.1007/978-3-030-32489-6</idno>
		<idno>978- 3-030-32489-6</idno>
		<ptr target="https://doi.org/10.1007/" />
		<title level="m">Contemporary Empirical Methods in Software Engineering</title>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Felderer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Guilherme</forename><surname>Horta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Travassos</forename></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automating systematic literature review</title>
		<author>
			<persName><forename type="first">R</forename><surname>Katia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">C</forename><surname>Felizardo</surname></persName>
		</author>
		<author>
			<persName><surname>Carver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Contemporary Empirical Methods in Software Engineering</title>
		<imprint>
			<biblScope unit="page" from="327" to="355" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">GHTorrent: Github&apos;s data from a firehose</title>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Gousios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diomidis</forename><surname>Spinellis</surname></persName>
		</author>
		<idno type="DOI">10.1109/MSR.2012.6224294</idno>
		<ptr target="https://doi.org/10.1109/MSR.2012.6224294" />
	</analytic>
	<monogr>
		<title level="m">th IEEE Working Conference of Mining Software Repositories</title>
		<editor>
			<persName><forename type="first">Michele</forename><surname>Msr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Massimiliano</forename><surname>Lanza</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tao</forename><surname>Di Penta</surname></persName>
		</editor>
		<editor>
			<persName><surname>Xie</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="12" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The road ahead for mining software repositories</title>
		<author>
			<persName><surname>Ahmed E Hassan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers of Software Maintenance. IEEE</title>
		<imprint>
			<biblScope unit="page" from="48" to="57" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The MSR cookbook: Mining a decade of research</title>
		<author>
			<persName><forename type="first">Hadi</forename><surname>Hemmati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Nadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olga</forename><surname>Baysal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksii</forename><surname>Kononenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reid</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Godfrey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 10th Working Conference on Mining Software Repositories (MSR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="343" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">FLOSSmole: A Collaborative Repository for FLOSS Research Data and Analyses</title>
		<author>
			<persName><forename type="first">James</forename><surname>Howison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Megan</forename><surname>Conklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Crowston</surname></persName>
		</author>
		<idno type="DOI">10.4018/jitwe.2006070102</idno>
		<ptr target="https://doi.org/10.4018/jitwe.2006070102" />
	</analytic>
	<monogr>
		<title level="j">IJITWE</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="17" to="26" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Meta-research: The art of getting it wrong</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><surname>Ioannidis</surname></persName>
		</author>
		<idno type="DOI">10.1002/jrsm.19</idno>
		<ptr target="https://doi.org/10.1002/jrsm.19" />
	</analytic>
	<monogr>
		<title level="j">Res. Synth. Methods</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="169" to="184" />
			<date type="published" when="2010-07">2010. Jul 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A survey and taxonomy of approaches for mining software repositories in the context of software evolution</title>
		<author>
			<persName><forename type="first">Huzefa</forename><surname>Kagdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">I</forename><surname>Michael L Collard</surname></persName>
		</author>
		<author>
			<persName><surname>Maletic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of software maintenance and evolution: Research and practice</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="77" to="131" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">To stem or lemmatize a highly inflectional language in a probabilistic IR environment</title>
		<author>
			<persName><forename type="first">Kimmo</forename><surname>Kettunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tuomas</forename><surname>Kunttu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalervo</forename><surname>J?rvelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Documentation</title>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Standing on shoulders or feet? An extended study on the usage of the MSR data papers</title>
		<author>
			<persName><forename type="first">Zoe</forename><surname>Kotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantinos</forename><surname>Kravvaritis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantina</forename><surname>Dritsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diomidis</forename><surname>Spinellis</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10664-020-09834-7</idno>
		<ptr target="https://doi.org/10.1007/s10664-020-09834-7" />
	</analytic>
	<monogr>
		<title level="j">Empir. Softw. Eng</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="3288" to="3322" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<author>
			<persName><forename type="first">Michael</forename><surname>Ley</surname></persName>
		</author>
		<idno type="DOI">10.1007/3-540-45735-6_1</idno>
		<ptr target="https://doi.org/10.1007/3-540-45735-6_1" />
	</analytic>
	<monogr>
		<title level="m">The DBLP Computer Science Bibliography: Evolution, Research Issues, Perspectives. In String Processing and Information Retrieval, 9th International Symposium</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">F</forename><surname>Alberto</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Arlindo</forename><forename type="middle">L</forename><surname>Laender</surname></persName>
		</editor>
		<editor>
			<persName><surname>Oliveira</surname></persName>
		</editor>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002-09-11">2002. 2002. September 11-13, 2002</date>
			<biblScope unit="volume">2476</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">World of code: an infrastructure for mining the universe of open source VCS data</title>
		<author>
			<persName><forename type="first">Yuxing</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Bogart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sadika</forename><surname>Amreen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russell</forename><surname>Zaretzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Audris</forename><surname>Mockus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Mining Software Repositories</title>
		<meeting>the 16th International Conference on Mining Software Repositories</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="143" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Foundations of statistical natural language processing</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schutze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Finding Trends in Software Research</title>
		<author>
			<persName><forename type="first">George</forename><surname>Mathew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amritanshu</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Menzies</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSE.2018.2870388</idno>
		<ptr target="https://doi.org/10.1109/TSE.2018.2870388" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Business intelligence in banking: A literature analysis from 2002 to 2013 using text mining and latent Dirichlet allocation</title>
		<author>
			<persName><forename type="first">S?rgio</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Cortez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Rita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1314" to="1324" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Guest Editors&apos; Introduction: Mining Software Archives</title>
		<author>
			<persName><forename type="first">Nachiappan</forename><surname>Nagappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Zeller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Zimmermann</surname></persName>
		</author>
		<idno type="DOI">10.1109/MS.2009.14</idno>
		<ptr target="https://doi.org/10.1109/MS.2009.14" />
	</analytic>
	<monogr>
		<title level="j">IEEE Softw</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="24" to="25" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Software evolution visualization: A systematic mapping study</title>
		<author>
			<persName><forename type="first">Renato</forename><surname>Lima Novais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andr?</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thiago</forename><surname>Souto Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manoel</forename><surname>Mendon?a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nico</forename><surname>Zazworka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Software Technology</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="1860" to="1883" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The Software Heritage graph dataset: public software development under one roof</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Pietri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diomidis</forename><surname>Spinellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Zacchiroli</surname></persName>
		</author>
		<ptr target="https://dl.acm.org/citation.cfm?id=3341907" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Mining Software Repositories</title>
		<editor>
			<persName><forename type="first">Anne</forename><forename type="middle">D</forename><surname>Margaret</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bram</forename><surname>Storey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sonia</forename><surname>Adams</surname></persName>
		</editor>
		<editor>
			<persName><surname>Haiduc</surname></persName>
		</editor>
		<meeting>the 16th International Conference on Mining Software Repositories<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-27">2019. 2019, 26-27 May 2019</date>
			<biblScope unit="page" from="138" to="142" />
		</imprint>
	</monogr>
	<note>IEEE / ACM</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Replicating MSR: A study of the potential replicability of papers published in the mining software repositories proceedings</title>
		<author>
			<persName><forename type="first">Gregorio</forename><surname>Robles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 7th IEEE Working Conference on Mining Software Repositories (MSR 2010)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Guidelines for conducting and reporting case study research in software engineering</title>
		<author>
			<persName><forename type="first">Per</forename><surname>Runeson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>H?st</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Engineering</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">131</biblScope>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<idno type="DOI">10.1007/978-1-84800-044-5</idno>
		<ptr target="https://doi.org/10.1007/978-1-84800-044-5" />
		<title level="m">Guide to Advanced Empirical Software Engineering</title>
		<editor>
			<persName><forename type="first">Forrest</forename><surname>Shull</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Janice</forename><surname>Singer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">K</forename><surname>Dag</surname></persName>
		</editor>
		<editor>
			<persName><surname>Sj?berg</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An n-gram analysis of Communications 2000-2010</title>
		<author>
			<persName><forename type="first">S</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ofir</forename><surname>Soper</surname></persName>
		</author>
		<author>
			<persName><surname>Turel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="81" to="87" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Machine learning vs. rules and out-of-the-box vs. retrained: An evaluation of open-source bibliographic reference and citation parsers</title>
		<author>
			<persName><forename type="first">Dominika</forename><surname>Tkaczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paraic</forename><surname>Sheridan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joeran</forename><surname>Beel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM</title>
		<meeting>the 18th ACM</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="99" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">CERMINE: automatic extraction of structured metadata from scientific literature</title>
		<author>
			<persName><forename type="first">Dominika</forename><surname>Tkaczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pawel</forename><surname>Szostek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Fedoryszak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Dendek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Bolikowski</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10032-015-0249-8</idno>
		<ptr target="https://doi.org/10.1007/s10032-015-0249-8" />
	</analytic>
	<monogr>
		<title level="j">Int. J. Document Anal. Recognit</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="317" to="335" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A historical dataset of software engineering conferences</title>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Vasilescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Serebrenik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Mens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 10th Working Conference on Mining Software Repositories (MSR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="373" to="376" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
