<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LARGE LANGUAGE MODELS CAN BE STRONG DIFFERENTIALLY PRIVATE LEARNERS</title>
				<funder ref="#_8FUE9rs #_WDAwsG2 #_MdbaJKK">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-11-10">10 Nov 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xuechen</forename><surname>Li</surname></persName>
							<email>lxuechen@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Florian</forename><surname>Tram?r</surname></persName>
							<email>tramer@cs.stanford.edu</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
							<email>pliang@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">LARGE LANGUAGE MODELS CAN BE STRONG DIFFERENTIALLY PRIVATE LEARNERS</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-11-10">10 Nov 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2110.05679v6[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Differentially Private (DP) learning has seen limited success for building large deep learning models of text, and straightforward attempts at applying Differentially Private Stochastic Gradient Descent (DP-SGD) to NLP tasks have resulted in large performance drops and high computational overhead. We show that this performance drop can be mitigated with (1) the use of large pretrained language models; (2) non-standard hyperparameters that suit DP optimization; and (3) finetuning objectives which are aligned with the pretraining procedure. With the above, we obtain NLP models that outperform state-of-the-art DP-trained models under the same privacy budget and strong non-private baselines-by directly fine-tuning pretrained models with DP optimization on moderately-sized corpora. To address the computational challenge of running DP-SGD with large Transformers, we propose a memory saving technique that allows clipping in DP-SGD to run without instantiating per-example gradients for any linear layer in the model. The technique enables privately training Transformers with almost the same memory cost as non-private training at a modest run-time overhead. Contrary to conventional wisdom that DP optimization fails at learning high-dimensional models (due to noise that scales with dimension) empirical results reveal that private learning with pretrained language models doesn't tend to suffer from dimension-dependent performance degradation. Code to reproduce results can be found at https: //github.com/lxuechen/private-transformers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Machine learning systems trained on sensitive user data can be vulnerable to privacy attacks <ref type="bibr" target="#b70">(Shokri et al., 2017;</ref><ref type="bibr" target="#b26">Hayes et al., 2019)</ref>. This issue is especially pressing for recent applications of large language models, as these models are capable of memorizing and reconstructing sensitive examples contained in the training data <ref type="bibr" target="#b86">(Zhang et al., 2016;</ref><ref type="bibr" target="#b11">Carlini et al., 2020)</ref>.</p><p>As a result of these concerns, there has been a large interest in developing methods that provide data privacy guarantees for large language models. The standard paradigm for providing such a guarantee in machine learning is Differential Privacy (DP) <ref type="bibr" target="#b19">(Dwork et al., 2006;</ref><ref type="bibr">2014)</ref>. Unfortunately, DP learning has typically struggled to produce useful models when applied to large language models, resulting in models with either vacuous privacy guarantees <ref type="bibr" target="#b18">(Dupuy et al., 2021)</ref> or performance far below non-private baselines. This is widely attributed to the fact that the core primitive of Differentially Private Stochastic Gradient Descent (DP-SGD) <ref type="bibr" target="#b72">(Song et al., 2013;</ref><ref type="bibr" target="#b3">Bassily et al., 2014;</ref><ref type="bibr" target="#b0">Abadi et al., 2016)</ref> injects noise that must scale with the number of parameters, resulting in large noise levels for large language models <ref type="bibr">(Yu et al., 2021b)</ref>.</p><p>We tackle the problem of building performant DP language models for sentence classification and language generation tasks with merely tens to hundreds of thousands of examples. We pursue this goal by re-examining the performance of the baseline DP optimization algorithm for fine-tuning large language models, and study how choices of hyperparameters, training objective, and pretrained models affect the performance given fixed privacy budgets. In contrast to the mainstream perception, our empirical results demonstrate that large pretrained models with hundreds of millions of parameters can be effectively and efficiently fine-tuned to yield models with high performance under modest privacy leakage. For sentence classification, the performance of our fine-tuned (a) Sentence classification MNLI-matched <ref type="bibr" target="#b79">(Williams et al., 2018)</ref>  (b) Natural language generation E2E <ref type="bibr" target="#b56">(Novikova et al., 2017)</ref> Figure <ref type="figure">1</ref>: A summary of a few of our findings: (1) Pretrained models fine-tuned with DP-Adam has strong performance. (2) Fine-tuning larger models produces better results.</p><p>(3) Fine-tuned RoBERTalarge under DP at = 3 outperforms TextHide (the extension of InstaHide <ref type="bibr">(Huang et al., 2020b</ref>) for text classification) with BERT-base. Non-private generation baseline numbers are based on those reported by <ref type="bibr" target="#b80">Wiseman et al. (2018)</ref>.</p><p>models surpasses those obtained under heuristic privacy notions <ref type="bibr">(Huang et al., 2020a)</ref> which do not possess formal privacy guarantees. For text generation, the performance of our models surpasses strong non-private baselines. Figure <ref type="figure">1</ref> illustrates some of these results and the overall scaling behavior. We summarize our contributions below.</p><p>(1) We show that with appropriate hyperparameters and downstream task objectives, fine-tuning pretrained language models with DP-SGD/DP-Adam yields strong performance for a suite of NLP tasks at privacy levels ? {3, 8}. Some of our fine-tuned models outperform strong non-private learning baselines and models obtained under heuristic privacy notions.</p><p>(2) Running DP-SGD can be memory-intensive due to clipping per-example gradients. We present ghost clipping, a memory saving technique that makes fine-tuning large Transformers under DP memory efficient. Our technique generalizes the <ref type="bibr" target="#b24">Goodfellow (2015)</ref> trick to handle sequential inputs, and can be combined with a layer-by-layer clipping procedure <ref type="bibr" target="#b39">(Lee &amp; Kifer, 2020)</ref> to enable privately fitting large Transformers with almost the same memory cost as non-private training-at the cost of one additional backward pass per processed batch.</p><p>(3) We show that the dimensionality of gradient updates does not explain private fine-tuning performance. While there exist dimension-dependent lower bounds for private (convex) optimization <ref type="bibr" target="#b3">(Bassily et al., 2014)</ref>, we find that larger pretrained models lead to better private fine-tuning results. Moreover, parameter-efficient adaptation methods that reduce the dimensionality of updates do not necessarily outperform a baseline method that fine-tunes all model parameters.</p><p>Our empirical studies indicate that directly fine-tuning pretrained models with DP optimization results in performant DP language models under modest privacy budgets. This enables building practical private NLP models for a range of common tasks where privacy could be at stake.</p><p>We say that two datasets are adjacent if and only if one can be obtained from the other by including an extra record. 1 How a record is defined is task dependent and will be made clear below.</p><p>Intuitively, DP algorithms ensure that random outputs obtained from similar inputs are difficult to distinguish. and ? are privacy leakage parameters that measure the loss of privacy and small values imply stronger privacy guarantees. Unlike heuristic privacy notions <ref type="bibr">(Huang et al., 2020b)</ref>, DP allows for the tracking of privacy loss through the calculation of leakage parameters, and ensures privacy under composition <ref type="bibr" target="#b20">(Dwork et al., 2014)</ref>, meaning that the overall privacy loss of multiple DP algorithms releasing multiple statistics can be reasoned in a principled manner.</p><p>DP learning typically relies on DP optimizers which privatize gradients before performing updates. The privatization step ensures that parameter updates leak limited information about training examples through their gradients. Specifically, this step clips per-example gradients with a norm constraint C, and adds Gaussian noise z ? N (0, C 2 ? 2 I p ) to the sum of clipped gradients. Here, ? is the noise multiplier determined from the privacy budget ( , ?), number of gradient updates S, and sampling rate q = B N for a batch size of B and a dataset size of N . 2 Intuitively, clipping individual gradients ensures that each example has bounded influence on the parameter update, whereas noising the gradient prevents exact tracing of particular examples. The noise being isotropic implies that larger models would experience heavier noise per update, as the norm of the p-dimensional Gaussian z 2 scales as C? ? p. This is widely believed to be the cause for DP optimization to perform poorly at training high-dimensional deep learning models <ref type="bibr" target="#b34">(Kamath, 2020;</ref><ref type="bibr">Yu et al., 2021b)</ref>.</p><p>Our starting point for building DP language models is (public) pretrained models. Pretrained language models tend to contain general knowledge of language <ref type="bibr" target="#b47">(Manning et al., 2020)</ref> and thus should make the downstream private learning problem easier. We fine-tune these models with DP-Adam <ref type="bibr" target="#b0">(Abadi et al., 2016;</ref><ref type="bibr" target="#b37">Kingma &amp; Ba, 2014)</ref> (see Appendix A for details) and track privacy loss through R?nyi DP <ref type="bibr" target="#b52">(Mironov, 2017)</ref>, but also report the converted from a Gaussian DP central limit theorem <ref type="bibr" target="#b17">(Dong et al., 2019)</ref> and from accurately composing tradeoff functions via fast Fourier transform <ref type="bibr" target="#b25">(Gopi et al., 2021)</ref>. We consider privacy levels ? {3, 8} and ? = 1 2|Dtrain| throughout for a training set of size |D train | (see Appendix B for further details). We tune hyperparameters on a text generation task (E2E; introduced below) and transfer these to remaining tasks. We outline two broad classes of NLP problems considered in this paper and define what constitutes a record below.</p><p>Sentence Classification. The goal is to learn a model that classifies sentences into one of a few categories. For these tasks, each example/record consists of input sentences and a label to be predicted. We fine-tune models of various sizes in the BERT <ref type="bibr" target="#b15">(Devlin et al., 2018)</ref> and RoBERTa <ref type="bibr">(Liu et al., 2019)</ref> families, as these models are known to work well in non-private learning.</p><p>Language Generation. The goal is to learn a model that generates natural language sentences given some context. For table-to-text generation tasks such as E2E <ref type="bibr" target="#b56">(Novikova et al., 2017)</ref> and DART <ref type="bibr" target="#b54">(Nan et al., 2020)</ref>, each example/record in the training data consists of a pair of table entry and corresponding text description to be predicted. For a dialogue generation task such as Persona-Chat <ref type="bibr" target="#b88">(Zhang et al., 2018)</ref>, each example/record consists of metadata, a dialogue history, and a response to be predicted. We fine-tune GPT-2 <ref type="bibr" target="#b66">(Radford et al., 2019)</ref> and variants of different sizes for these problems, as this model family is known to work well for text generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EFFECTIVE DIFFERENTIALLY PRIVATE FINE-TUNING</head><p>By studying the impact of hyperparameters and choice of fine-tuning objective, we demonstrate that the performance of the DP-Adam baseline can be substantially improved, even matching some strong non-private learning results. Our analyses reveal common failure modes when straightforwardly applying DP optimization and explain poor results reported in past works that consider these baselines.</p><p>1 An alternative definition of adjacency assumes all datasets are of equal size and is based on the replacement of records. This is not the definition we adopt.</p><p>2 Since we adopted the definition of "neighboring" based on addition/removal, the batch size here should be interpreted as the lot size <ref type="bibr" target="#b0">(Abadi et al., 2016)</ref> or, equivalently stated, the expected size of a batch drawn with Poisson sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">HYPERPARAMETER TUNING</head><p>DP optimization is sensitive to the choice of hyperparameters <ref type="bibr" target="#b60">(Papernot et al., 2019)</ref>. Our experiments suggest that its performance can vary from being close to that of random initialization with ill-chosen hyperparameters to near state-of-the-art with appropriately chosen ones. As a consequence, we present simple but effective guidelines on setting the most important hyperparameters. Unless otherwise stated, the unmentioned hyperparameters are set to defaults documented in Appendix H.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">BATCH SIZE, LEARNING RATE &amp; TRAINING EPOCHS</head><p>Our experiments suggest that batch size is one of the most important hyperparameters to set correctly, and the dependence of the optimal batch size on the learning rate and training epochs makes its selection complex. We first describe batch size selection in realistic, compute-bound settings and then describe how the complexity of identifying the optimal batch size in these situations arise due to constraints on the number of training epochs.   Fixed Training Epochs E. We first describe a very practical situation in which there is a constraint on the compute budget. For the case of DP-SGD, this compute budget constraint often loosely translates to a constraint on the number of examples processed for gradient updates. <ref type="foot" target="#foot_0">3</ref> In this fixed training epoch setting, the learning rate and batch size jointly affect performance, since using larger batches implies performing fewer gradient updates. To study this joint influence empirically, we fine-tune GPT-2 on the E2E dataset for table-to-text generation with DP-Adam at = 3 with various batch sizes and learning rates. Figure <ref type="figure" target="#fig_2">2</ref> shows that the best performing models (BLEU score 62) are obtained with both a large batch size and large learning rate. Using a small learning rate together with a small batch size yields considerably worse results. Note a seq2seq baseline achieves a test BLEU of 65 without privacy here <ref type="bibr" target="#b80">(Wiseman et al., 2018)</ref>.</p><p>Recall that in the non-private world, pretrained language models are typically fine-tuned with small batch sizes and small learning rates with Adam (bottom left panel in Figure <ref type="figure" target="#fig_2">2</ref>). This implies that na?vely fine-tuning pretrained language models privately using hyperparameters routinely used for non-private learning would degrade performance by more than necessary. <ref type="foot" target="#foot_1">4</ref>Recently, <ref type="bibr" target="#b76">Tram?r &amp; Boneh (2020)</ref> studied how the batch size and learning rate jointly affect learning private image classifiers while holding other hyperparameters fixed. They heuristically suggested a linear scaling rule: Scaling the learning rate together with the batch size by the same constant should yield models with almost the same performance. However, Figure <ref type="figure" target="#fig_2">2</ref> indicates that this fails to hold consistently as it falsely predicts that large batch and high learning rate (top right entry) would have equal performance to small batch and low learning rate (bottom left entry). We explain why linear scaling fails to predict performance for the small batch regime in Appendix D.</p><p>Fixed Update Steps S. In the fixed epoch setting, we saw that the optimal batch size was complex due to the trade-off between batch size and number of gradient updates. We now show that the complexity of setting batch sizes arises almost entirely from this tradeoff by considering a different setting, where the total number of gradient updates (rather than epochs) is fixed. In this case, using larger batches implies training for more epochs.</p><p>Here, we find that using larger batch sizes almost always results in better performance at a given privacy budget at the cost of processing more examples with more compute, once the other hyperparameters S, ?, C, , and ? are fixed. We provide a heuristic explanation of this by introducing the idea of an effective noise multiplier ? eff = ? q = ?N B . Recall the noise multiplier ? is determined from the privacy budget ( , ?), the number of update steps S, and the sampling rate q. In addition, recall the privatized gradient ? in DP-SGD/DP-Adam which loosely takes the following form:</p><formula xml:id="formula_0">? = g + z, g = 1 B i?B Clip(?L i , C), z ? N 0, C 2 ? 2 B 2 I p = N 0, C 2 ? 2 eff N 2 I p ,<label>(1)</label></formula><p>where B is the Poisson-sampled batch of indices, ?L i is the gradient of the ith example and Clip(v, C) = v ? min(1, C / v 2 ) clips the vector v by the norm constraint C. We observe that for moderately large batches, the signal-to-noise ratio r = g 2/ z 2 is mainly controlled by the batch size through the effective noise multiplier: The signal term g tends to concentrate quickly due to being an average of bounded vectors, whereas the effective noise multiplier ? eff decreases as the batch size B increases (shown in Figure <ref type="figure">3</ref> (a)). Figure <ref type="figure">3</ref> (b) plots the average signal-to-noise ratio r over the first 30 gradient updates against the final model's performance on E2E and demonstrates that large batches (up to a threshold) correlates with both increased signal-to-noise ratio at the beginning of training and better performance at the end of training. These findings additionally resonate with and explains recent empirical successes of large-scale private pretraining <ref type="bibr" target="#b1">(Anil et al., 2021)</ref>. E2E test set per token NLL q = 2 8 q = 2 7 q = 2 6 q = 2 5 q = 2 3 q = 2 2 q = 2 1 q = 2 0 Figure 3: Left: Effective noise multiplier decreases with increasing sampling rate for various fixed number of updates S. Right: Large batch sizes (corresponding to large q in the figure) have higher signal-to-noise ratio at the beginning of training, which log-linearly correlates with final performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">CLIPPING NORM</head><p>DP optimization is known to be sensitive to the choice of clipping norm. Since the scale of noise depends on this clipping norm (recall its standard deviation is C?), picking the threshold C much larger than the actual gradient norm implies more noise is being applied than necessary. In practice, we have found that a small clipping norm which enforces almost all gradients to be clipped throughout training leads to the best performing models (see Figure <ref type="figure" target="#fig_11">8</ref> in Appendix H).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">IMPROVING THE TASK ALIGNMENT HELPS PRIVATE LEARNING</head><p>Our fine-tuned models on language generation tasks work well since the pretraining objective and downstream task are aligned: Both involve predicting sequences of tokens. This alignment simplifies the task and benefits private learning. While pretrained models are naturally aligned for language generation, it is much less so for classification tasks. The standard approach for adapting language models for classification involves stacking a freshly initialized network on top of the encoding of the special [CLS] token and jointly optimizing all parameters <ref type="bibr" target="#b15">(Devlin et al., 2018)</ref>. This workflow introduces a discrepancy between pretraining and fine-tuning: Pretraining predicts masked out words from a large vocabulary whereas fine-tuning predicts integer labels.</p><p>To eliminate the discrepancy, we instead consider learning to predict the missing word during finetuning for classification. For example, for sentiment classification, we reframe the problem as filling in the [MASK] token in the sequence "&lt;INPUT&gt;. It is <ref type="bibr">[MASK]</ref>." and compare the probabilities of words "awesome" and "terrible". This text infilling task is almost exactly the procedure used for pretraining masked language models, and recent works have demonstrated its effectiveness for knowledge probing <ref type="bibr" target="#b62">(Petroni et al., 2019)</ref>, few-shot learning <ref type="bibr" target="#b22">(Gao et al., 2020)</ref> and multi-task finetuning <ref type="bibr" target="#b78">(Wei et al., 2021)</ref>. On SST-2, we found that using the generic template as described above already improved private fine-tuning performance by 3 ? 5% across different settings. Table <ref type="table" target="#tab_1">1</ref> (to be presented) contains additional results and Appendix E includes analyses on choices of label words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">GHOST CLIPPING: CLIPPING WITHOUT PER-EXAMPLE GRADIENTS</head><p>DP-SGD has high memory overhead due to clipping per-example gradients. Na?vely implemented, this step instantiates a giant gradient vector for each example during optimization and can be prohibitively expensive. For example, <ref type="bibr" target="#b28">Hoory et al. (2021)</ref> pretrained BERT with DP optimization and reported memory issues when using the large batches necessary to achieve high performance.</p><p>A time-costly solution to the memory problem is micro-batching: Split large batches into multiple smaller ones and aggregate the results after processing each small batch individually <ref type="bibr" target="#b76">(Tram?r &amp; Boneh, 2020)</ref>. This solution, however, is unlikely to be sufficient as neural language models become larger and fitting even a few copies of the gradient in memory can be difficult. <ref type="bibr" target="#b39">Lee &amp; Kifer (2020)</ref> observed that per-example gradients need not be instantiated at all, if the goal is to sum the clipped gradients. They presented a clipping procedure that only instantiates the per-example gradient for parameters of a single layer in the model one at a time, as opposed to the entire model at once, at the cost of an extra backpropagation pass per processed batch.</p><p>Unfortunately, we find this trick to be still insufficient for sequence models such as Transformers <ref type="bibr" target="#b77">(Vaswani et al., 2017)</ref>, as the memory requirement for per-example gradients of embedding layers and language modeling heads can be costly. We extend the <ref type="bibr" target="#b39">Lee &amp; Kifer (2020)</ref> approach such that training Transformers with DP optimization can have almost the same memory consumption as non-private training. Unlike their approach, our extension avoids instantiating the per-example gradient even for individual linear layers. We call this approach ghost clipping, as the per-example gradient is the ghost that never explicitly appears. We anticipate this extension to be useful for both privately fine-tuning and pretraining large Transformers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">THE MEMORY TRICK BY LEE &amp; KIFER (2020)</head><p>Per-example gradient clipping is easy if we know per-example gradient norms. In this case, we first compute the scaling factor c i = min(1, C / ?Li 2 ), where C is the clipping threshold and L i is the loss associated with the ith example. Then, we perform the usual backward pass with the reweighted scalar loss i c i L i . This procedure gives us the sum of clipped gradients. Under this setup, the difficulty is computing the per-example gradient norm ?L i 2 . We emphasize two technicalities that enable computing this quantity without instantiating the full per-example gradient ?L i .</p><p>First, for a typical neural net layer l with parameters W (l) (without parameter sharing), the perexample gradient w.r.t. parameters can be easily computed using the input to the layer a (l) and the gradient of the loss w.r.t. the output g (l) , both of which are available during backpropagation. Second, for a large vector formed by concatenating several small vectors u = [u 1 , . . . , u k ], its Euclidean norm is simply the norm of the vector of norms, i.e. u 2 = ( u 1 2 , . . . , u k 2 ) 2 . The second observation means that computing the per-example gradient norm ?L i 2 can be done by computing the per-example gradient norms for individual layers of the neural net ? W (1) L i 2 , . . . , ? W (L) L i 2 one at a time (L is layer count). Moreover, the first observation implies that the norms for each layer can be computed using quantities freely available to a typical backward pass. Overall, the per-example gradient norm of any network without parameter sharing can be computed in a layer-by-layer fashion with only one per-example gradient tensor for a single layer being instantiated at any time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">GHOST CLIPPING FOR TRANSFORMERS WITH SEQUENTIAL DATA</head><p>The trick by <ref type="bibr" target="#b39">Lee &amp; Kifer (2020)</ref> still requires instantiating the per-example gradient of individual layers (although not simultaneously). This can be problematic in terms of memory for Transformers with large embedding layers. <ref type="foot" target="#foot_2">5</ref> Here, we present a specialized procedure for computing the perexample gradient norm for linear and embedding layers when they are applied to sequential data. <ref type="foot" target="#foot_3">6</ref>This procedure reduces memory footprint and can be viewed as a generalization of the <ref type="bibr" target="#b24">Goodfellow (2015)</ref> trick that additionally handles sequential inputs.</p><p>Let a ? R B?T ?d be the input to a linear layer with weight matrix W ? R p?d , and s ? R B?T ?p be the output with s i,j = W a i,j . Let g ? R B?T ?p be the gradient of the loss w.r.t. the output s. Here, T is the number of time steps in the input, and we omitted biases for simplicity. Simple calculation shows that the per-example gradient is the product of two matrices:</p><formula xml:id="formula_1">? W L i = g i a i ? R p?d .</formula><p>(2) Since the per-example gradient norms are the end goal, the per-example gradients</p><formula xml:id="formula_2">{? W L i } B i=1</formula><p>themselves need not be instantiated explicitly. More precisely, we observe that the squared perexample gradient norm for this layer ? W L i 2 F obeys the following key identity:</p><formula xml:id="formula_3">? W L i 2 F = vec(a i a i ) vec(g i g i ).</formula><p>(3)</p><p>See Appendix F for a derivation. Implemented with common primitives in machine learning libraries,</p><p>(3) has a memory complexity of order O(BT 2 ) when a i a i ? R T ?T and g i g i ? R T ?T are instantiated,<ref type="foot" target="#foot_4">7</ref> as opposed to O(Bpd) in the na?ve approach which goes through instantiating (2).<ref type="foot" target="#foot_5">8</ref> </p><p>The memory efficiency of this procedure is exemplified with off the shelf pretrained language models, most of which have large embedding layers. For instance, for GPT-2, d ? 50, 000 and p = 768 for the embedding layer, and the context window T ? 1024.<ref type="foot" target="#foot_6">9</ref> Our method in theory reduces the memory cost associated with this large embedding layer by at least a factor of 22 compared to when the per-example gradient is na?vely instantiated. Overall, we also observe significant savings, since embedding layers can be a major source of memory spending for training large language models.<ref type="foot" target="#foot_7">10</ref> </p><p>To stress-test ghost clipping, we compare it with 4 baselines: The PyTorch package Opacus that implements DP optimization by instantiating per-example gradients, the approach by <ref type="bibr" target="#b39">Lee &amp; Kifer (2020)</ref>, non-private training in PyTorch, and na?ve DP optimization implemented in JAX with jit and vmap enabled. We include the JAX baseline since a recent study showed that DP optimization can be made cheap through compiler optimization <ref type="bibr" target="#b73">(Subramani et al., 2020)</ref>. Figure <ref type="figure" target="#fig_4">4</ref> (a) shows that for typical inputs, our technique is the most memory friendly and allows fitting batches almost as large as those in non-private training. Since ghost clipping allows us to fit larger batches but with a run-time penalty, a natural question is whether it improves throughput with the use of larger batches. Figure <ref type="figure" target="#fig_4">4</ref> (b) shows that while ghost clipping only provides minor gains compared to Opacus for smaller models, it allows processing 10% more examples compared to the approach by <ref type="bibr" target="#b39">Lee &amp; Kifer (2020)</ref> for fitting GPT-2-large, a model that neither Opacus or JAX could handle. See Appendix G for the setup of these experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">LOW DIMENSIONAL UPDATES ARE NOT NECESSARILY BETTER</head><p>Since the norm of the noise injected into gradients during DP learning scales with dimensionality, it is natural to ask whether updating fewer parameters would result in improved performance. We decompose this question into two aspects: (1) Do smaller pretrained models lead to better private fine-tuned performance, and (2) do parameter-efficient adaptation methods designed with a reduced dimensionality of updates outperform full fine-tuning? Our experiments below show that neither is necessarily true. Reported numbers in this section are averaged over three independent seeds.</p><formula xml:id="formula_4">GPT-2 GPT-2-medium GPT-2-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">LARGER PRETRAINED MODELS RESULT IN BETTER PERFORMANCE</head><p>We observe that larger pretrained models lead to better private fine-tuned performance. Specifically, we fully fine-tune four sizes of GPT-2 models (for language generation) and three sizes of BERT/RoBERTa models (for sentence classification) at the same privacy budget with DP-Adam and compare their performances. Since the performance of DP optimization heavily depends on hyperparameter choices, we need to ensure that our hyperparameters are not particularly favoring larger models. We thus tune hyperparameters on the smallest model for each model type and then reuse the same hyperparameters for all fine-tuning workloads for that model type. Figure <ref type="figure">1</ref> from earlier demonstrates gains from model scaling on E2E and MNLI, and we find similar improvements on 5 additional tasks (deferred to Figure <ref type="figure">5</ref> in Appendix C).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">FULL FINE-TUNING WITH DP-ADAM MATCHES STATE-OF-THE-ART</head><p>There is a range of lightweight fine-tuning methods that reduce the dimensionality of updates, including some that are designed for DP <ref type="bibr">(Yu et al., 2021c)</ref>. Do methods that optimize fewer parameters lead to better results under DP even if they perform similarly non-privately? Empirical results suggest otherwise and that full fine-tuning is a strong baseline that even matches specialized low-dimensional DP learning methods for both classification and generation. Below, we study the two sets of tasks separately. For completeness, all experimental details are in Appendix K.</p><p>Sentence Classification. We study DP fine-tuning on tasks from the GLUE benchmark that have more than Table <ref type="table" target="#tab_1">1</ref> shows that using larger pretrained models and the text-infilling objective generally improve classification accuracy. We compare full fine-tuning with reparameterized gradient perturbation (RGP) <ref type="bibr">(Yu et al., 2021c)</ref>, as it is the state-of-the-art for DP fine-tuning on sentence classification at the time the first version of this paper was uploaded to arXiv. The method is designed to privatize gradients projected onto low dimensional subspaces and was motivated to reduce DP noise in highdimensional models. We note that full fine-tuning with the text infilling objective outperforms well-tuned RGP on all tasks despite being the simplest baseline. <ref type="foot" target="#foot_8">11</ref> Computationally, while RGP is faster per-update, it requires more than 3 times as many epochs as full fine-tuning-overall, the two methods are comparable in terms of wall time.   <ref type="table" target="#tab_3">2</ref> shows that LoRA and full fine-tuning are generally the most performant on E2E. Tables <ref type="table" target="#tab_8">7</ref> and<ref type="table" target="#tab_9">8</ref> in Appendix J contain the full result on E2E and DART and confirm the trend. Chit-Chat Dialog Generation. We stress-test full fine-tuning under DP on the task of chit-chat dialog generation. This task has the distinct challenge that the response space is intrinsically diverse <ref type="bibr" target="#b41">(Li et al., 2015;</ref><ref type="bibr" target="#b21">Gao et al., 2018)</ref> since human conversations can be informal and noisy <ref type="bibr" target="#b89">(Zhang et al., 2019)</ref>. Moreover, dialog datasets are usually formed with user data which may contain sensitive information. We use the Persona-Chat dataset <ref type="bibr" target="#b88">(Zhang et al., 2018)</ref> as a testbed and build off a processed version that has 130k training entries. Each entry contains a dialog history, persona descriptions of the respondent, and the response. We fine-tune GPT-2, GPT2-medium, and DialoGPTmedium on this dataset both privately and non-privately by training to predict the response with the dialog history and persona description. We report the F1 score and perplexity on the validation split, and human evaluated quality scores of generations. Table <ref type="table" target="#tab_4">3</ref> shows that private models have strong performance. In particular, fine-tuned DialoGPT-medium at = 8 beats the (non-private) winning entry of the ConvAI2 challenge <ref type="bibr" target="#b16">(Dinan et al., 2019)</ref> on perplexity and has a human evaluation rating that is close to non-private models. Samples from our private models can be found in Appendix O. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">SCOPE AND LIMITATIONS</head><p>We presented strategies for fine-tuning large pretrained language models under DP for a wide range of NLP tasks. For researchers and practitioners working on private NLP, our empirical results suggest that DP fine-tuning with a proper setup is a competitive baseline that is worth trying before prematurely shifting to less formal notions of privacy which have not stood against the test of time.</p><p>In addition, since DP fine-tuning generally requires substantially less private data (than training with DP from scratch), we hope this will motivate organizations which are already conducting private learning (e.g., federated learning with DP) to reduce the collection and use of private data to benefit privacy in the long run. Below we list limitations and future directions.</p><p>Public Pretraining. Our empirical studies are based on fine-tuning off-the-shelf models such as BERT and GPT-2 that are pretrained on data collected from the internet. Due to the permissive nature of the data collection for some of these models, there can be privacy concerns (e.g., text data scraped expansively from the internet may contain sensitive information such as PIIs <ref type="bibr" target="#b11">(Carlini et al., 2020)</ref>).</p><p>We selected off-the-shelf models as they are widely accessible to ensure our results are reproducible.</p><p>When considering applying DP fine-tuning to real world settings, one should consider and create more curated public corpora for pretraining.</p><p>Hyperparameter Tuning. We studied how choices of basic hyperparameters affect the performance of DP-Adam for fine-tuning. Our study is by no means comprehensive or complete. In particular, we did not study how weight decay, learning rate schedule, clipping norm schedule, or batch size schedule affect private learning. Custom setups for these knobs have been found helpful for other private learning tasks <ref type="bibr" target="#b1">(Anil et al., 2021)</ref>.</p><p>Overall, our studies revealed that hyperparameter values can affect private fine-tuning in significant ways. This calls for more transparency in reporting hyperparameter choices, analyses of hyperparameter transferability across tasks and architectures, and accounting of the privacy loss for hyperparameter tuning when hyperparameters aren't transferred across workloads.</p><p>Pretraining and Its Relation to Private Learning. Our model scaling results (Figure <ref type="figure">1</ref>) suggest that using larger pretrained models improves performance. This argument, however, is dependent on the particular choice of pretrained models. How pretraining helps private learning and whether better pretrained models for private learning could be built are interesting future avenues.</p><p>Scaling Laws for Private Learning. While scaling laws <ref type="bibr" target="#b35">(Kaplan et al., 2020)</ref> for non-private deep learning have become prevalent, we are unaware of a case study in the private learning realm. Studies on how the dimensionality of models (and pretraining) generally affect private deep learning in precise terms will likely be a useful tool in trading off compute budget and model quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ETHICS STATEMENT</head><p>While the present paper studies private NLP, all experiments performed herein are based on public and well-studied datasets.</p><p>To the best of our knowledge, this work is the first to demonstrate that DP NLP can achieve promising levels of performance across a wide range of tasks with limited data. Our experimental results suggest that DP learning has the potential to be used in industry settings to build high performing applications with small private datasets without making big sacrifices in privacy.</p><p>On the other hand, we acknowledge that successful private learning has the potential to motivate companies to more aggressively collect user data, which could result in long-term privacy harms <ref type="bibr" target="#b68">(Rogaway, 2015;</ref><ref type="bibr" target="#b71">Solove, 2005)</ref>. In addition, other societal harms not captured by DP (e.g., representation bias) can arise with more machine learning models being trained on private data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REPRODUCIBILITY</head><p>All experiments in the paper are based on publicly available datasets. Links to these datasets are included in the main text and appendices. Hyperparameters necessary for reproducing our experiments are documented in Appendix I and H. Code to reproduce the headline results can be found at https://github.com/lxuechen/private-transformers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A DP-ADAM</head><p>We use DP-Adam throughout. DP-Adam works just like regular Adam (Kingma &amp; Ba, 2014) but performs updates and moment accumulation with privatized gradients. The gradient privatization part is the same as that performed in DP-SGD <ref type="bibr" target="#b72">(Song et al., 2013;</ref><ref type="bibr" target="#b0">Abadi et al., 2016)</ref>. Seemingly uncommon, DP-Adam is used in many private ML libraries. <ref type="foot" target="#foot_9">12</ref> To determine the noise multiplier, we account privacy through R?nyi differential privacy (RDP) <ref type="bibr" target="#b52">(Mironov, 2017;</ref><ref type="bibr" target="#b53">Mironov et al., 2019)</ref>. For completeness, we include the pseudocode for DP-Adam below.</p><p>Algorithm 1 DP-Adam</p><formula xml:id="formula_5">1: Input: Data D = {x i } N i=1</formula><p>, learning rate ?, noise multiplier ?, batch size B, Euclidean norm threshold for gradients C, epochs E, initial parameter vector ? 0 ? R p , initial moment estimates m 0 , v 0 ? R p , exponential decay rates</p><formula xml:id="formula_6">? 1 , ? 2 ? R, avoid division-by-zero constant ? ? R. 2: for t ? [E ? N /B] do 3:</formula><p>Draw a batch B t via Poisson sampling; each element has probability B /N of being selected 4:</p><formula xml:id="formula_7">for x i ? B t do 5: g t (x i ) ? ? ?t L(x i ), gt (x i ) ? g t (x i ) ? min(1, C / gt(xi) 2 ) 6:</formula><p>end for 7:</p><formula xml:id="formula_8">z t ? N (0, ? 2 C 2 I p ) 8: ?t = 1 B N i=1 gt (x i ) + z t 9: ? t+1 , m t+1 , v t+1 ? AdamUpdate(? t , m t , v t , ?t , ? 1 , ? 2 , ?) 10: end for 11: return ?TN /B Algorithm 2 AdamUpdate 1: Input: ? t , m t , v t , ?t , ? 1 , ? 2 , ? 2: m t+1 ? ? 1 ? m t + (1 -? 1 ) ? ?t , v t+1 ? ? 2 ? v t + (1 -? 2 ) ? ?t 2 3: m t+1 ? m t+1 / (1 -? t 1 ) , v t+1 ? v t+1 / (1 -? t 2 ) 4: ? t+1 ? ? t -? ? m t+1 / v t+1 + ? 5: return ? t+1 , m t+1 , v t+1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B PRIVACY ACCOUNTING</head><p>We train all models under approximate-DP <ref type="bibr" target="#b20">(Dwork et al., 2014)</ref>, and we view two datasets as being adjacent if and only if one can be obtained from the other by including an extra record <ref type="bibr" target="#b53">(Mironov et al., 2019)</ref>. Instead of accounting the privacy loss with Moments Accountant <ref type="bibr" target="#b0">(Abadi et al., 2016)</ref>, we perform computation through (i) R?nyi DP <ref type="bibr" target="#b52">(Mironov, 2017;</ref><ref type="bibr" target="#b53">Mironov et al., 2019)</ref>, (ii) Gaussian DP with an associated central limit theorem <ref type="bibr" target="#b17">(Dong et al., 2019)</ref>, and (iii) numerically composing tradeoff functions via fast Fourier transform <ref type="bibr" target="#b25">(Gopi et al., 2021;</ref><ref type="bibr" target="#b38">Koskela et al., 2020)</ref>. All approaches are improvements over the Moments Accountant. Accounting loss with R?nyi DP provides strict upper bounds on the actual privacy leakage but may result in loose bounds. Accounting loss with Gaussian DP and its central limit theorem, although asymptotically exact, only provides approximations to the actual loss under a finite number of compositions <ref type="bibr">(Dong et al., 2019, Theorem 3.4</ref>). <ref type="bibr" target="#b25">Gopi et al. (2021)</ref> observed that accounting loss with GDP and its CLT results in underestimation and proposed to numerically compose tradeoff functions resulting in both upper and lower bounds on the actual leakage . We therefore also report the converted with the approach by Gopi et al. (2021) using their code. <ref type="foot" target="#foot_10">13</ref>Given the noise multiplier ?, sampling rate q, number of steps S, and failure constant ?, can be computed via first computing the R?nyi DP leakage and then converting it to approximate DP. When a privacy spending (specified by a set of given and ?) is prescribed, we can numerically invert the above procedure to obtain a suitable ? for noisy optimization. This is what we do throughout all experiments. For completeness, given the ? chosen as above, we also report the leakage estimated by going through the central limit theorem in Gaussian DP <ref type="bibr" target="#b7">(Bu et al., 2020)</ref>.</p><p>Model selection from hyperparameter tuning on private training and validation data incurs extra leakage <ref type="bibr" target="#b43">(Liu &amp; Talwar, 2019;</ref><ref type="bibr" target="#b12">Chaudhuri &amp; Vinterbo, 2013;</ref><ref type="bibr" target="#b57">Papernot &amp; Steinke, 2021)</ref>. We perform tuning only on the E2E task and reuse almost the exact hyperparameters for remaining tasks. Note the general strategy of tuning hyperparameters on a separate (public) dataset and thereafter transfer has been applied to train private production language models <ref type="bibr" target="#b67">(Ramaswamy et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C ADDITIONAL RESULTS ON MODEL SCALING</head><p>We repeat the model scaling experiments from Figure <ref type="figure">1</ref> on the other tasks considered in the paper.</p><p>Figure <ref type="figure">5</ref> shows that the trend that larger and better pretrained models lead to improved private finetuned performance holds consistently across all tasks. TextHide numbers based on the TextHide intra formulation <ref type="bibr">(Huang et al., 2020a)</ref>. (e) DART Figure <ref type="figure">5</ref>: Larger and better pretrained models consistently lead to better private fine-tuned performance on sentence classification and language generation tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D WHEN AND WHY DOES LINEAR SCALING FAIL?</head><p>Recall <ref type="bibr" target="#b76">Tram?r &amp; Boneh (2020)</ref> suggested that the following simple rule approximately holds in private learning: Scaling the learning rate together with the batch size by the same constant yields models with almost the same performance. Note that their experiments on MNIST, Fashion-MNIST, and CIFAR-10 used only batch sizes in {512, 1024, 2048, 4096}. These values are fairly large from a non-private learning perspective. Indeed, our experiments on E2E suggest that this rule does not generalize to batch sizes that are too small (sampling rates q = B /N &lt; 2 -8 ).</p><p>We provide an explanation by noting that a core assumption which the linear scaling rule depends on fails to hold for small batch sizes. This assumption is that given a privacy budget, a "square-root" relationship holds between the noise multiplier and the sampling rate (see also <ref type="bibr" target="#b76">(Tram?r &amp; Boneh, 2020</ref>, Claim D.1)). For instance, <ref type="bibr" target="#b76">Tram?r &amp; Boneh (2020)</ref> showed that ? ? c ? q when q ? [2 -7 , 1]</p><p>for some constant c. Our numerical estimates show that this relationship fails to hold for small q -it underestimates the true noise multiplier ? that would be obtained with numerical computation.</p><p>Figure <ref type="figure" target="#fig_7">6</ref> provides an illustration for ( , ?) = (3, 10 -5 ) when the sample size N = 50k and number of training epochs E = 50. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E HOW DOES THE CHOICE OF LABEL WORDS AFFECT SENTENCE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CLASSIFICATION</head><p>Recall in Section 3.2 we cast sentence classification as filling in the missing word among K candidates for a K-way classification problem. Since a label word could be mapped to multiple possible words, we study how the choice of label words affect performance. We again use the sentiment classification task SST-2 as a testbed. Figure <ref type="figure" target="#fig_8">7</ref> shows the effect of varying the label word, where we measure the alignment between the label word and the downstream task by the zero-shot performance of the infilling task (x-axis). We find that increasing the task alignment of the label words alone improves performance by 1 -2% (orange curve), which is in contrast to the non-private setting, where choice of label words do not affect performance in statistically significant ways (blue curve). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F DERIVATION OF THE FROBENIUS NORM IDENTITY</head><p>Recall a ? R B?T ?d is the input to a linear layer with weight matrix W ? R p?d , and g ? R B?T ?p is the gradient of the loss w.r.t. the output. The identity follows from trivial algebra: = vec(a i a i ) vec(g i g i ).</p><formula xml:id="formula_9">? W L i 2 F = g i a i 2 F = T k=1 g i,k a i,k<label>2</label></formula><p>Note that when T = 1, the identity takes the form of</p><formula xml:id="formula_10">? W L i 2 F = vec(a i a i ) vec(g i g i ) = a i 2 2 g i 2 2 .</formula><p>This is exactly what is used in the <ref type="bibr" target="#b24">Goodfellow (2015)</ref> trick.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G PROTOCOL FOR EXPERIMENTS IN SECTION 4.2</head><p>For these experiments, we used mock examples with the same format as examples in the E2E dataset. We created mock input sequences of length 100, as this length is almost the maximum length of examples in the actual E2E training set.</p><p>Our JAX implementation is adapted from a codebase used in the work by <ref type="bibr" target="#b73">Subramani et al. (2020)</ref> and utilizes the package flaxmodels for loading pretrained models. <ref type="foot" target="#foot_11">14</ref> The Opacus <ref type="bibr" target="#b82">(Yousefpour et al., 2021)</ref> baseline is based on version 0.14.0 of the library, where for a fair comparison, we also optimized the implementation of the privacy engine by replacing all einsum operations with basic primitives that manipulate tensors directly. We found certain einsum steps to cause large and unnecessary speed and memory overheads.</p><p>To identify the maximum batch size that each approach could use, we ran binary search over the range of possible batch sizes until the upper bound matched the lower bound and that OOM did not occur.</p><p>To estimate the throughput of each private method, we compared them to non-private training first. Specifically, for a pairwise comparison, we took the maximum batch size for non-private training and some private method, and computed the least common multiple as a batch size to perform updates with. Using the least common multiple batch size ensures that both methods will process exactly the same number of examples and perform the same number of updates. By estimating the time elapse of these methods for performing a fixed number of updates, we obtained throughputs for non-private training and the private method. This gives us the relative throughput of the private method with non-private training as the reference.</p><p>For methods implemented in PyTorch, the time elapse was recorded with torch.profiler.</p><p>When estimating the time elapse for a training procedure, we first performed 3 gradients updates as a warm up process before taking the actual steps which will be timed. In particular, this eliminates the time that JAX uses for compiling computation graphs with vmap and jit.</p><p>All experimental runs in the section were under full precision.</p><p>H DETAILS AND ADDITIONAL RESULTS FOR STUDIES IN SECTION 3.1   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I HYPERPARAMETER SEARCH RANGES FOR EXPERIMENTS IN SECTION 5</head><p>We compare different adaptation methods by reporting task specific metrics on the test split using hyperparameters that maximize validation BLEU on E2E. For sentence classification tasks, we reused the same hyperparameters, except for the number of training epochs and batch size. For SST-2, we reused the same batch size as for private E2E fine-tuning, and the number of epochs exactly as in typical non-private fine-tuning for SST-2 (number of epochs equals to 3 in this case). For remaining classification tasks, we use a batch size such that the sampling rate is the same as for SST-2, and a number of training epochs that is roughly proportional to the dataset size. Appendix L outlines why we transfer the sampling rate as opposed to the batch size. We list the range of hyperparameters that we searched over for each individual adaptation method on E2E considered in the paper. Prefix-tuning has two additional hyperparameters: the length of the prefix and the dimensionality of the hidden layer. We set these to the default used by <ref type="bibr" target="#b42">Li &amp; Liang (2021)</ref> (10 for the former and 512 for the latter).</p><p>For Adam, we use the default hyperparamaters set by PyTorch <ref type="bibr" target="#b61">(Paszke et al., 2017)</ref>. </p><formula xml:id="formula_11">(3, 1 /2|D train |) (3, 1 /2|D train |) (3, 1 /2|D train |) (3, 1 /2|D train |) Clipping norm C 0.1 0.1 0.1 0.1 Batch size B {512, 1024} {512, 1024} {512, 1024}<label>{512</label></formula><p>, 1024} Learning rate ? {200, 100, 30, 10, 3} ? 10 -5 {200, 100, 30, 10, 3} ? 10 -5 {200, 100, 30, 10, 3} ? 10 -5 {200, 100, 30, 10, 3}  <ref type="table" target="#tab_1">1</ref> are taken from documented numbers in their released codebase. <ref type="foot" target="#foot_12">15</ref> These results are under the DP guarantees of ( , ?) = (3, 10 -5 ) or ( , ?) = (8, 10 -5 ). These guarantees are strictly looser than our guarantees which are based on ? = 1 /2|Dtrain| (recall the smallest dataset in this cohort of tasks has 60k+ records). The RGP numbers in Table <ref type="table" target="#tab_1">1</ref> are higher than those reported in their paper <ref type="bibr">(Yu et al., 2021c)</ref>, since the latter numbers are not based on fine-tuning the official RoBERTa models.</p><p>Table -To-Text Generation. To evaluate models trained on E2E and DART, we evaluate generations from models obtained with beam search with a beam size of 5. For evaluation, we run the official pipeline for E2E, <ref type="foot" target="#foot_13">16</ref> and the pipeline used in the GEM benchmark <ref type="bibr" target="#b23">(Gehrmann et al., 2021)</ref> for DART.<ref type="foot" target="#foot_14">17</ref> </p><p>Chit-Chat Dialog Generation. We built off Huggingface's codebase of the winning entry of the ConvAI2 competition,<ref type="foot" target="#foot_15">18</ref> <ref type="foot" target="#foot_16">19</ref> and used their preprocessed training set with the minor modification of truncating the number of training examples to be a multiple of the batch size. The original ConvAI2 competition is aimed at advancing research on building engaging chatbots and also requested models to predict the mostly likely response given a list of candidates. The challenge included hits@1 as part of its suite of automatic metrics. For simplicity, we skip this step of predicting the most likely response for both training and evaluation. Results for the entry HuggingFace (ConvAI2 winner) in Table <ref type="table" target="#tab_4">3</ref> are taken from the official validation set leader board. <ref type="foot" target="#foot_17">20</ref> Our reimplementation of HuggingFace's submission uses the released code for their winning entry, fine-tunes GPT with the default hyperparameters, and removes the classification loss for learning to predict the most likely response given candidates.</p><p>We additionally fine-tuned DialoGPT-medium <ref type="bibr" target="#b89">(Zhang et al., 2019)</ref>, since the model was pretrained on conversation-like exchanges extracted from Reddit comment chains. Intuitively, this pretraining corpus is more aligned with the downstream fine-tuning data than WebText <ref type="bibr" target="#b66">(Radford et al., 2019)</ref>, and thus would likely improve downstream performance.</p><p>To evaluate the F1 score, we obtained predicted responses from trained models using beam search with a beam size of 5. Since past work found that the F1 score can be gamed by always letting the model predict a predetermined phrase <ref type="bibr" target="#b16">(Dinan et al., 2019)</ref>, we additionally ask humans to rate generations from the model through Amazon mechanical turk to obtain a more complete picture of model quality. When sampling responses for human evaluation, we used nucleus sampling with p = 0.9 <ref type="bibr" target="#b27">(Holtzman et al., 2019)</ref>. For human evaluation, we asked 20 turkers to each rate 5 entries. For each entry, a turker is asked to rate on a scale of 1 to 5 the quality of predicted responses from privately fine-tuned DialoGPT-medium models, non-privately fine-tuned DialoGPT-medium models, non-privately fine-tuned GPT models (our reimplementation of HuggingFace's entry), and the reference text, given the history of the dialog. Since human evaluation can yield noisy results, we also report the 95% asymptotic confidence interval in Table <ref type="table" target="#tab_4">3</ref>. All models were trained and evaluated on the version of Persona-Chat with the original persona. All numbers reported in Table <ref type="table" target="#tab_4">3</ref> are obtained on the validation split.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L TRANSFERRING HYPERPARAMETERS ACROSS DATASETS</head><p>Our work involved tuning hyperparameter with models trained via DP-Adam on one private dataset and transferring such hyperparameters to other private datasets. Since different datasets may be of different sizes, transferring the batch size may cause a discrepancy in the effective noise multiplier across workloads with different datasets. Transferring the batch size based on hyperparameter tuning on small datasets to larger datasets can be particularly problematic, as the effective noise multiplier can be larger than ideal. In this work, we instead transferred the sampling rate q across different datasets.</p><p>M DOES DP FINE-TUNING PREVENT UNINTENDED MEMORIZATION?</p><p>One of the ultimate goals of fitting models under DP is to ensure that training data extraction is unlikely given the trained model. To empirically evaluate whether DP fine-tuning helps prevent against unintended memorization and related attacks, we follow the secret sharer framework <ref type="bibr" target="#b10">(Carlini et al., 2019)</ref> and estimate the exposure of artificial canaries inserted into the training set used for fine-tuning. We use the E2E dataset as a testbed.</p><p>To create canaries, we first form a subvocabulary by randomly sampling V = 10 words in the original vocabulary of GPT-2. Our canaries have prefixes of the form " name : &lt;word&gt; | Type : &lt;word&gt; | area : &lt;word&gt; ", where &lt;word&gt; is randomly sampled from the subvocabulary. The suffix which our model should learn to predict consists of randomly sampled words with an average length of l = 5. By definition, canaries with an estimated exposure close to log 2 (V l ) ? 17 can likely be extracted. We experiment with canary-corrupted datasets for repetition values r ? {1, 10, 100}. A canary has a higher chance in being extracted when it's repeated for more than once in the training data. Recall that fine-tuning for classification can be reformulated as filling in the [MASK] token in a template sequence. Here, we list the templates used for each classification task considered in the paper. These templates are almost generic and are not obtained from expensive manual or automated search. We anticipate better templates obtained from automated search based on data <ref type="bibr" target="#b22">(Gao et al., 2020)</ref> to improve the performance even further. However, we also expect that such a procedure would lead to some amount of increased privacy spending if it were based on private data.   <ref type="bibr" target="#b22">Gao et al. (2020)</ref>. The Punter is a cheap Indian restaurant near Express by Holiday Inn in the riverside area. It is not family -friendly. GPT-2 ( = 8)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>O UNCURATED SAMPLES FROM FINE-TUNED MODELS</head><p>The Punter is a cheap Indian restaurant near Express by Holiday Inn in the riverside area. It is not family -friendly. GPT-2-m ( = 3) The Punter is a cheap Indian restaurant located in the riverside area near Express by Holiday Inn. It has an average customer rating and is not family -friendly. GPT-2-m ( = 8) The Punter is a restaurant providing Indian food in the cheap price range. It is located in the riverside area near Express by Holiday Inn. Its customer rating is average. GPT-2-l ( = 3) The Punter is a cheap Indian restaurant in the riverside area near Express by Holiday Inn.</p><p>It is not family -friendly and has an average customer rating. GPT-2-l ( = 8) The Punter is a restaurant providing Indian food in the cheap price range. It is located in the riverside area near Express by Holiday Inn. Its customer rating is average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>The restaurant named The Punter has cheap Indian food and an average customer rating .</p><p>It is near the Express by Holiday Inn on the riverside and is not family friendly .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table name :</head><p>The Mill -Type : restaurant -food : English -price : moderate -customer rating : 3 out of 5 -area : city centre -family friendly : yes -near : Caf? Rouge GPT-2 ( = 3)</p><p>The Mill is a moderately priced restaurant located in the city centre near Caf? Rouge. GPT-2 ( = 8)</p><p>The Mill is a moderately priced restaurant located in the city centre near Caf? Rouge. GPT-2-m ( = 3) The Mill is an English restaurant located in the city centre near Caf? Rouge. It is moderately priced and has a customer rating of 3 out of 5. GPT-2-m ( = 8) The Mill is a moderately priced restaurant located in the city centre near Caf? Rouge. It is child friendly and has a customer rating of 3 out of 5. GPT-2-l ( = 3) The Mill is a moderately priced English restaurant in the city centre near Caf? Rouge. It is child friendly and has a customer rating of 3 out of 5. GPT-2-l ( = 8) The Mill is a kid friendly English restaurant in the city centre near Caf? Rouge. It has a moderate price range and a customer rating of 3 out of 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>Serving moderately priced English food with a 3 out of 5 customer approval , The Mill restaurant is kid friendly and conveniently located at the city centre near the Caf? Rouge .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table name :</head><p>The Vaults -Type : pub -food : Japanese -price : high -customer rating : 3 out of 5 -area : city centre -family friendly : yes -near : Raja Indian Cuisine GPT-2 ( = 3) Located near Raja Indian Cuisine in the city centre, The Vaults is a family -friendly Japanese pub with a high customer rating. GPT-2 ( = 8)</p><p>The Vaults is a Japanese pub in the city centre near Raja Indian Cuisine. It has a high price range and a customer rating of 3 out of 5. GPT-2-m ( = 3) The Vaults is a Japanese pub located in the city centre near Raja Indian Cuisine. It has a high price range and a customer rating of 3 out of 5. GPT-2-m ( = 8) The Vaults is a Japanese pub located in the city centre near Raja Indian Cuisine. It has a high price range and a customer rating of 3 out of 5. GPT-2-l ( = 3) The Vaults is a Japanese pub in the city centre near Raja Indian Cuisine. It has a high price range and a customer rating of 3 out of 5. GPT-2-l ( = 8) The Vaults is a child friendly Japanese pub in the city centre near Raja Indian Cuisine. It has a high price range and a customer rating of 3 out of 5. Reference Located near the Raja Indian Cuisine at the city centre , is family -friendly pub The Vaults . Serving Japanese food , The Vaults , is high priced with a 3 out of 5 customer satisfaction rating .   The capital of the United States is Washington, D.C. and is part of Benton County, Oregon. GPT-2-m ( = 3) Albany, Oregon is part of Benton County, Oregon in the United States where Asian Americans are an ethnic group. GPT-2-m ( = 8) Albany, Oregon is part of Benton County, Oregon in the United States where Asian Americans are an ethnic group. GPT-2-l ( = 3) Albany, Oregon is part of the United States where Asian Americans are an ethnic group and the capital is Washington D.C. GPT-2-l ( = 8) Albany, Oregon is part of the United States where Asian Americans are an ethnic group and the capital is Washington D.C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>The Asian Americans are an ethnic group in the United States, which has the capital city of Washington DC. It is also the location of Albany, part of Benton County in Oregon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table</head><p>A Loyal Character Dancer : language : English language -English language : spoken in : Great Britain -A Loyal Character Dancer : country : United States -United States : ethnic group : Native Americans in the United States GPT-2 ( = 3)</p><p>A Loyal Character Dancer is an English language spoken in the United States where Native Americans are the ethnic group. GPT-2 ( = 8)</p><p>A Loyal Character Dancer is written in English and is spoken in Great Britain. Native Americans are an ethnic group in the United States. GPT-2-m ( = 3) A Loyal Character Dancer is written in English and is written in the United States where Native Americans are an ethnic group. GPT-2-m ( = 8) A Loyal Character Dancer is written in English and is written in the United States where Native Americans are an ethnic group. GPT-2-l ( = 3) A Loyal Character Dancer is written in English and is written in the United States where Native Americans are an ethnic group. GPT-2-l ( = 8) A Loyal Character Dancer is written in English, which is spoken in Great Britain and the United States. Native Americans are an ethnic group in the United States. Reference A Loyal Character Dancer is written in English which is spoken in Great Britain. The book is published in the United States where the Native Americans are an ethnic group.   <ref type="formula">2016</ref>) consider transferring features learned on public datasets to simplify the subsequent private learning task. On the other hand, <ref type="bibr" target="#b90">Zhou et al. (2020)</ref>; <ref type="bibr" target="#b33">Kairouz et al. (2020)</ref> remove the ambient dimension dependence of DP noise by identifying subspaces in which private gradients lie and would be privatized. <ref type="bibr">Yu et al. (2021b;</ref><ref type="bibr">c</ref>) make such ideas practical and demonstrate improved results on private learning benchmarks. <ref type="bibr" target="#b87">Zhang et al. (2021)</ref> applied the sparse vector technique to learning wide neural layers to reduce the amount of injected noise. Our work mostly falls under the first campimproving private learning through simplifying the learning task. Our work is also distinct from prior works in that we focus on privately fine-tuning large pretrained models. Lastly, there are alternative solutions in the literature that enforces DP which are not based on gradient perturbation <ref type="bibr" target="#b59">(Papernot et al., 2018;</ref><ref type="bibr">2016)</ref>. These methods typically require extra public data and are not the present focus.</p><p>Parameter-Efficient Fine-Tuning. Recent developments on pretrained model adaptation have produced a wide range of parameter-efficient fine-tuning methods for both vision and language tasks. We briefly summarize these, grouping by category. Approaches based on optimizing prompt-like constructions for NLP tasks include prefix-tuning <ref type="bibr" target="#b42">(Li &amp; Liang, 2021)</ref>, P-tuning <ref type="bibr" target="#b44">(Liu et al., 2021)</ref>, and prompt-tuning <ref type="bibr" target="#b40">(Lester et al., 2021)</ref>. Adapter-based methods insert small subnetworks inside pretrained Transformers <ref type="bibr" target="#b29">(Houlsby et al., 2019;</ref><ref type="bibr" target="#b69">R?ckl? et al., 2020;</ref><ref type="bibr" target="#b63">Pfeiffer et al., 2020)</ref>. Methods that optimize low-rank matrices include the work by <ref type="bibr" target="#b30">Hu et al. (2021);</ref><ref type="bibr" target="#b46">Mahabadi et al. (2021)</ref>. In addition, there are adaptation methods that only optimize biases for vision <ref type="bibr" target="#b9">(Cai et al., 2020)</ref> and language tasks <ref type="bibr" target="#b4">(Ben Zaken et al., 2021)</ref>. Our evaluation in Section 5.2 covered the most representative methods that generally have state-of-the-art non-private learning performance (at the time of writing) for the range of NLP tasks studied in this paper.</p><p>Speeding Up DP-SGD. Apart from the work by <ref type="bibr" target="#b39">Lee &amp; Kifer (2020)</ref> and <ref type="bibr" target="#b73">Subramani et al. (2020)</ref>, there is an approach that approximates per-example gradient norms through the combination of random projection and forward-mode autodiff <ref type="bibr" target="#b8">(Bu et al., 2021)</ref>. While faster than vanilla private learning, this approach has the drawback of increased privacy spending and having an extra hyperparameter.</p><p>Our ghost clipping technique, while only suited for Transformers applied to sequential data, does not introduce new hyperparameters.</p><p>Alternative Clipping Strategies. While there are alternative clipping strategies in the literature that show improvements on simple tasks <ref type="bibr" target="#b64">(Pichapati et al., 2019;</ref><ref type="bibr" target="#b2">Asi et al., 2021)</ref>, we have opted to study the simplest strategy that clips gradients by their Euclidean norm. We leave the study of these algorithms for NLP tasks to future work.</p><p>Concurrent Work. We are made aware of a concurrent work that also studies fine-tuning large language models under DP <ref type="bibr">(Yu et al., 2021a)</ref>. This work presents initial successes on fine-tuning under DP with low-rank methods such as LoRA. Our experiments on language generation (see Section 5.2 and Table <ref type="table" target="#tab_3">2</ref>) demonstrate similar findings. Yet, we moreover show that full fine-tuning with good hyperparameters attains similar performance and possesses similar model scaling properties, which was raise by <ref type="bibr">Yu et al. (2021a)</ref> as interesting open questions to pursue. Lastly, our private fine-tuning results for sentence classification may be far from optimal, since we used hyperparameters mostly transferred from tuning on the E2E language generation task.</p><p>DP Synthetic Data Generation. Fine-tuning generative language models on private data under DP can also be viewed as a means of accomplishing DP synthetic data generation -learning generative models from private data so that synthetic examples could be sampled and used for analysis. Previous work employed generative adversarial networks and focused primarily on image or tabular datasets <ref type="bibr" target="#b75">(Torkzadehmahani et al., 2019;</ref><ref type="bibr" target="#b55">Neunhoeffer et al., 2020;</ref><ref type="bibr" target="#b13">Chen et al., 2020;</ref><ref type="bibr" target="#b74">Torfi et al., 2020)</ref>. Perhaps more related is the work by <ref type="bibr" target="#b5">Bommasani et al. (2019)</ref> which attempted fine-tuning GPT-2 on medical datasets to generate synthetic records but did not report any quantitative results.</p><p>factor K is considered during clipping and noising. This procedure, while having the same DP guarantee, typically does not result in similar results as full precision when the same hyperparameters are used across the two settings (even with an optimizer like Adam which self-adjusts the magnitude of updates with accumulated empirical second moments). We also identified that this implementation is also the primary reason that a prior work's code does not produce good results with full fine-tuning using our near-optimal hyperparameters.<ref type="foot" target="#foot_18">21</ref> </p><p>U FINE-TUNING WITH RGP AND THE TEXT-INFILLING OBJECTIVE Recall Section 3.2 and Table <ref type="table" target="#tab_1">1</ref> showed that private full fine-tuning with a text-infilling objective leads to improved classification results. Here, we show that the infilling objective is also helpful when one privately fine-tunes with the RGP method for a classification task. To study this, we reimplemented the RGP method and tuned the hyperparameters in full precision. Fixing all hyperparameters, we compared models trained with and without infilling. Table <ref type="table" target="#tab_19">14</ref> confirms that fine-tuning with RGP based on infilling is generally helpful across the considered tasks. Note the aim of this experiment is not obtain state-of-the-art performance, but rather to study the effect of using the text-infilling objective. Thus, we expect these results could generally be further improved with more extensive hyperparameter search. While we were able to obtain similar results on the E2E and DART datasets with full fine-tuning and LoRA (Tables <ref type="table" target="#tab_1">1</ref> and<ref type="table" target="#tab_9">8</ref>), we encountered significant difficulties in fine-tuning for dialog generation (even non-privately) when not updating the embedding layer and language modeling head -perplexity was much worse, and generations frequently contained seemingly arbitrary characters. This result suggests that while full fine-tuning may be more computationally intensive than lightweight approaches at times, its simplicity (involving few design decisions) makes it an attractive first option when compute resource is sufficient.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: Large batches and learning rates lead to good performance when the number of epochs is fixed. Red lines divide heat map into four panels. Top and bottom correspond to low and high learning rate regimes; left and right correspond to small and large batch regimes. Numbers are BLEU scores on the test split of E2E; higher is better.</figDesc><graphic url="image-1.png" coords="4,358.68,278.87,101.07,101.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: Left: Ghost clipping is 3 times more memory efficient than Opacus and is almost as efficient as non-private training for typical sequences across model sizes. For GPT-2-large, we were unable to fit single-example micro batches together with gradient accumulation with Opacus or JAX on a TITAN RTX GPU (24 GBs of VRAM). Right: DP optimization with ghost clipping processes 10% more examples than the approach by<ref type="bibr" target="#b39">Lee &amp; Kifer (2020)</ref> under unit time for GPT-2-large.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>10k training examples (MNLI, QQP, QNLI, and SST-2), following the experimental setup of Yu et al. (2021c). The associated datasets have modest sizes: SST-2 and QNLI have 60k+ and 100k+ training examples, respectively. MNLI and QQP each contains less than 400k examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure6: "Square-root" relationship underestimates the noise multiplier for small batch sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure7: Better text labels help private learning more than non-private learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>k1,r g i,k1,s a i,k2,r g i,k2,s k1,r a i,k2,r p s=1 g i,k1,s g i,k2,s</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Additional results on hyperparameter sensitivity.</figDesc><graphic url="image-3.png" coords="21,118.48,310.17,182.48,197.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Full fine-tuning larger pretrained models with text infilling has best performance. Results are dev set accuracies. Best numbers based on two-sample test for each privacy level are in bold.</figDesc><table><row><cell></cell><cell></cell><cell>= 3</cell><cell></cell><cell></cell><cell></cell><cell>= 8</cell></row><row><cell>Method</cell><cell cols="6">MNLI-(m/mm) QQP QNLI SST-2 MNLI-(m/mm) QQP QNLI SST-2</cell></row><row><cell>RGP (RoBERTa-base)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>80.5/79.6</cell><cell>85.5 87.2 91.6</cell></row><row><cell>RGP (RoBERTa-large)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>86.1/86.0</cell><cell>86.7 90.0 93.0</cell></row><row><cell>full (RoBERTa-base)</cell><cell cols="6">82.47/82.10 85.41 84.62 86.12 83.30/83.13 86.15 84.81 85.89</cell></row><row><cell>full (RoBERTa-large)</cell><cell cols="6">85.53/85.81 86.65 88.94 90.71 86.28/86.54 87.49 89.42 90.94</cell></row><row><cell cols="7">full + infilling (RoBERTa-base) 82.45/82.99 85.56 87.42 91.86 83.20/83.46 86.08 87.94 92.09</cell></row><row><cell cols="7">full + infilling (RoBERTa-large) 86.43/86.46 86.43 90.76 93.04 87.02/87.26 87.47 91.10 93.81</cell></row><row><cell>? (Gaussian DP + CLT)</cell><cell>2.52</cell><cell cols="3">2.52 2.00 1.73</cell><cell>5.83</cell><cell>5.85 4.75 4.33</cell></row><row><cell>? (Compose tradeoff func.)</cell><cell>2.75</cell><cell cols="3">2.75 2.57 2.41</cell><cell>7.15</cell><cell>7.16 6.87 6.69</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table -</head><label>-</label><figDesc></figDesc><table /><note><p><p><p><p><p><p><p><p><p>To-Text Generation. We study different fine-tuning methods under DP for table-to-text generation where the goal is to generate natural language descriptions of table entries. We consider the datasets E2E</p><ref type="bibr" target="#b56">(Novikova et al., 2017)</ref> </p>and DART</p><ref type="bibr" target="#b54">(Nan et al., 2020)</ref></p>. E2E consists of simple restaurant reviews, whereas DART consists of open-domain table entries from Wikipedia and is more complex. Both datasets are small: E2E has more than 40k training examples, whereas DART has more than 60k. Since we are the first to experiment with this task under DP, we compare full fine-tuning (full) against a suite of parameter-efficient approaches which includes LoRA</p><ref type="bibr" target="#b30">(Hu et al., 2021)</ref></p>, prefix-tuning</p><ref type="bibr" target="#b42">(Li &amp; Liang, 2021)</ref> </p>(prefix), RGP, and fine-tuning the top 2 Transformer blocks (top2), all of which optimize few parameters. On GPT-2 (125 million parameters), prefix-tuning with default hyperparameters optimizes 10 million parameters; LoRA with rank 4 optimizes 0.15 million parameters. We also report results for training from scratch (retrain). Hyperparameters of each method were tuned only the E2E dataset; the complete search ranges are in Appendix I. Table</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Full fine-tuning performs on par with or outperforms others methods that execute gradient update in low dimensional spaces. Results are on E2E from fine-tuning GPT-2.</figDesc><table><row><cell>Metric</cell><cell cols="4">DP Guarantee Gaussian DP Compose + CLT tradeoff func. full</cell><cell>Method LoRA prefix RGP top2 retrain</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.68</cell><cell>? 2.75</cell><cell cols="2">61.519 58.153 47.772 58.482 25.920 15.457</cell></row><row><cell>BLEU</cell><cell>= 8 non-private</cell><cell>? 6.77 -</cell><cell>? 7.27 -</cell><cell cols="2">63.189 63.389 49.263 58.455 26.885 24.247 69.463 69.682 68.845 68.328 65.752 65.731</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.68</cell><cell>? 2.75</cell><cell cols="2">65.670 65.773 58.964 65.560 44.536 35.240</cell></row><row><cell>ROUGE-L</cell><cell>= 8 non-private</cell><cell>? 6.77 -</cell><cell>? 7.27 -</cell><cell cols="2">66.429 67.525 60.730 65.030 46.421 39.951 71.359 71.709 70.805 68.844 68.704 68.751</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Fine-tuning with DP-Adam yields high quality chit-chat dialog generation models.<ref type="bibr" target="#b6">Bommasani et al. (2021)</ref> briefly commented on the possibility of achieving cheaper private learning by fine-tuning large pretrained language models.<ref type="bibr" target="#b1">Anil et al. (2021)</ref> pretrained BERT under global DP on datasets with hundreds of millions of examples.<ref type="bibr" target="#b18">Dupuy et al. (2021)</ref> studied private BERT fine-tuning on datasets of utterances, but reported results with on the order of at least 100. Orthogonally, many works considered training language models that satisfy empirical notions of privacy<ref type="bibr" target="#b81">(Xu et al., 2021;</ref><ref type="bibr" target="#b14">Coavoux et al., 2018;</ref><ref type="bibr" target="#b51">Mireshghallah et al., 2021;</ref><ref type="bibr" target="#b49">Melamud &amp; Shivade, 2019)</ref>. Our work is distinct from all works mentioned above in that we study fine-tuning large language models (with hundreds of millions of parameters) under global DP with stringent guarantees ( ? {3, 8}) on smaller datasets (much less than a million examples).</figDesc><table><row><cell>Model</cell><cell cols="6">Metrics tradeoff func. F1 ? Perplexity ? Quality (human) ? DP Guarantee Gaussian DP Compose +CLT</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.54</cell><cell cols="3">? 2.73 15.90 24.59</cell><cell>-</cell></row><row><cell>GPT-2</cell><cell>= 8 non-private</cell><cell>? 6.00 -</cell><cell cols="3">? 7.13 16.08 23.57 -17.96 18.52</cell><cell>--</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.54</cell><cell cols="3">? 2.73 15.99 20.68</cell><cell>-</cell></row><row><cell>GPT-2-medium</cell><cell>= 8 non-private</cell><cell>? 6.00 -</cell><cell cols="3">? 7.13 16.53 19.25 -18.64 15.40</cell><cell>--</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.54</cell><cell cols="4">? 2.73 17.37 17.64 2.82 (2.56, 3.09)</cell></row><row><cell>DialoGPT-medium</cell><cell>= 8 non-private</cell><cell>? 6.00 -</cell><cell cols="4">? 7.13 17.56 16.79 3.09 (2.83, 3.35) -19.28 14.28 3.26 (3.00, 3.51)</cell></row><row><cell>HuggingFace (ConvAI2 winner)</cell><cell>non-private</cell><cell>-</cell><cell>-</cell><cell cols="2">19.09 17.51</cell><cell>-</cell></row><row><cell cols="2">HuggingFace (our implementation) non-private</cell><cell>-</cell><cell>-</cell><cell cols="3">16.36 20.55 3.23 (2.98, 3.49)</cell></row><row><cell>Reference</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>3.74 (3.49, 4.00)</cell></row><row><cell>6 RELATED WORK</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p><p><p><p><p><p><p><p>Private NLP. The privacy-preserving NLP space is largely divided by whether or not DP (or its extensions) is considered.</p><ref type="bibr" target="#b48">McMahan et al. (2017)</ref> </p>successfully trained small word-level RNNs with 1.35 million parameters in a federated setting with more than 700k users under a global DP guarantee with ( , ?) = (4.6, 10 -9 ).</p><ref type="bibr" target="#b67">Ramaswamy et al. (2020)</ref> </p>train production grade next-word prediction models using DP-FedAvg with millions of users.</p><ref type="bibr" target="#b65">Qu et al. (2021)</ref> </p>studied fine-tuning BERT for language understanding tasks under local DP.</p><ref type="bibr" target="#b36">Kerrigan et al. (2020)</ref> </p>presented initial results that public pretraining is helpful for downstream DP fine-tuning. However, they did not attempt fine-tuning large pretrained models with DP-SGD.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Default hyperparameters for ablation studies.</figDesc><table><row><cell>Method</cell></row></table><note><p>calculated numerically so that a DP budget of ( , ?) is spent after E epochs (a) Batch size. 60.26 59.58 60.01 57.87 35.44 50.48 50.31 50.48 49.25 34.47 33.17 33.18 33.13 32.96 29.50 29.74 29.55 29.61 29.62 27.07 9.69 9.69 9.68 9.65 5.79</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Hyperparameter search range for different methods.</figDesc><table><row><cell>Method</cell><cell>Full</cell><cell>Prefix</cell><cell>Linear</cell><cell>FT2</cell></row><row><cell>Guarantee ( , ?)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Hyperparameter search range for different methods (continued).</figDesc><table><row><cell>? 10 -5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Full results on E2E from fine-tuning GPT-2.</figDesc><table><row><cell cols="4">Metrics tradeoff func. BLEU NIST METEOR ROUGE-L CIDEr Method DP Guarantee Gaussian DP Compose +CLT</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.33</cell><cell>? 2.67 61.519 6.697 0.384 65.670 1.761</cell></row><row><cell>full</cell><cell>= 8 non-private</cell><cell>? 5.51 -</cell><cell>? 6.98 63.189 7.444 0.400 66.429 1.919 -69.463 8.780 0.461 71.359 2.422</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.68</cell><cell>? 2.75 58.153 5.463 0.370 65.773 1.581</cell></row><row><cell>LoRA</cell><cell>= 8 non-private</cell><cell>? 6.77 -</cell><cell>? 7.28 63.389 7.449 0.407 67.525 1.948 -69.682 8.822 0.463 71.709 2.491</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.33</cell><cell>? 2.67 47.772 5.775 0.331 58.964 1.300</cell></row><row><cell>prefix</cell><cell>= 8 non-private</cell><cell>? 5.51 -</cell><cell>? 6.98 49.263 6.276 0.349 60.730 1.496 -68.845 8.722 0.456 70.805 2.418</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.18</cell><cell>? 2.59 58.482 5.249 0.363 65.560 1.507</cell></row><row><cell>RGP</cell><cell>= 8 non-private</cell><cell>? 5.19 -</cell><cell>? 6.89 58.455 5.525 0.364 65.030 1.569 -68.328 8.722 0.445 68.844 2.345</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.68</cell><cell>? 2.75 25.920 1.510 0.197 44.536 0.452</cell></row><row><cell>top2</cell><cell>= 8 non-private</cell><cell>? 6.77 -</cell><cell>? 7.28 26.885 1.547 0.207 46.421 0.499 -65.752 8.418 0.443 68.704 2.180</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.33</cell><cell>? 2.67 15.457 0.376 0.113 35.240 0.116</cell></row><row><cell>retrain</cell><cell>= 8 non-private</cell><cell>? 5.51 -</cell><cell>? 6.98 24.247 1.010 0.145 39.951 0.281 -65.731 8.286 0.429 68.751 2.004</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>Full results on DART from fine-tuning GPT-2. Trend is consistent with results on E2E.Sentence Classification. Results for RGP in Table</figDesc><table><row><cell cols="5">Metrics tradeoff func. METEOR ROUGE-1 ROUGE-2 ROUGE-L BLEU BERTScore BLEURT Method DP Guarantee Gaussian DP Compose + CLT</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.28</cell><cell>? 2.65</cell><cell>0.294 62.815 40.773 52.063 31.025 0.887 -0.058</cell></row><row><cell>full</cell><cell>= 8 non-private</cell><cell>? 5.35 -</cell><cell>? 6.95 -</cell><cell>0.319 66.423 43.609 54.576 35.057 0.901 0.043 0.369 71.563 47.168 56.717 42.783 0.915 0.178</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.68</cell><cell>? 2.76</cell><cell>0.304 63.641 40.753 52.012 32.329 0.885 -0.029</cell></row><row><cell>LoRA</cell><cell>= 8 non-private</cell><cell>? 6.68 -</cell><cell>? 7.26 -</cell><cell>0.318 66.336 43.056 54.082 34.163 0.899 0.036 0.366 71.192 47.336 57.430 42.254 0.915 0.182</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.28</cell><cell>? 2.65</cell><cell>0.269 59.503 38.229 49.444 25.726 0.860 -0.144</cell></row><row><cell>prefix</cell><cell>= 8 non-private</cell><cell>? 5.35 -</cell><cell>? 6.95 -</cell><cell>0.297 64.009 41.581 52.602 30.463 0.892 -0.021 0.353 70.341 46.643 56.858 40.163 0.912 0.148</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.10</cell><cell>? 2.54</cell><cell>0.265 58.688 37.202 49.011 25.748 0.873 -0.175</cell></row><row><cell>RGP</cell><cell>= 8 non-private</cell><cell>? 5.02 -</cell><cell>? 6.86 -</cell><cell>0.279 60.005 38.258 49.835 28.304 0.874 -0.141 0.324 65.667 42.617 53.477 35.551 0.895 0.022</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.68</cell><cell>? 2.76</cell><cell>0.022 3.570 2.183 3.166 0.388 0.098 -1.952</cell></row><row><cell>top2</cell><cell>= 8 non-private</cell><cell>? 6.68 -</cell><cell>? 7.26 -</cell><cell>0.054 11.475 7.054 10.042 2.453 0.240 -1.660 0.318 62.777 38.367 49.426 36.099 0.883 -0.082</cell></row><row><cell></cell><cell>= 3</cell><cell>? 2.28</cell><cell>? 2.65</cell><cell>0.064 19.085 8.901 17.142 2.997 0.493 -1.513</cell></row><row><cell>retrain</cell><cell>= 8 non-private</cell><cell>? 5.35 -</cell><cell>? 6.95 -</cell><cell>0.093 24.971 11.938 21.680 7.765 0.573 -1.302 0.232 47.782 26.361 37.864 26.794 0.806 -0.593</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Fine-tuning under DP prevents unintended memorization of downstream data. Numbers reported are exposure values estimated with the approximation by distribution model approach.</figDesc><table><row><cell>``````````G uarantee</cell><cell>Repetitions</cell><cell>r = 1</cell><cell>r = 10</cell><cell>r = 100</cell></row><row><cell></cell><cell>= 3</cell><cell cols="3">1.09 ? 0.86 1.32 ? 1.32 5.26 ? 4.20</cell></row><row><cell cols="2">non-private</cell><cell cols="3">13.82 ? 3.86 17.22 ? 0.00 17.78 ? 5.49</cell></row><row><cell cols="5">N TEMPLATES AND LABEL WORDS FOR TEXT-INFILLING-BASED</cell></row><row><cell cols="3">CLASSIFICATION IN SECTION 3.2</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>&lt;S 1 &gt; It was [MASK] . positive: great, negative: terrible MNLI &lt;S 1 &gt; ? [MASK] , &lt;S 2 &gt; entailment: Yes, netural: Maybe, contradiction: No QNLI &lt;S 1 &gt; ? [MASK] , &lt;S 2 &gt; entailment: Yes, not entailment: No QQP &lt;S 1 &gt; [MASK] , &lt;S 2 &gt; equivalent: Yes, not equivalent: No</figDesc><table><row><cell>Task Template</cell><cell>Label words</cell></row><row><cell>SST-2</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 10 :</head><label>10</label><figDesc>Templates and label words borrowed from the work by</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table name :</head><label>name</label><figDesc>The Punter -Type : restaurant -food : Indian -price : cheap -customer rating : average -area : riverside -family friendly : no -near : Express by Holiday</figDesc><table><row><cell>Inn</cell></row><row><cell>GPT-2 ( = 3)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 11 :</head><label>11</label><figDesc></figDesc><table /><note><p>Fully fine-tuned GPT-2, GPT-2-medium, and GPT-2-large generations with E2E test table entries.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>Luis Miguel Ramis is the manager of Real Madrid Castilla. He plays for C.D. FAS. GPT-2-m ( = 8) Luis Miguel Ramis is the manager of Real Madrid Castilla. He plays for C.D. FAS. GPT-2-l ( = 3) Luis Miguel Ramis is the manager of Real Madrid Castilla and C.D. FAS. GPT-2-l ( = 8) Luis Miguel Ramis is the manager of Real Madrid Castilla and Abner (footballer) plays for C.D. FAS. Reference Footballer, Abner, plays C.D. FAS. and Real Madrid Castilla, the manager of which, is Luis Miguel Ramis.</figDesc><table><row><cell>Table</cell><cell>Real Madrid Castilla : manager : Luis Miguel Ramis -Abner (footballer) : club : Real</cell></row><row><cell></cell><cell>Madrid Castilla -Abner (footballer) : club : C.D. FAS</cell></row><row><cell>GPT-2 ( = 3)</cell><cell>Luis Miguel Ramis played for Real Madrid Castilla and played for C.D. FAS.</cell></row><row><cell>GPT-2 ( = 8)</cell><cell>Luis Miguel Ramis is the manager of Abner (footballer) who plays for Real Madrid</cell></row><row><cell></cell><cell>Castilla.</cell></row><row><cell>GPT-2-m ( = 3)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table United</head><label>United</label><figDesc></figDesc><table><row><cell></cell><cell>States : ethnic group : Asian Americans -United States : capital : Washington,</cell></row><row><cell></cell><cell>D.C. -Albany, Oregon : is part of : Benton Oregon -Albany, Oregon : country</cell></row><row><cell></cell><cell>: United States</cell></row><row><cell>GPT-2 ( = 3)</cell><cell>The capital of the United States is Washington, D.C. and is part of Benton County, Oregon.</cell></row><row><cell>GPT-2 ( = 8)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 12 :</head><label>12</label><figDesc>Fully fine-tuned GPT-2, GPT-2-medium, and GPT-2-large generations with DART test table entries.</figDesc><table><row><cell>Persona</cell><cell>['i am 40 years old.', 'i work as a car salesman.', 'my wife spends all my money.', 'i hate</cell></row><row><cell></cell><cell>my job.', "i'm planning on getting a divorce."]</cell></row><row><cell>History</cell><cell>['i know the struggle, i volunteer at a homeless shelter', "great, i hope you don't get to see</cell></row><row><cell></cell><cell>me there.", 'i hope not either, would not wish it on my worse enemy', 'between wife, job</cell></row><row><cell></cell><cell>with no money, i am thinking now of divorce.', "i've given it a few thoughts before"]</cell></row><row><cell>GPT-2-m ( = 3)</cell><cell>i wish i had a better idea .</cell></row><row><cell>GPT-2-m ( = 8)</cell><cell>i think i will . what are your thoughts on divorce ?</cell></row><row><cell cols="2">DialoGPT-medium ( = 3) i'm sorry to hear that . i hope you don't have any financial problems .</cell></row><row><cell cols="2">DialoGPT-medium ( = 8) i don't have any money , i do not know how i could manage .</cell></row><row><cell>Reference</cell><cell>do you give demonstrations of your skills ?</cell></row><row><cell>Persona</cell><cell>['my mother is a dentist.', 'my favourite artist is travis scott.', 'i have one older sister.', 'i</cell></row><row><cell></cell><cell>am currently looking for a job preferably at a restaurant.', 'i like playing basketball.']</cell></row><row><cell>History</cell><cell>['hello, how are you tonight?']</cell></row><row><cell>GPT-2-m ( = 3)</cell><cell>i'm good , good luck</cell></row><row><cell>GPT-2-m ( = 8)</cell><cell>i am good , just listening to travis scott . what about you ?</cell></row><row><cell cols="2">DialoGPT-medium ( = 3) i'm good . just got back from a dentist visit .</cell></row><row><cell cols="2">DialoGPT-medium ( = 8) i am doing well . just got back from a dentist visit</cell></row><row><cell>Reference</cell><cell>i am good . about to go to basketball practice .</cell></row><row><cell>Persona</cell><cell>['my mom passed away when i was young.', 'i work in the insurance business.', 'my father</cell></row><row><cell></cell><cell>is in the army.', 'i recently was fired and had to get a new job.']</cell></row><row><cell>History</cell><cell>["god isn't really real", 'to each their own, but i believe he is.', 'my children are gone</cell></row><row><cell></cell><cell>now', 'i lost my mom at a young age', 'my wife took them all']</cell></row><row><cell>GPT-2-m ( = 3)</cell><cell>she was a great mother</cell></row><row><cell>GPT-2-m ( = 8)</cell><cell>they were so young , they were so crazy</cell></row><row><cell cols="2">DialoGPT-medium ( = 3) that is horrible . my mom was a soldier</cell></row><row><cell cols="2">DialoGPT-medium ( = 8) what happened to her ?</cell></row><row><cell>Reference</cell><cell>sorry to hear that . i barely see my dad he's in the army</cell></row><row><cell>Persona</cell><cell>['i am also a graduate student.', 'i walk dogs for a living.', 'my parents taught me survival</cell></row><row><cell></cell><cell>skills.', 'i am an avid kayaker.', 'i enjoy reading journals and guides related to psychology.']</cell></row><row><cell>History</cell><cell>['hi, how are you today?', "good evening. how are you tonight? i'm well.", 'i am doing</cell></row><row><cell></cell><cell>good, i just finished playing ping pong.', 'i am trying to write invoices for my dog walking</cell></row><row><cell></cell><cell>business.', 'that seems like hare work, i like to play the violin in my free time.']</cell></row><row><cell>GPT-2-m ( = 3)</cell><cell>i have a lot of dogs , i walk them on my walks .</cell></row><row><cell>GPT-2-m ( = 8)</cell><cell>that is a very rewarding hobby . i have a dog named jasper .</cell></row><row><cell cols="2">DialoGPT-medium ( = 3) oh , that is a nice hobby . what do you do for a living ?</cell></row><row><cell cols="2">DialoGPT-medium ( = 8) it is . i love learning to play the violin .</cell></row><row><cell>Reference</cell><cell>i love the violin . i do not play anything . i kayak for fun however .</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 13 :</head><label>13</label><figDesc>Fully fine-tuned GPT-2-medium and DialoGPT-medium generations for Persona-Chat validation examples.P ADDITIONAL RELATED WORKDifferentially Private Deep Learning. DP-SGD has been viewed as ineffective for large models due to the addition of large Gaussian noise to gradient updates. Improvements to the learning procedure mostly fall under two distinct camps: (i) Simplifying the private learning problem, and (ii) reducing the scale of noise. For instance,<ref type="bibr" target="#b60">Papernot et al. (2019);</ref><ref type="bibr" target="#b76">Tram?r &amp; Boneh (2020)</ref>;Abadi  et al. (</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 14 :</head><label>14</label><figDesc>Text-infilling objective improves the performance of RGP for classification. Numbers are averaged over three independent runs. MNLI-(m/mm) QQP QNLI SST-2 RGP (RoBERTa-base) 79.79/80.40 83.58 84.14 89.60 RGP + infilling (RoBERTa-base) 81.97/82.28 84.02 87.20 92.85 V WHICH METHOD SHALL I USE FOR PRIVATE FINE-TUNING?</figDesc><table><row><cell>Method</cell><cell>= 8</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>This is because DP-SGD often necessitates microbatching, in which case the number of backward passes is independent of the actual batch size for gradient updates but dependent on numbers of passes through the data.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>Anecdotally, moderately large learning rates also tend to work reasonably well in non-private learning. Small learning rates, however, are generally more stable, especially when (average) gradients aren't clipped.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>For GPT-2, per-example gradients w.r.t. the embedding for ten examples alone occupy 1.5GB of memory.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>An embedding layer is essentially a linear layer: The embedding lookup operation applied to indices is equivalent to a matrix multiplication of the embedding matrix with one-hot encoded indices.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4"><p>The derived complexity is based on the assumption that the space complexity for multiplying two matrices A ? R m?n and B ? R n?p is roughly O(mp), which is the case for most workloads running on a framework like PyTorch. In addition, more sophisticated solutions may even avoid instantiating aia i and gig i entirely by trading in more run-time. Custom CUDA kernels are likely needed to make these solutions fast in practice.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5"><p>We omitted the cost of storing ai and gi, since our goal is to compare the additional cost induced by computing gradient norms.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6"><p>In practice, for fine-tuning tasks, the maximum sequence length is usually a few hundred.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_7"><p>While there are alternative approaches for reducing the memory footprint of embedding layers during training, these methods tend to introduce extra hyperparameters that potentially require further tuning and privacy spending.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_8"><p>The careful reader will notice that the original RGP paper(Yu et al., 2021c)  reported considerably worse full fine-tuning results. We analyzed their released codebase and discovered a bug caused by their use of mixed-precision training. With this bug fixed, their codebase produces results similar to ours for full fine-tuning on SST-2. We detail subtleties of DP mixed-precision training in Appendix T, and outline our implementation which achieves approximate scale invariance.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_9"><p>https://github.com/tensorflow/privacy/blob/7c4f5bab0964bd32b7ceafa009d9488920856440/ tensorflow_privacy/privacy/optimizers/dp_optimizer.py#L385</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_10"><p>https://github.com/microsoft/prv_accountant</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_11"><p>https://github.com/matthias-wright/flaxmodels</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_12"><p>https://github.com/dayu11/Differentially-Private-Deep-Learning/tree/ main/language</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_13"><p>https://github.com/tuetschek/e2e-metrics</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_14"><p>https://github.com/GEM-benchmark/GEM-metrics</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_15"><p>https://github.com/huggingface/transfer-learning-conv-ai</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_16"><p>http://convai.io/2018/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20" xml:id="foot_17"><p>https://github.com/DeepPavlov/convai/blob/master/leaderboards.md</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="21" xml:id="foot_18"><p>https://github.com/dayu11/Differentially-Private-Deep-Learning</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We thank <rs type="person">Xiang Lisa Li</rs> for help on reproducing non-private prefix-tuning results. We thank <rs type="person">Da Yu</rs> for discussions and help on reproducing results for the RGP method. We thank <rs type="person">Abhradeep Guha Thakurta</rs> and <rs type="person">Rishi Bommasani</rs> for helpful discussions. We thank members of the <rs type="institution">Stanford statistical machine learning group</rs> for comments on early versions of the abstract. We thank <rs type="person">Guodong Zhang</rs> and <rs type="person">Mayee Chen</rs> for comments on an early draft. We thank <rs type="person">Stanford HAI</rs> for a <rs type="grantName">Google Cloud Credits Grant</rs>. XL is supported by a <rs type="grantName">Stanford Graduate Fellowship</rs>. PL is supported by a <rs type="grantName">PECASE award</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_8FUE9rs">
					<orgName type="grant-name">Google Cloud Credits Grant</orgName>
				</org>
				<org type="funding" xml:id="_WDAwsG2">
					<orgName type="grant-name">Stanford Graduate Fellowship</orgName>
				</org>
				<org type="funding" xml:id="_MdbaJKK">
					<orgName type="grant-name">PECASE award</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q ESTIMATES OF RUN-TIME IN PRACTICE</head><p>The actual run-time of algorithms depends on implementation details. Here, we outline estimates of the run-time for full fine-tuning with DP-Adam on tasks considered in the paper. These numbers are based on running with a single RTX 3090 with PyTorch==1.9.0. Fine-tuning GPT-2 on E2E and DART takes less than 10 minutes per epoch, and fine-tuning for 10 epochs results in reasonably performing models. The time to fine-tune RoBERTa-base on classification tasks depends on the size of the dataset. It takes less than 10 minutes per epoch on the smallest SST-2, whereas for the largest MNLI, it takes less than an hour per epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R EFFECTS OF VARYING AND ? ON DP FULL FINE-TUNING PERFORMANCE</head><p>Figure <ref type="figure">9</ref> shows how different values of and ? affect the performance of full fine-tuning under DP. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S DP-ADAM VS DP-SGD</head><p>Our work focused on DP-Adam as opposed to DP-SGD, since Adam is more commonly used for non-private language model fine-tuning. While the two algorithms differ in their parameter update rule, the basic gradient privatization procedure is the same. We performed additional experiments fine-tuning GPT-2 on the E2E dataset with DP-SGD (with freshly tuned learning rate and clipping norm values) and observed that its performance (test set BLEU 63.175 at ( , ?) = (8, 10 -5 )) is on par with DP-Adam (test set BLEU 63.189 at ( , ?) = (8, 10 -5 )).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T SUBTLETIES OF IMPLEMENTING DP MIXED PRECISION TRAINING</head><p>Mixed precision training <ref type="bibr" target="#b50">(Micikevicius et al., 2017)</ref> accelerates updates by storing certain tensors in half-precision. To mitigate negative effects caused by potential arithmetic underflow, usual implementations upscale the loss with an adaptive factor pre-backpropagation and downscale the gradients with the same factor post-backpropagation. The scaling factor is adapted based on whether underflow is observed during training.</p><p>Special care needs to be taken when combining gradient privatization with mixed precision training. One implementation that ensures similar results across full and mixed precision training (1) upscales the loss with the adaptive factor K, (2) clips per-example gradients by CK, (3) adds to the sum of clipped gradients the usual Gaussian noise multiplied by K, and (4) downscales the noisy gradient by K. This is the implementation that we adopt, and we were able to obtain similar results on the E2E dataset with and without mixed precision.</p><p>One alternative implementation (a) upscales the loss with the adaptive factor K, (b) clips per-example gradients by C, (c) adds the usual Gaussian noise to the sum of clipped gradients, and (d) downscales noisy gradients by K. The main difference between this procedure and the prior is whether the</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep learning with differential privacy</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Brendan Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGSAC conference on computer and communications security</title>
		<meeting>the 2016 ACM SIGSAC conference on computer and communications security</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="308" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Large-scale differentially private bert</title>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Badih</forename><surname>Ghazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vineet</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pasin</forename><surname>Manurangsi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.01624</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Private adaptive gradient methods for convex optimization</title>
		<author>
			<persName><forename type="first">Hilal</forename><surname>Asi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alireza</forename><surname>Fallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omid</forename><surname>Javidbakht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="383" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Differentially private empirical risk minimization: Efficient algorithms and tight error bounds</title>
		<author>
			<persName><forename type="first">Raef</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhradeep</forename><surname>Thakurta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models</title>
		<author>
			<persName><forename type="first">Elad</forename><surname>Ben Zaken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shauli</forename><surname>Ravfogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">2106</biblScope>
		</imprint>
	</monogr>
	<note>arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Towards private synthetic text generation</title>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xanda</forename><surname>Schofield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2019 Machine Learning with Guarantees Workshop</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">On the opportunities and risks of foundation models</title>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Drew</forename><forename type="middle">A</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simran</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><surname>Sydney Von Arx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeannette</forename><surname>Michael S Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bohg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><surname>Brunskill</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07258</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Deep learning with gaussian differential privacy. Harvard data science review</title>
		<author>
			<persName><forename type="first">Zhiqi</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinshuo</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijie J</forename><surname>Su</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Fast and memory efficient differentially private-sgd via jl projections</title>
		<author>
			<persName><forename type="first">Zhiqi</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sivakanth</forename><surname>Gopi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janardhan</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Tat Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judy</forename><forename type="middle">Hanwen</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uthaipon</forename><surname>Tantipongpipat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.03013</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Tinytl: Reduce memory, not parameters for efficient on-device learning</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuang</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.11622</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The secret sharer: Evaluating and testing unintended memorization in neural networks</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?lfar</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jernej</forename><surname>Kos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">28th {USENIX} Security Symposium ({USENIX} Security 19)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="267" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Extracting training data from large language models</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Tramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulfar</forename><surname>Erlingsson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.07805</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A stability-based validation procedure for differentially private machine learning</title>
		<author>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><surname>Vinterbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2652" to="2660" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Gs-wgan: A gradient-sanitized approach for learning differentially private generators</title>
		<author>
			<persName><forename type="first">Dingfan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tribhuvanesh</forename><surname>Orekondy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.08265</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Maximin</forename><surname>Coavoux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.09408</idno>
		<title level="m">Privacy-preserving neural representations of text</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The second conversational intelligence challenge (convai2)</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><surname>Malykh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.00098</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Jinshuo</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijie J</forename><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.02383</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">Gaussian differential privacy. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">An efficient dp-sgd mechanism for large scale nlp models</title>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Dupuy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radhika</forename><surname>Arava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rumshisky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.14586</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Calibrating noise to sensitivity in private data analysis</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kobbi</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory of cryptography conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="265" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The algorithmic foundations of differential privacy</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="211" to="407" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural approaches to conversational ai</title>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1371" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Making pre-trained language models better few-shot learners</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15723</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tosin</forename><surname>Adewumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karmanya</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pawan</forename><surname>Sasanka Ammanamanchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aremu</forename><surname>Anuoluwapo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghavi</forename><surname>Khyathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miruna</forename><surname>Chandu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipanjan</forename><surname>Clinciu</surname></persName>
		</author>
		<author>
			<persName><surname>Das</surname></persName>
		</author>
		<author>
			<persName><surname>Kaustubh D Dhole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.01672</idno>
		<title level="m">The gem benchmark: Natural language generation, its evaluation and metrics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Efficient per-example gradient computations</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.01799</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Sivakanth</forename><surname>Gopi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Tat Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Wutschitz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.02848</idno>
		<title level="m">Numerical composition of differential privacy</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Membership inference attacks against generative models</title>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Danezis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emiliano</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristofaro</forename><surname>Logan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings on Privacy Enhancing Technologies (PoPETs)</title>
		<meeting>on Privacy Enhancing Technologies (PoPETs)</meeting>
		<imprint>
			<publisher>De Gruyter</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="page" from="133" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The curious case of neural text degeneration</title>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09751</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning and evaluating a differentially private pre-trained language model</title>
		<author>
			<persName><forename type="first">Shlomo</forename><surname>Hoory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Feder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avichai</forename><surname>Tendler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alon</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sofia</forename><surname>Erell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Itay</forename><surname>Laish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hootan</forename><surname>Nakhost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Stemmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayelet</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avinatan</forename><surname>Hassidim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Privacy in Natural Language Processing</title>
		<meeting>the Third Workshop on Privacy in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Parameter-efficient transfer learning for nlp</title>
		<author>
			<persName><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Giurgiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanislaw</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruna</forename><surname>Morrone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>De Laroussilhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Gesmundo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Attariyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2790" to="2799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yelong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyuan</forename><surname>Wallis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shean</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Lora</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.09685</idno>
		<title level="m">Low-rank adaptation of large language models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Texthide: Tackling data privacy in language understanding tasks</title>
		<author>
			<persName><forename type="first">Yangsibo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.06053</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Instahide: Instance-hiding schemes for private distributed learning</title>
		<author>
			<persName><forename type="first">Yangsibo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4507" to="4518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Fast dimension independent private adagrad on publicly estimated subspaces</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kairouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ribero</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><surname>Thakurta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.06570</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Gautam</forename><surname>Kamath</surname></persName>
		</author>
		<ptr target="http://www.gautamkamath.com/CS860notes/lec14.pdf" />
		<title level="m">Lecture 14 -Private ML and Stats: Modern ML</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.08361</idno>
		<title level="m">Scaling laws for neural language models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Gavin</forename><surname>Kerrigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Slack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jens</forename><surname>Tuyls</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.05886</idno>
		<title level="m">Differentially private language models benefit from public pre-training</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Computing tight differential privacy guarantees using fft</title>
		<author>
			<persName><forename type="first">Antti</forename><surname>Koskela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joonas</forename><surname>J?lk?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antti</forename><surname>Honkela</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2560" to="2569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Scaling up differentially private deep learning with fast per-example gradient clipping</title>
		<author>
			<persName><forename type="first">Jaewoo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Kifer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.03106</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">The power of scale for parameter-efficient prompt tuning</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08691</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.03055</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Prefix-tuning: Optimizing continuous prompts for generation</title>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00190</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Private selection from private candidates</title>
		<author>
			<persName><forename type="first">Jingcheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing</title>
		<meeting>the 51st Annual ACM SIGACT Symposium on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="298" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.10385</idno>
		<title level="m">Gpt understands, too</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><surname>Roberta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Compacter: Efficient low-rank hypercomplex adapter layers</title>
		<author>
			<persName><forename type="first">Rabeeh</forename><surname>Karimi Mahabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.04647</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Emergent linguistic structure in artificial neural networks trained by self-supervision</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Christopher D Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urvashi</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">48</biblScope>
			<biblScope unit="page" from="30046" to="30054" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Learning differentially private recurrent language models</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>H Brendan Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.06963</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Towards automatic generation of shareable synthetic clinical notes using neural language models</title>
		<author>
			<persName><forename type="first">Oren</forename><surname>Melamud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaitanya</forename><surname>Shivade</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.07002</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">Paulius</forename><surname>Micikevicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonah</forename><surname>Alben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erich</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Ginsburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Houston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksii</forename><surname>Kuchaiev</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.03740</idno>
		<title level="m">Ganesh Venkatesh, et al. Mixed precision training</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">Fatemehsadat</forename><surname>Mireshghallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcello</forename><surname>Huseyin A Inan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Hasegawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>R?hle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><surname>Sim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.07567</idno>
		<title level="m">Privacy regularization: Joint privacy-utility optimization in language models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">R?nyi differential privacy</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE 30th Computer Security Foundations Symposium (CSF)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="263" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">R\&apos;enyi differential privacy of the sampled gaussian mechanism</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10530</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Dart: Open-domain structured data record to text generation</title>
		<author>
			<persName><forename type="first">Linyong</forename><surname>Nan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amrit</forename><surname>Rau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinand</forename><surname>Sivaprasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiachun</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangru</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aadit</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neha</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Krishna</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.02871</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<author>
			<persName><forename type="first">Marcel</forename><surname>Neunhoeffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Steven Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.11934</idno>
		<title level="m">Private post-gan boosting</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">The e2e dataset: New challenges for end-to-end generation</title>
		<author>
			<persName><forename type="first">Jekaterina</forename><surname>Novikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ond?ej</forename><surname>Du?ek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Verena</forename><surname>Rieser</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.09254</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Steinke</surname></persName>
		</author>
		<title level="m">Hyperparameter tuning with renyi differential privacy</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Semisupervised knowledge transfer for deep learning from private training data</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mart?n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulfar</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.05755</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Scalable private learning with pate</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Ananth Raghunathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?lfar</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><surname>Erlingsson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.08908</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Making the shoe fit: Architectures, initializations, and tuning for learning with privacy</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuang</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Abhradeep Thakurta, and Ulfar Erlingsson</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rockt?schel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">H</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.01066</idno>
		<title level="m">Language models as knowledge bases? arXiv preprint</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aishwarya</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>R?ckl?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00247</idno>
		<title level="m">Adapterfusion: Non-destructive task composition for transfer learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">Venkatadheeraj</forename><surname>Pichapati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theertha</forename><surname>Ananda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><forename type="middle">X</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sashank</forename><forename type="middle">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjiv</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.07643</idno>
		<title level="m">Adaclip: Adaptive clipping for private sgd</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Privacyadaptive bert for natural language understanding</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weize</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.07504</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">Swaroop</forename><surname>Ramaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Om</forename><surname>Thakkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajiv</forename><surname>Mathews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Galen</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Brendan Mcmahan</surname></persName>
		</author>
		<author>
			<persName><surname>Franc</surname></persName>
		</author>
		<author>
			<persName><surname>Beaufays</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.10031</idno>
		<title level="m">Training production language models without memorizing user data</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">The moral character of cryptographic work</title>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Rogaway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cryptology ePrint Archive</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">Andreas</forename><surname>R?ckl?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Geigle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Glockner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tilman</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName><surname>Adapterdrop</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11918</idno>
		<title level="m">On the efficiency of adapters in transformers</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Membership inference attacks against machine learning models</title>
		<author>
			<persName><forename type="first">Reza</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Stronati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Congzheng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A taxonomy of privacy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><surname>Solove</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">U. Pa. l. Rev</title>
		<imprint>
			<biblScope unit="volume">154</biblScope>
			<biblScope unit="page">477</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Stochastic gradient descent with differentially private updates</title>
		<author>
			<persName><forename type="first">Shuang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><forename type="middle">D</forename><surname>Sarwate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE Global Conference on Signal and Information Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="245" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Enabling fast differentially private sgd via just-in-time compilation and vectorization</title>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Subramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Vadivelu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautam</forename><surname>Kamath</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.09063</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Differentially private synthetic medical data generation using convolutional gans</title>
		<author>
			<persName><forename type="first">Amirsina</forename><surname>Torfi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandan K</forename><surname>Reddy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.11774</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Dp-cgan: Differentially private synthetic data and label generation</title>
		<author>
			<persName><forename type="first">Reihaneh</forename><surname>Torkzadehmahani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Kairouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benedict</forename><surname>Paten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<author>
			<persName><forename type="first">Florian</forename><surname>Tram?r</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Boneh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.11660</idno>
		<title level="m">Differentially private learning needs better features (or much more data)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
		<title level="m">Attention is all you need</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.01652</idno>
		<title level="m">Finetuned language models are zero-shot learners</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">The multi-genre nli corpus</title>
		<author>
			<persName><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName><surname>Samuel R Bowman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Learning neural templates for text generation</title>
		<author>
			<persName><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><forename type="middle">M</forename><surname>Shieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.10122</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">On a utilitarian approach to privacy preserving text generation</title>
		<author>
			<persName><forename type="first">Zekun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oluwaseyi</forename><surname>Feyisetan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Teissier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.11838</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<author>
			<persName><forename type="first">Ashkan</forename><surname>Yousefpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Shilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davide</forename><surname>Testuggine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mani</forename><surname>Malek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sayan</forename><surname>Gosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akash</forename><surname>Bharadwaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<title level="m">Opacus: User-friendly differential privacy library in pytorch</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Differentially private fine-tuning of language models</title>
		<author>
			<persName><forename type="first">Da</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arturs</forename><surname>Backurs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sivakanth</forename><surname>Gopi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautam</forename><surname>Huseyin A Inan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janardhan</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin Tat</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andre</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Manoel</surname></persName>
		</author>
		<author>
			<persName><surname>Wutschitz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.06500</idno>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Do not let privacy overbill utility: Gradient embedding perturbation for private learning</title>
		<author>
			<persName><forename type="first">Da</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huishuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.12677</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Large scale private learning via low-rank reparametrization</title>
		<author>
			<persName><forename type="first">Da</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huishuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.09352</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno>CoRR, abs/1611.03530</idno>
		<ptr target="http://arxiv.org/abs/1611.03530" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<author>
			<persName><forename type="first">Huanyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meisam</forename><surname>Hejazinia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.01294</idno>
		<title level="m">Wide network learning with differential privacy</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">Personalizing dialogue agents: I have a dog, do you have pets too</title>
		<author>
			<persName><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.07243</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Dialogpt: Large-scale generative pre-training for conversational response generation</title>
		<author>
			<persName><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yen-Chun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.00536</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Bypassing the ambient dimension: Private sgd with gradient subspace identification</title>
		<author>
			<persName><forename type="first">Yingxue</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Steven Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arindam</forename><surname>Banerjee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.03813</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
