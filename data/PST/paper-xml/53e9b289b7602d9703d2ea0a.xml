<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CPU demand for web serving: Measurement analysis and dynamic estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2007-12-14">14 December 2007</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Giovanni</forename><surname>Pacifici</surname></persName>
							<email>giovanni@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution">IBM T.J. Watson Research Center</orgName>
								<address>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wolfgang</forename><surname>Segmuller</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM T.J. Watson Research Center</orgName>
								<address>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mike</forename><surname>Spreitzer</surname></persName>
							<email>mspreitz@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution">IBM T.J. Watson Research Center</orgName>
								<address>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Asser</forename><surname>Tantawi</surname></persName>
							<email>tantawi@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution">IBM T.J. Watson Research Center</orgName>
								<address>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CPU demand for web serving: Measurement analysis and dynamic estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2007-12-14">14 December 2007</date>
						</imprint>
					</monogr>
					<idno type="MD5">DB64710FBAA45A3EC0B6C9288686879C</idno>
					<idno type="DOI">10.1016/j.peva.2007.12.001</idno>
					<note type="submission">Received 3 December 2007; accepted 7 December 2007</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Workload profiling</term>
					<term>Linear regression</term>
					<term>Web workload</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Managing the resources in a large Web serving system requires knowledge of the resource needs for service requests of various types. In order to investigate the properties of Web traffic and its demand, we collected measurements of throughput and CPU utilization and performed some data analyses. First, we present our findings in relation to the time-varying nature of the traffic, the skewness of traffic intensity among the various types of requests, the correlation among traffic streams, and other system-related phenomena. Then, given such nature of web traffic, we devise and implement an on-line method for the dynamic estimation of CPU demand.</p><p>Assessing resource needs is commonly performed using techniques such as off-line profiling, application instrumentation, and kernel-based instrumentation. Little attention has been given to the dynamic estimation of dynamic resource needs, relying only on external and high-level measurements such as overall resource utilization and request rates. We consider the problem of dynamically estimating dynamic CPU demands of multiple kinds of requests using CPU utilization and throughput measurements. We formulate the problem as a multivariate linear regression problem and obtain its basic solution. However, as our measurement data analysis indicates, one is faced with issues such as insignificant flows, collinear flows, space and temporal variations, and background noise. In order to deal with such issues, we present several mechanisms such as data aging, flow rejection, flow combining, noise reduction, and smoothing. We implemented these techniques in a Work Profiler component that we delivered as part of a broader system management product. We present experimental results from using this component in scenarios inspired by real-world usage of that product.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Web serving systems are becoming increasingly complex, involving a large number of servers, several tiers of interconnected systems, many applications, and fluctuating request patterns. The dynamic management of resources and quality of service in such an environment are of vital importance to the performance and operation of the Web serving system <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b17">18]</ref>. A key requirement to an effective dynamic resource management is the knowledge of the resource needs of the various kinds of requests. It is important to be able to classify requests with sufficient granularity to support management goals (e.g., multiple service classes within a given application). It is also important to recognize that the resource requirements of a given kind of request may change over time, due to evolution in, e.g., the request parameters or the server states. Focusing on the CPU as the resource of interest, there exist several techniques to assess the CPU cycles consumed by each kind of requests. At application development time, one may utilize profiling mechanisms to measure CPU usage off-line, or predict CPU usage of the various branches of an application on-line. At application run-time, one may instrument application code with calls, such as the ARM (Application Resource Measurement) API <ref type="bibr" target="#b0">[1]</ref> to keep track of the time spent at various resources while servicing a (transaction) request. The ARM standard includes measuring availability, performance, usage, and end-to-end transaction response time -all based on an open request classification scheme. An alternative to using high-level calls is kernel-based measurement <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b19">20]</ref> which may prove to be more efficient but intrusive. Another statistical technique for profiling applications used in Grid computing is Statistical Demand Profiles <ref type="bibr" target="#b14">[15]</ref>. Such profiles accumulate over time the distribution of resource needs, and hence could be used for resource allocation.</p><p>The profiling techniques that we mentioned so far have several drawbacks: adding instrumentation to the application at development time, relying on middleware or kernel agents to collect and correlate events, incurring overheads in the request execution path, limited ability to track changes in requirements, and/or limited granularity of classification. Little attention has been given to the dynamic estimation of dynamic resource needs, relying only on external and high-level measurements such as overall resource utilization and request rates. We consider the problem of dynamically estimating dynamic CPU demands of various kinds of requests using CPU utilization and throughput measurements. We introduce a problem formulation as a linear regression problem and obtain its basic solution.</p><p>There are several practical issues that will cause the basic solution to be inaccurate, or even unstable. In order to understand such practical issues, one needs to investigate the salient features of Web traffic and its demand. Through external measurements of throughput and CPU utilizations, we perform some data analysis and arrive at some basic practical properties. We present our findings in relation to the time-varying nature of the traffic, the skewness of traffic intensity among the various types of requests, the correlation among traffic streams, and other system-related phenomena. Accordingly, one needs to consider practical issues such as insignificant flows, collinear flows, space and temporal variations, and background noise. We present techniques to deal with such practical considerations such as data aging, flow rejection, flow combining, noise reduction, and smoothing. We have incorporated our dynamic profiling techniques in a Work Profiler component in an IBM product, WebSphere Extended Deployment <ref type="bibr" target="#b1">[2]</ref>.</p><p>The rest of this paper is organized as follows. Prior work is summarized in Section 2. Section 3 describes the work profiling problem. The basic solution to the problem is given in Section 4. Data measurement and its analysis are presented in Section 5. Section 6 describes practical enhancements to the basic solution. Section 7 presents the experimental results. Finally, in Section 8 we discuss our conclusions and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Prior work</head><p>The workload characterization of web servers has received attention for over a decade now. Motivated by various reasons; traffic modeling, capacity planning, and resource management, various metrics are collected, analyzed, and visualized. As an early example <ref type="bibr" target="#b4">[5]</ref>, statistics of traffic (arrival pattern, request interarrival time, and mix of requests), files (size and popularity), response (size, time, and throughput), and client behavior are reported. Given the statistical data, researchers attempted to characterize the load by fitting distributions to data and building performance models driven by such distributions, e.g. <ref type="bibr" target="#b5">[6]</ref>. Queueing network models and layered queueing models have been developed <ref type="bibr" target="#b15">[16]</ref>. The parameters of such models needed to be estimated. Basically, there are two methods for parameter estimation: direct measurement and statistical inference. With direct measurement, instrumentation in the operating system, as well as applications, collects data observations. This method incurs overhead, may result in a large amount of data, requires events correlation, and assumes OS support, and potentially application instrumentation. Alternatively, statistical inference uses regression techniques to extract parameter estimates from external observations. There, the difficulty lies in the validity of the regression model and the pitfalls of regression analysis.</p><p>One of the early works in applying linear regression to parameter estimation in VM systems is <ref type="bibr" target="#b2">[3]</ref>, where several data sets are analyzed off-line in order to estimate job CPU time and system overhead from observations of job concurrency and CPU usage. More recently <ref type="bibr" target="#b12">[13]</ref>, linear regression is used for parameter estimation and is shown to be accurate (single digit percent error) when compared to simulation results. It is noted, however, that the regression method fails when there is not enough variation in the observed data, or if parameters have high variances. The accuracy of linear regression is studied <ref type="bibr" target="#b13">[14]</ref> using simulation of various service time distributions and is shown to decrease with the increase in variability. A correction of the estimated parameters through the use of extended Kalman filter is investigated <ref type="bibr" target="#b23">[24]</ref>. Dynamic changes in parameters such as service time, population size, and think time are tracked through filtering, given observations of measured quantities such as utilization and response time. Recently <ref type="bibr" target="#b22">[23]</ref>, regression-based approximation of the CPU demand has been applied to multitiered systems. Using the TPC-W benchmark, it is shown that the regression-based approach provides a simple and powerful solution for efficient capacity planning and resource provisioning. In <ref type="bibr" target="#b21">[22]</ref>, a combination of linear throughput model and a response time queueing model are used to formulate a nonlinear optimization problem for estimating service demands in multitiered systems. In <ref type="bibr" target="#b9">[10]</ref>, quadratic programming is used to infer queueing network parameters using end-to-end measurements.</p><p>Nonlinear regression analysis has also been applied to workload characterization. Service times in call centers are estimated using local polynomial regression <ref type="bibr" target="#b18">[19]</ref>. Further, instead of linear and polynomial regression, splines are used to characterize CPU service demand as a function of other parameters, such as number of users and file size <ref type="bibr" target="#b3">[4]</ref>.</p><p>Alternative to regression analysis, time series analysis is used for demand prediction. A method for capacity management based on trace analysis <ref type="bibr" target="#b6">[7]</ref> relies on workload characterization, demand prediction, and workload placement recommendation. Application of forecasting analysis using long term real data is used for capacity management and demand prediction of data centers <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem description</head><p>In this section, we describe the dynamic work profiling problem. In general the web serving system will be organized into multiple tiers. For the sake of brevity here we address only one tier; it is straightforward to apply this technique to multiple tiers (provided only the necessary high-level instrumentation). Consider a tier consisting of M machines and K request flows (or, simply flows). The classification of a request into a flow k, k = 1, 2, . . . , K , is arbitrary. For example, classification may be based on the URL of the request. A flow is destined to one or more server processes in the tier, depending on the placement of those processes onto machines and the deployment of applications into those processes. We require an infrastructure that can sense the CPU utilization of each machine, producing readings ρ m in the range [0, 1] occasionally for each machine m, m = 1, 2, . . . , M. If the infrastructure can provide occasional readings of the CPU utilization of each server process, we can use those instead of the machine utilization readings. We also require occasional sensors for the flow rates λ k,m ≥ 0 req/s for flow k on machine m. Finally we require knowledge (from sensors and/or configuration management) of the CPU power of each machine m, denoted by Ω m , in "standard cycles" per second. For simplicity we make an approximation, discussed later, that there is a machine-and application-independent measure of CPU work and call this the "standard cycle". For example: a single clock cycle on one type of machine might do 1.1 standard cycles of work, while a single clock cycle on a less powerful type of machine does 0.8 standard cycles of work. The measurements ρ m and λ k,m are collected periodically. We denote the utilization and flow rates collected during period i (for i = 1, 2, . . .) by ρ m,i and λ k,m,i , respectively, where i = 1 is the current period, i = 2 is the previous period, and so on. To simplify our initial description we start by using a sliding window of length I periods to limit the samples used; later we will describe an alternative technique which uses all samples with geometric aging.</p><p>To simplify our description we presume that the throughput and utilization readings for a given machine are synchronized: in each ρ m,i and λ k,m,i pair, we assume both components report on the same period of time. In our implementation, the throughput readings typically follow shortly after the machine utilization readings. (The throughput and utilization readings were not synchronized in the case of per-process CPU reading as discussed later.)</p><p>The dynamic work profiling problem is to come up with coefficients α k , for k in 1, 2, . . . , K , which we refer to as "work factor", representing the average number of cycles consumed due to processing one request of flow k. Multiplying a flow rate by the work factor for the flow yields the cycles/sec consumed by the flow. By summing up over all flows, we get the total utilized cycles/s. Hence we have the following model</p><formula xml:id="formula_0">ρ m,i Ω m = k=1,2,...,K λ k,m,i α k + i ,<label>(1)</label></formula><p>where i is an error term. Note that an additional variable representing work not due to flow processing may be added on the right-hand side, as an intercept. However, by doing that, we have encountered problems estimating that variable, especially when the λ space is not properly explored. So, according to Eq. ( <ref type="formula" target="#formula_0">1</ref>), any overhead (or background work) is spread among the flows, proportional to their rates. We recognize that model ( <ref type="formula" target="#formula_0">1</ref>) is an approximate one. In particular, one aspect of the approximation is the notion that there is an application-and machine-independent measure of CPU work. This is not actually true, but we suspect the approximation is close enough to be valuable in some management systems. If it is not close enough, the techniques in this paper can easily be adapted to a more fine-grained model that recognizes that the CPU cost of a flow may depend on the kind of machine where it is being served.</p><p>In order to estimate the K unknowns α k in Eq. ( <ref type="formula" target="#formula_0">1</ref>), we need to select a value for I in such a way that we have at least K nonzero, and independent equations. We use the variable N for the number of (throughput, utilization) readings used -that is, the number of distinct equations. In the next section we describe the solution to the dynamic work profiling problem Eq. <ref type="bibr" target="#b0">(1)</ref>. A desirably low value for the mean squared error in the solution helps in choosing a good value for N , and consequently the window size I .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Analysis</head><p>We use linear regression <ref type="bibr" target="#b11">[12]</ref> to estimate the α k , for k = 1, , 2, . . . , K , using Eq. (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Linear regression problem</head><p>The multivariate linear regression problem with N samples and K independent variables is stated as</p><formula xml:id="formula_1">Y = Xα + ,<label>(2)</label></formula><p>where</p><formula xml:id="formula_2">Y is (N × 1), X is (N × K ), the unknown α is (K × 1)</formula><p>, and is a (N × 1) vector of error residuals. The random variable is assumed to have an expectation</p><formula xml:id="formula_3">E[ ] = 0 and a (N × N ) variance-covariance matrix V [ ] = Iσ 2 .</formula><p>The unbiased estimate α with minimum mean squared error (MSE) is given by</p><formula xml:id="formula_4">α = X T X -1 X T Y.<label>(3)</label></formula><p>Defining</p><formula xml:id="formula_5">C = X T X and D = X T Y,</formula><p>Eq. ( <ref type="formula" target="#formula_4">3</ref>) may be written as</p><formula xml:id="formula_6">α = C -1 D.<label>(4)</label></formula><p>C is (K × K ) and D is (K × 1). The complexity of solving the linear regression problem is dominated by the matrix inversion operation in Eq. ( <ref type="formula" target="#formula_6">4</ref>). The mean squared error is estimated by</p><formula xml:id="formula_7">MSE = (Y -X α) T (Y -X α) N -K -1 ,</formula><p>which using Eq. ( <ref type="formula" target="#formula_6">4</ref>) simplifies to:</p><formula xml:id="formula_8">MSE = Y T Y -αT D N -K -1 .<label>(5)</label></formula><p>The validity of using a linear model is tested through the coefficient of determination, R 2 , which is defined as,</p><formula xml:id="formula_9">R 2 = 1 - SSE SST ,<label>(6)</label></formula><p>where</p><formula xml:id="formula_10">SSE = Y T Y -αT D , SST = Y T Y -N Ȳ 2 ,</formula><p>and</p><formula xml:id="formula_11">Ȳ = (1Y) /N .</formula><p>Ȳ is the average value of column Y and 1 is a (1 × N ) identity vector. A value of R 2 close to one signifies that there is a linear relationship between X and Y.</p><p>The basic work profiling problem is obtained from Eqs. ( <ref type="formula" target="#formula_0">1</ref>) and ( <ref type="formula" target="#formula_1">2</ref>), where</p><formula xml:id="formula_12">Y n = ρ m,i Ω m , and X n,k = λ k,m,i ,<label>(7)</label></formula><p>n = 1, 2, . . . , N , is the nth equation from the set of Eq. ( <ref type="formula" target="#formula_0">1</ref>) in some arbitrary order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Solution goodness measure</head><p>We need a measure of how well the data fits the linear model. We have α as an estimate of the mean of the solution to the linear regression problem. Let S 2 be a vector of length K , defined as</p><formula xml:id="formula_13">S 2 = MSE • diag(C -1 ),</formula><p>where MSE is given by Eq. ( <ref type="formula" target="#formula_8">5</ref>), and diag() is the diagonal operator, i.e. it produces a vector consisting of the diagonal elements of a matrix. S 2 is an estimate of the variance of the solution to the linear regression problem. Let S k = S 2 k , k = 1, 2, . . . , K , denote an estimate for the standard deviation of the solution, where S 2 k is the kth element of vector S 2 . Dividing the mean by the standard deviation we get a goodness of fit measure, denoted by g k , as</p><formula xml:id="formula_14">g k = αk S k .</formula><p>The higher the value of g k , the better the solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Correlation matrix</head><p>The linear relationships among pairs of (independent or dependent) variables are captured by the correlation matrix η, which is the (K + 1) square matrix, and is defined as <ref type="bibr" target="#b11">[12]</ref> </p><formula xml:id="formula_15">η = L W T (I -1/N )W L, (<label>8</label></formula><formula xml:id="formula_16">)</formula><p>where I is the identity matrix, W is the (N ×(K +1)) matrix comprising the dependent variable Y and the independent variables X. Define U as a vector of corrected sums of squares, given by</p><formula xml:id="formula_17">U = diag(W T (I -1/N )W).</formula><p>Let U k denote the kth element of U. Then L is a diagonal matrix of the reciprocals of U k . Element ηi, j is in the range [-1, 1], with ηi, j = 0 for uncorrelated variables i and j, ηi, j = 1(-1) for positively (negatively) correlated variables i and j, and otherwise for variables i and j being correlated with factor ηi, j , i, j = 1, 2, . . . , K + 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Data aging</head><p>An alternative to using a sliding window of measurements of size I periods is to weight the measurements depending on their age at the time of solving the linear regression problem. The motivation is that older data is less representative of the current behavior than more recent data is. Other weighting techniques are possible and may lead to the robust linear regression methodology <ref type="bibr" target="#b16">[17]</ref>. A common age discounting mechanism is to use a weight that decreases geometrically with age. We define the decay rate of our geometric weights in terms of a half-life value of h periods. In other words, the most recent data point gets a weight of one, the preceding data point gets a weight of 1/2 1/ h , then 1/2 2/ h , and so on. The h old data point gets a weight of 1/2. Thus, Eq. ( <ref type="formula" target="#formula_12">7</ref>) becomes</p><formula xml:id="formula_18">Y n = 2 (1-i)/ h ρ m,i Ω m , and X n,k = 2 (1-i)/ h λ k,m,i .<label>(9)</label></formula><p>In addition to discounting older data, the geometrical discounting mechanism is advantageous from an implementation point of view. Instead of storing the X and Y matrices, one can work with the C and D matrices which are smaller in size. Since the C and D matrices are the products of X T with X and Y, respectively, updating the C and D matrices with measurements obtained for a new period may be achieved by multiplying the matrices by 1/2 1/ h • 1/2 1/ h = 2 -2/ h , and adding the new measured data.</p><p>Since old data points decrease in significance and approach zero asymptotically, the effective number of samples used is computed using the same geometrically decreasing weights. The effective number of samples is used when computing the degrees of freedom in Eq. ( <ref type="formula" target="#formula_8">5</ref>). Let N h denote the effective number of samples when using the data aging technique. Hence, we have</p><formula xml:id="formula_19">N h = N i=1 2 (1-i)/ h = 1 -2 -N / h 1 -2 -1/ h .</formula><p>For large N , we get lim</p><formula xml:id="formula_20">N →∞ N h = 1/(1 -2 -1/ h ).</formula><p>To meet the requirement that N h ≥ K , we thus need to choose h such that</p><formula xml:id="formula_21">h ≥ 1 -log 2 (1 -1/K ) .</formula><p>From our experiment, we found that a value of h = 40 steps is reasonable for up to K = 20 variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Measurements</head><p>We collected measurements from an internal Web serving system that is accessible worldwide. The system hosts nine different applications, serving sixteen traffic classes (or flows), denoted by A through P. The system consists of three nodes: N 1, N 2, and N 3, and a front-end proxy performing request classification, traffic management, and load balancing. The duration of measurements is approximately one day (about 21 h).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Measured data</head><p>Fig. <ref type="figure" target="#fig_0">1</ref> illustrates the throughput measurements for the four highest rate flows, labeled A, B, C, and D, respectively. Fig. <ref type="figure" target="#fig_1">2</ref> provides the CPU measurements of the three nodes in the system. When using the correlation matrix in Eq. ( <ref type="formula" target="#formula_15">8</ref>), we found four flows: A, B, C, and D, having correlation coefficients close to one, as shown in Fig. <ref type="figure" target="#fig_2">3</ref> (shown for a four-hour period). Examining the figures, we extract the following properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Traffic skewness and variations</head><p>Among the sixteen different flows, we find that the top three or four, A through D, are the most significant in terms of throughput. The remainder of the flows have very little throughput values. During a day period, the traffic intensity varies slowly, showing work periods at different time zones (mostly North America and Europe). The traffic is shaped as a ramp up phase followed by a steady phase, then a ramp down phase. Zooming in on a four-hour period (48,000 to 62,400), we observe variations in traffic intensity from a measurement cycle to the next. Note that such variations are contributing to the success of using the linear regression model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">CPU utilization</head><p>In general, the CPU utilization values are fairly low to medium. Typically, the system is engineered in a way to have ample of capacity in order to be able to cope with a surge in the traffic. Note that the CPU utilizations of the three nodes were nearly equal, except for two distinct periods where node N 2 experienced higher utilization than nodes  N 1 and N 3. The equality of CPU utilization is due to the load balancing function. The higher utilization on node N 2 is seemingly due to some background load which takes about 20% of the CPU on the node. During low utilization intervals, we observe significant noise in the CPU utilization measurement. The CPU readings during the four-hour period (48,000-62,400) are consistently equal among the three nodes, tend to be low between 10% and 20%, and vary from one measurement cycle to the next. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Traffic correlation</head><p>There is a strong correlation among some flows. Flows A, B, C, and D form a group of dependent flows. This is apparent from the pairwise correlation coefficients that are between 0.88 and 0.98. In particular, flows B and C show consistent correlation of about 0.98, suggesting that one request of flow B corresponds to a multiple number (could be one) of requests of flow C. It is this dependence among some flows that causes challenging problems when solving the linear regression problem, due to the occurrence of collinearity as discussed in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Practical considerations</head><p>In this section, we consider the traffic properties that we obtained by analyzing the measurement data and provide mechanisms to deal with such properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Insignificant flows</head><p>Typically, the flow rates λ k,m are quite variant, with some flows being so insignificant that we need to remove them from the regression problem to avoid numerical instability. We use the following criterion to identify insignificant flows. Let</p><formula xml:id="formula_22">X = (1X) /N h ,</formula><p>where 1 is a (1 × N ) identity vector and X is a (1 × K ) vector representing the average values of the columns of X. Further, let X be the L 1 norm of X. Flow k, k = 1, 2, . . . , K , with Xk / X &lt; δ, where δ is a small number, e.g. 10 -5 , is removed from the regression problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Utilization discounting</head><p>Since the data becomes more noisy when the machine CPU utilization is low, we need to discount data as the utilization decreases. Define f (ρ m ) as a discounting function of CPU utilization with values between zero and one, where zero means throw away the CPU utilization data point, one means take the CPU utilization data point as is, and a fraction means that the CPU utilization data point is multiplied by that fraction. The choice of the discounting function is arbitrary and does not impact the solution methodology presented in this paper. Hence, Eq. ( <ref type="formula" target="#formula_18">9</ref>) becomes</p><formula xml:id="formula_23">Y n = 2 (1-i)/ h f (ρ m,i )ρ m,i Ω m , X n,k = 2 (1-i)/ h f (ρ m,i )λ k,m,i .</formula><p>Based on our empirical observations, we implemented a simple, piecewise linear discounting function with f (0) = 0, f (0.2) = 2/3, and f (1) = 1. Given this utilization discounting function, one expects improved behavior of the linear regression method as the utilization increases, since such data points would have higher weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Low contribution flows</head><p>When solving linear regression problem <ref type="bibr" target="#b1">(2)</ref>, one often finds that some columns in X have minimal significant effect on Y, hence leading to improper results α. Forming a combined variable out of such subset of insignificant variables is a technique that is often used <ref type="bibr" target="#b11">[12]</ref>. We developed the following algorithm for combining flows.</p><p>-Order the elements in X in decreasing order. -Let j be the lowest index of element X j such that X j ≤ X .</p><p>-Combine flows ( j + q), ( j + q + 1), . . . , K , for some value of q ≥ 1 (we use q = 2).</p><p>-Solve regression problem with flows 1, 2, . . . , ( j + q -1) and the combined flow.</p><p>-For all p where αp fails according to the failing criterion described below, add flow p to the combined flow and re-solve problem.</p><p>The above loop is repeated a finite number of times. We chose that number to be 2q + 1. The failing criterion for flow p is: αp &lt; 0, αp represents a problem with the floating-point calculations, or g p &lt; 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Dynamic variations</head><p>Due to various kinds of noises, the αk values obtained as above are very noisy; to combat this we apply a smoothing technique, producing smoothed values αk . Let αk,r be the value of αk obtained at the r th solution of the linear regression problem, and αk,r be its smoothed value, where r = 1, 2, . . . . We use the following weighted average smoothing function</p><formula xml:id="formula_24">αk,r = P k,r /Q k,r ,<label>(10)</label></formula><p>where</p><formula xml:id="formula_25">P k,r = 2 -1/t P k,r -1 + s(g k,r ) αk,r , Q k,r = 2 -1/t Q r -1 + s(g k,r</formula><p>), P k,0 = Q k,0 = 0, t is a half-life step period, and s(g k,r ) is a function of the goodness of fit measure, g k,r , obtained for flow k at the r th solution of the linear regression problem. Based on our experimentation, we choose a piecewise linear function with s(x) = x, 0 ≤ x &lt; 20, s(x) = x/20 + 19, 20 ≤ x &lt; 100, and s(x) = 24, x ≥ 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.">Collinear flows</head><p>It is quite common to find flows with flow rates that are proportional to each other. For example, the number of login requests is usually the same as the number of logout requests. Or, every lookup request generates a photoRetrieval request. In such cases, related flows are called collinear flows since their entries in the X matrix are nearly proportional, resulting into a near-singular matrix C. Thus, the values of α obtained from equation (4) become unstable for the collinear flows. Flow rates can be effectively collinear for two kinds of reasons. One is that the client behavior links the two flows, as suggested above. The other is simpler but perhaps more common: if there is little variation in the throughput of some flows over a long period of time (compared with the aging half-life), they are trivially collinear.</p><p>There are several techniques for the detection and handling of collinear flows <ref type="bibr" target="#b11">[12]</ref>. This topic is beyond the scope of this paper. We simply state that the smoothing technique given by Eq. ( <ref type="formula" target="#formula_24">10</ref>) lessens the effect of collinearity through averaging over time. Further, the technique (described earlier) for combining flows also helps in coping with collinearity: when there are collinear flows, at least one of their fit results will often meet the failure criterion -which causes a reduction in the number of collinear flows in the regression problem (and this is iterated).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6.">Machine and process CPU</head><p>The CPU utilization ρ m for machine m is a coarse measure since it represents a collection of contributions due to a number of running processes in the system. If we imagine that every flow k is processed by a separate server that runs in a separate process, then knowing the CPU utilization measures due to these processes would partition the multivariate linear regression problem into a set of independent univariate linear regression problems. However, in practice, it may be the case that a collection of flows are processed by a single server which runs in a separate process. In such a case, having the CPU utilization of that process partitions the original multivariate linear regression problem into a set of independent, smaller-sized multivariate linear regression problems. This may yield more efficient and accurate results than having only coarse CPU utilization measures. This effect is sought later in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7.">Degrees of freedom and responsiveness</head><p>The degrees of freedom when solving the linear regression problem (2) are given by (N -K -1), where N is the number data point samples and K is the number of independent variables, α. In general, the accuracy of the results improves as the number of degrees of freedom increases. Since data samples are collected over time, then the dynamic behavior of α plays a role in deciding the number of samples N , and hence the degrees of freedom. If α is stationary, then a large N is desirable. However, in practice, the values of α change with time in reaction to many factors such as the data in the request, the state of the server, the workload on the system, and the mix of requests. Hence, one is faced with a trade-off between having a large enough N and obtaining estimates for α which are responsive to dynamic behavior. The value of N is adjusted through the selection of the sliding window size I , or the half-life period h if using the data aging technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.8.">Background noise</head><p>The CPU utilization measure is usually contaminated by noise that is not due to applications processing requests. One source of such a noise is some background work that varies slowly over time. The contribution of such a background work to the CPU utilization may be captured by adding an independent variable to α and a column of ones to the X matrix. The value of the additional variable is an estimate of the CPU cycles taken by the background work. A degenerate case arises if the CPU utilization varies little over a long period of time. In such a case, the additional α which captures the background work may be erroneously estimated. We tried this technique for characterizing the background work, and found that it often failed in this way. For this reason, we do not recommend this technique.</p><p>Another kind of background work is intermittent and quite significant when launched. Examples of such a background work are the starting and stopping of application servers. Such operations may last for tens of seconds and contribute significantly to the CPU utilization. By identifying such periods of time, one may throw out sampled data during such periods as outliers so as not to contaminate the values of α.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Experimental results</head><p>In this section we summarize the results of applying our technique in scenarios inspired by real-world usage, as illustrated in Section 5. First, we present an experiment that validates the linear model. Then, we present a baseline experiment that uses only whole-machine CPU utilization readings and no collinearity among high-power flows. We then show the results of switching to per-process CPU utilization readings. Then, we summarize the results of some tests focusing on collinearity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Validation of the linear model</head><p>In our model validation experiments, we used a micro-benchmarking servlet and program-generated requests. We created four flows on a node, each flow having a CPU utilization between 5% and 25%, the load being varied in a sinusoidal wave with different periods for the flows. The periods were 5, 10, 15, and 20 min. This yields repetitive cycles of 300 min each. We applied this load for two cycles. The CPU utilization on the node varied between 20% and 97%. The coefficient of determination, R 2 , during the experiment was between 0.996 and 0.999, hence validating our linear model. Further, the coefficient of determination was calculated for all the experiments presented in this paper,  and was between 0.996 and 0.999 for the significant flows at steady state. As expected, we did see lower values of the coefficient of determination during transients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Setup</head><p>In the following experiments we use a scenario and synthetic workload inspired by real-world usage. Our technique is available in a product used in an internal web site at our company. In our experiments we use a micro-benchmarking servlet and program-generated requests so that we can confidently say what the alphas really are; in the real-world usage the alphas are dependent on server state and request parameters that are not captured in the available traces, so we cannot provide any independent verification of the alphas. To obtain information on the evaluation of our results, we carried out off-line profiling of our synthetic workload. We next describe the scenario.</p><p>As in the real-world usage, there are 16 distinct flows of requests; we will designate the flows by the letters A through P. A diagram of the testing configuration is illustrated in Fig. <ref type="figure" target="#fig_3">4</ref>. Requests are served by application server processes. These server processes are organized into nine clusters: three clusters have two processes each, and the other six clusters have just one process each. The processes are spread across four machines (named xd008 through xd011), with three processes on each. Each machine's processing power is 4585 standard MHz. Table <ref type="table" target="#tab_0">1</ref> shows the placement for the experiments without collinearity. Table <ref type="table" target="#tab_1">2</ref> shows which flows load which clusters; we use the same relationship found in the real-world usage. This table also shows the relative magnitudes of the throughputs among those flows, exhibiting the skewness in traffic flows. Our experiments with collinearity use the same throughput proportions as the real-world usage; for the experiments without significant collinearity we collapse three flows' throughput onto B.</p><p>In our experiments the arrival process is a Poisson arrival of HTTP sessions, each of which consists of a geometrically distributed number of requests. The mean of the geometric distribution is such that when multiplied by the session arrival rate it yields the total throughput of the system. Each session's behavior is to alternately issue a request and think for a stochastic amount of time. Each request is randomly chosen from among the 16 or 14 flows in play; the probability of each flow is proportional to the desired throughput for that flow. After each think an independent choice is made of whether to terminate the session. All the arrival process parameters are identical across the flows, except for the mean session arrival rate. That is set in the proportions given in Table <ref type="table" target="#tab_1">2</ref>, and total magnitude adjusted so that the CPU utilizations on the machines are limited to roughly the 5%-40% range -which is what is observed in the real-world usage.</p><p>In our experiment we used just one micro-benchmarking servlet, whose alpha depends on request parameters, and 11 different combinations of parameters. The servlet does a controllable combination of arithmetic and sleeping. We generated the 11 combinations of parameters by: (a) using a Zipf-like distribution (the exponent was 1.0) for the parameter that controls the total amount of arithmetic done and (b) using randomly generated values for the parameters (uniform within a limited range) that control the number and length of sleeps. We did off-line profiling of those 11 different kinds of requests, and got the results in Table <ref type="table">3</ref>. In this section we quantify work factors in units of standard megacycles (std. MC).</p><p>We designed our main experiments to explore both the transient and steady-state behavior of our technique. The technique in this paper is targeted at situations where the work factors may change slowly over time. To clearly separate the transient and steady-state results, we structure our workload into a series of five, equal-length phases. During a given phase, the characteristics of the workload are constant, making it easy to examine the steady-state response of our technique. At each phase change, the workload characteristics jump abruptly to new values, making it easy to examine the transient response of our technique. This choppy aspect of the workload behavior is intentionally artificial, for the purpose of making it easy to see different aspects of the performance of our technique; we expect that real workloads change gradually. Each phase is 2 h long, so a whole experiment is 10 h long. During a given phase, a given flow makes only one of our 11 kinds of requests; this gives ample time to see whether our technique settles on a value and, if so, how accurate that value is. A given flow makes different kinds of requests in different phases; that is, we have a sharp transient at the beginning of each phase. We use five (one for each phase) randomly generated associations between flow and request kinds, as follows. Note that the last five flows (L through P) have extremely low throughputs. To give them the best chance of having an effect, in each phase we bind to them a randomly generated permutation of the five "heaviest" kinds of requests. For the remaining flows, of which there are 9 when avoiding significant collinearity and 11 when not avoiding that, in each phase we bind to those flows a randomly generated permutation of the 9 or 11 heaviest kinds of requests. Table <ref type="table" target="#tab_2">4</ref> shows these randomly generated bindings used in the experiments without significant collinearity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.">Baseline</head><p>In our first experiment we avoid significant collinearity and use only whole-machine CPU utilization readings. We divide each phase into two stages: a transient stage of 30 min, followed by a tail of 90 min. Table <ref type="table">5</ref> shows the maximum power error seen for each flow, in each stage of each phase. The power error for a flow k during period i is</p><formula xml:id="formula_26">λ k,i • | αk,i -α k,i |</formula><p>where λ k,i is the throughput averaged over that period, αk,i is the alpha estimate produced from that period, and α k,i is the true alpha for that flow at that time. Here we use periods of 1 min, as in the default configuration of the product. We focus on computational power, which can be quantified by the product of throughput and alpha, because that is what is managed by the product that uses our profiling technique. Errors in the estimated power consumption of a flow are less significant if they are smaller. The average power consumed in each phase is roughly as follows: 550 std. MHz in phase 1, 710 in phase 2, 1720 in phase 3, 620 in phase 4, and 1570 in phase 5.</p><p>Fig. <ref type="figure" target="#fig_4">5</ref> shows the smoothed alpha estimates produced, as functions of time during the experiment, for flow A. Fig. <ref type="figure" target="#fig_5">6</ref> shows the alpha estimates for flow B. Fig. <ref type="figure" target="#fig_6">7</ref> shows the estimates for flow F. Our work profiler produced estimates significantly above 1 for only A, B, and F.   Table <ref type="table" target="#tab_3">6</ref> summarizes the alpha and power results for the transient stage of phase 1. For each flow it gives: the minimum and maximum observed throughputs, as averaged over 1 min periods; the smallest and largest alpha estimates produced during that stage; the alpha derived from off-line profiling; the smallest and largest power estimates (λ k,i αk,i ) produced during that stage; and the maximum power error for that stage. Table <ref type="table">7</ref> gives the same quantities We show some traces of alpha estimates. Fig. <ref type="figure" target="#fig_7">8</ref> shows the trace for flow A, Fig. <ref type="figure" target="#fig_8">9</ref> for flow B, and Fig. <ref type="figure" target="#fig_9">10</ref> for flow J (which had relatively high-power errors).   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.">Collinearity</head><p>We next studied harder cases of collinearity. The easy case is when the collinear flows target different clusters. It is more difficult when collinear flows target the same cluster, and those flows are not combined as in Section 6.3. To study this we began by un-collapsing C and D from B. That in turn required new bindings between flow and request kinds. Table <ref type="table" target="#tab_4">11</ref> shows these bindings (which were generated in the stochastic manner outlined above). Notice that in these bindings, we never have high-power draw in two or more out of the three flows B, C, and D. We found that in this relatively nonchallenging situation, our work profiler was about as accurate as in the experiments reported earlier above.</p><p>To explore more challenging settings, we conducted further experiments with an altered placement and flow/alpha binding. Table <ref type="table" target="#tab_1">12</ref> shows that placement. Table <ref type="table" target="#tab_0">13</ref> shows the bindings for the most significant flows.</p><p>Fig. <ref type="figure" target="#fig_0">11</ref> shows the results for flows A, B, C, and D when using only whole-machine CPU readings. The curves are the on-line alpha estimates and the horizontal edges on the right-hand side of the figure represent the off-line profiled values. We note that the alpha estimates vary over time. On the average, the estimates compare well with the off-line values for flow B, they overestimate flow A and underestimate flow C. As for flow D, the variation in the estimates is quite significant due to the relative low intensity of its traffic. Fig. <ref type="figure" target="#fig_10">12</ref> shows the results for those flows when  per-process CPU readings are used. We see that the per-process utilization readings produced a better estimate for flow A and worse estimates for the others; flow A draws significantly more power than the others, so the finer granularity readings at least improved the most significant answer.</p><p>The linear fitness results for top significant clusters, C1 through C4 are provided in Fig. <ref type="figure" target="#fig_11">13</ref> where the coefficient of determination is plotted. The results exhibit consistent coefficient of determination between 0.8 and 1.0, except during phase transition, where the linear relationship is violated. The pairwise correlation coefficients, defined by Eq. ( <ref type="formula" target="#formula_15">8</ref>   enough so as to enable one to extract good values for the work factor estimates. The goodness measure is depicted in Fig. <ref type="figure" target="#fig_16">17</ref>. Note that high values of goodness correspond to steady values of the estimated work factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>We considered the problem of dynamically estimating CPU demands of applications using CPU utilization and throughput measurements. Using a linear model, we formulated the problem as a multivariate linear regression problem. We collected measurement data from a Web serving system and analyzed the data in order to extract realistic  traffic properties. We addressed those practical issues such as insignificant flows, collinear flows, space and temporal variations, and background noise. We presented on-line techniques to deal with such practical considerations. The experimental results proved that our approach is a viable one for the rough estimation of dynamic CPU demand of Web applications.</p><p>Interestingly, some of the experimental results present us with a few challenges to be considered as future enhancements. In particular, we notice a bias between the estimated and predicted demands. Further, we see that the smoothed results take minutes to respond to variations in the demand, calling for an investigation of the trade-off between precision and responsiveness. Special mechanisms to deal with collinear flows, other than just combining flows and averaging through smoothing, are needed. One viable approach is to use collinearity detection mechanisms and ridge regression <ref type="bibr" target="#b8">[9]</ref>. Capturing the background noise in CPU utilization through randomization needs further investigation. Also, scaling and standardization techniques may help with numerical stability <ref type="bibr" target="#b11">[12]</ref>.</p><p>The effects of hyper-threading need more investigation. We found that using hyper-threading has two interesting effects. One is that the machine's power is increased, but by a factor that is significantly smaller than two. The other is that the CPU utilization readings are distorted. When a hyper-threaded machine is delivering half of its maximum possible computing power, Linux reports its CPU utilization as something much less than one half. We think this distortion is due to the interaction of the hyper-threading architecture with the way the OS estimates CPU utilization (Linux 2.6.9). We characterized the distortion; it fits rather well to a polynomial of degree 3. The inverse of the distortion function also fits a degree 3 polynomial very well. We repeated experiments like those above but with hyper-threading enabled. When we used an appropriately adjusted figure for the machine's power (Ω ), and applied a correcting transformation to the CPU utilization readings, we got very similar on-line profiling results.</p><p>There are several extensions to this work. We have only considered the CPU as the bottleneck resource. In some situations, there may be multiple resources, yielding a multidimensional regression model. The complexity of our approach is dominated by a matrix inversion operation, which may be costly for a very large problem. Other approaches based on stochastic search techniques are under investigation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Throughput of service requests.</figDesc><graphic coords="7,114.20,63.64,312.12,231.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Percent CPU utilization.</figDesc><graphic coords="7,114.20,345.00,312.12,231.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Correlation coefficient among flows A, B, C, and D.</figDesc><graphic coords="8,117.93,63.64,312.12,233.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Test configuration.</figDesc><graphic coords="11,150.20,63.64,240.12,191.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Work factor estimates (in std. MC) for no collinearity, machine CPU, flow A.</figDesc><graphic coords="14,165.99,63.64,216.00,151.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Work factor estimates (in std. MC) for no collinearity, machine CPU, flow B.</figDesc><graphic coords="14,165.99,255.92,216.00,151.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Work factor estimates (in std. MC) for no collinearity, machine CPU, flow F.</figDesc><graphic coords="14,165.99,448.20,216.00,151.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Work factor estimates (std. MC) for no collinearity, process CPU, flow A.</figDesc><graphic coords="17,162.26,63.64,216.00,151.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Work factor estimates (std. MC) for no collinearity, process CPU, flow B.</figDesc><graphic coords="17,162.26,248.24,216.00,151.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Work factor estimates (std. MC) for no collinearity, process CPU, flow J .</figDesc><graphic coords="17,162.26,432.83,216.00,151.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Work factor estimate (std. MC) traces for collinearity, process CPU.</figDesc><graphic coords="19,165.14,63.64,210.24,151.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Fitness test.</figDesc><graphic coords="19,114.20,252.37,312.12,228.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>), for the collinear group consisting of flows B, C, and D, are illustrated in Fig. 14. It is apparent that the collinear group has correlation coefficient values close to one. The estimated work factors, during the five phases of the experiment, for flows A, B, C, and D are shown in Fig. 15. For the most significant flow A, the estimates are stable and track the change in work factor from phase to phase. For the less significant flow B, the estimates behaves well, but vary slightly in time. As for the least significant flows C and D, the estimates vary significantly. Applying the smoothing technique given in Eq. (10), we obtain the smoothed values for the work factor estimates depicted in Fig. 16. The smoothed estimates for flow B (and to some extent flow C) are clearer for the five phases. As for the least significant flow D, the smoothing was not sufficient</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Correlation.</figDesc><graphic coords="20,117.93,63.64,312.12,229.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Work factors.</figDesc><graphic coords="20,117.39,326.73,313.20,229.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Work factors smoothed.</figDesc><graphic coords="21,113.66,63.64,313.20,231.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Work goodness.</figDesc><graphic coords="21,114.20,328.96,312.12,228.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 Placement</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell>for experiments with no collinearity</cell><cell></cell><cell></cell></row><row><cell>xd008</cell><cell>xd009</cell><cell>xd010</cell><cell>xd011</cell></row><row><cell>C1</cell><cell>C1</cell><cell>C2</cell><cell>C2</cell></row><row><cell>C3</cell><cell>C4</cell><cell>C5</cell><cell>C3</cell></row><row><cell>C7</cell><cell>C8</cell><cell>C9</cell><cell>C6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Cluster and relative throughputs for each flow</figDesc><table><row><cell>Flow</cell><cell>Cluster</cell><cell>Relative throughput</cell><cell></cell></row><row><cell></cell><cell></cell><cell>(no collinearity)</cell><cell>(with collinearity)</cell></row><row><cell>A</cell><cell>C1</cell><cell>539,304</cell><cell>539,304</cell></row><row><cell>B</cell><cell>C2</cell><cell>398,758</cell><cell>277,823</cell></row><row><cell>C</cell><cell>C2</cell><cell></cell><cell>98,055</cell></row><row><cell>D</cell><cell>C2</cell><cell></cell><cell>22,880</cell></row><row><cell>E</cell><cell>C3</cell><cell>22,062</cell><cell>22,062</cell></row><row><cell>F</cell><cell>C4</cell><cell>18,794</cell><cell>18,794</cell></row><row><cell>G</cell><cell>C5</cell><cell>9,806</cell><cell>9,806</cell></row><row><cell>H</cell><cell>C2</cell><cell>4,086</cell><cell>4,086</cell></row><row><cell>I</cell><cell>C6</cell><cell>2,697</cell><cell>2,697</cell></row><row><cell>J</cell><cell>C7</cell><cell>2,697</cell><cell>2,697</cell></row><row><cell>K</cell><cell>C2</cell><cell>1,389</cell><cell>1,389</cell></row><row><cell>L</cell><cell>C8</cell><cell>82</cell><cell>82</cell></row><row><cell>M</cell><cell>C9</cell><cell>82</cell><cell>82</cell></row><row><cell>N</cell><cell>C9</cell><cell>82</cell><cell>82</cell></row><row><cell>O</cell><cell>C1</cell><cell>82</cell><cell>82</cell></row><row><cell>P</cell><cell>C1</cell><cell>82</cell><cell>82</cell></row><row><cell>Table 3</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Work factor for each kind of request, from off-line profiling</cell><cell></cell><cell></cell></row><row><cell>Request kind</cell><cell></cell><cell></cell><cell>Work factor</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(std. MC)</cell></row><row><cell>1</cell><cell></cell><cell></cell><cell>39.0</cell></row><row><cell>2</cell><cell></cell><cell></cell><cell>18.2</cell></row><row><cell>3</cell><cell></cell><cell></cell><cell>13.5</cell></row><row><cell>4</cell><cell></cell><cell></cell><cell>11.1</cell></row><row><cell>5</cell><cell></cell><cell></cell><cell>5.2</cell></row><row><cell>6</cell><cell></cell><cell></cell><cell>5.0</cell></row><row><cell>7</cell><cell></cell><cell></cell><cell>3.8</cell></row><row><cell>8</cell><cell></cell><cell></cell><cell>6.3</cell></row><row><cell>9</cell><cell></cell><cell></cell><cell>3.3</cell></row><row><cell>10</cell><cell></cell><cell></cell><cell>3.3</cell></row><row><cell>11</cell><cell></cell><cell></cell><cell>3.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4</head><label>4</label><figDesc>Request kind by phase and flow, no collinearity</figDesc><table><row><cell></cell><cell cols="3">Request kind for flow</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>A</cell><cell>B</cell><cell>E</cell><cell>F</cell><cell>G</cell><cell>H</cell><cell>I</cell><cell>J</cell><cell>K</cell><cell>L</cell><cell>M</cell><cell></cell><cell>N</cell><cell>O</cell><cell>P</cell></row><row><cell>Phase 1</cell><cell>8</cell><cell>4</cell><cell>9</cell><cell>3</cell><cell>7</cell><cell>6</cell><cell>2</cell><cell>5</cell><cell>1</cell><cell>5</cell><cell>1</cell><cell></cell><cell>2</cell><cell>4</cell><cell>3</cell></row><row><cell>Phase 2</cell><cell>6</cell><cell>2</cell><cell>8</cell><cell>3</cell><cell>7</cell><cell>1</cell><cell>9</cell><cell>5</cell><cell>4</cell><cell>1</cell><cell>3</cell><cell></cell><cell>2</cell><cell>5</cell><cell>4</cell></row><row><cell>Phase 3</cell><cell>1</cell><cell>4</cell><cell>5</cell><cell>9</cell><cell>8</cell><cell>6</cell><cell>3</cell><cell>7</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell></cell><cell>1</cell><cell>5</cell><cell>2</cell></row><row><cell>Phase 4</cell><cell>3</cell><cell>9</cell><cell>5</cell><cell>4</cell><cell>2</cell><cell>1</cell><cell>7</cell><cell>6</cell><cell>8</cell><cell>3</cell><cell>5</cell><cell></cell><cell>2</cell><cell>1</cell><cell>4</cell></row><row><cell>Phase 5</cell><cell>1</cell><cell>6</cell><cell>4</cell><cell>9</cell><cell>7</cell><cell>8</cell><cell>2</cell><cell>3</cell><cell>5</cell><cell>4</cell><cell>3</cell><cell></cell><cell>1</cell><cell>2</cell><cell>5</cell></row><row><cell>Table 5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Power errors for no collinearity, machine CPU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Phase</cell><cell>Stage</cell><cell cols="4">Max. power error (in std. MHz) for flow</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>A</cell><cell>B</cell><cell>E</cell><cell>F</cell><cell>G</cell><cell>H</cell><cell>I</cell><cell>J</cell><cell>K</cell><cell>L</cell><cell>M</cell><cell>N</cell><cell>O</cell><cell>P</cell></row><row><cell>1</cell><cell>Transient</cell><cell>121.55</cell><cell>87.07</cell><cell>3.90</cell><cell>17.87</cell><cell>2.12</cell><cell>1.36</cell><cell>4.30</cell><cell>1.03</cell><cell>5.28</cell><cell>0.12</cell><cell>0.63</cell><cell>0.19</cell><cell>0.22</cell><cell>0.35</cell></row><row><cell>1</cell><cell>Tail</cell><cell>56.16</cell><cell>35.37</cell><cell>4.02</cell><cell>25.53</cell><cell>2.12</cell><cell>1.49</cell><cell>4.98</cell><cell>1.15</cell><cell>5.91</cell><cell>0.09</cell><cell>0.63</cell><cell>0.38</cell><cell>0.22</cell><cell>0.35</cell></row><row><cell>2</cell><cell>Transient</cell><cell>87.16</cell><cell>242.37</cell><cell>29.45</cell><cell>28.79</cell><cell>2.15</cell><cell>12.66</cell><cell>0.54</cell><cell>0.96</cell><cell>1.46</cell><cell>0.64</cell><cell>0.14</cell><cell>0.38</cell><cell>0.07</cell><cell>0.17</cell></row><row><cell>2</cell><cell>Tail</cell><cell>68.09</cell><cell>60.36</cell><cell>57.82</cell><cell>17.79</cell><cell>2.40</cell><cell>16.21</cell><cell>0.61</cell><cell>0.98</cell><cell>1.91</cell><cell>0.85</cell><cell>0.28</cell><cell>0.38</cell><cell>0.09</cell><cell>0.22</cell></row><row><cell>3</cell><cell>Transient</cell><cell>1147.25</cell><cell>155.75</cell><cell>62.41</cell><cell>33.72</cell><cell>4.27</cell><cell>1.48</cell><cell>2.65</cell><cell>0.66</cell><cell>2.30</cell><cell>0.28</cell><cell>0.17</cell><cell>1.06</cell><cell>0.09</cell><cell>0.29</cell></row><row><cell>3</cell><cell>Tail</cell><cell>291.98</cell><cell>37.70</cell><cell>28.31</cell><cell>42.36</cell><cell>4.39</cell><cell>1.60</cell><cell>3.28</cell><cell>0.76</cell><cell>2.58</cell><cell>0.35</cell><cell>0.28</cell><cell>1.05</cell><cell>0.12</cell><cell>0.29</cell></row><row><cell>4</cell><cell>Transient</cell><cell>747.09</cell><cell>199.96</cell><cell>7.23</cell><cell>28.03</cell><cell>13.61</cell><cell>13.51</cell><cell>0.65</cell><cell>1.09</cell><cell>0.68</cell><cell>0.21</cell><cell>0.09</cell><cell>0.38</cell><cell>0.84</cell><cell>0.28</cell></row><row><cell>4</cell><cell>Tail</cell><cell>271.39</cell><cell>114.13</cell><cell>7.30</cell><cell>35.20</cell><cell>13.72</cell><cell>15.19</cell><cell>0.76</cell><cell>1.00</cell><cell>0.94</cell><cell>0.28</cell><cell>0.09</cell><cell>0.38</cell><cell>0.85</cell><cell>0.28</cell></row><row><cell>5</cell><cell>Transient</cell><cell>1027.08</cell><cell>28.51</cell><cell>16.90</cell><cell>30.75</cell><cell>2.19</cell><cell>1.80</cell><cell>4.01</cell><cell>3.12</cell><cell>0.65</cell><cell>0.17</cell><cell>0.21</cell><cell>0.63</cell><cell>0.29</cell><cell>0.12</cell></row><row><cell>5</cell><cell>Tail</cell><cell>312.11</cell><cell>68.48</cell><cell>17.06</cell><cell>37.25</cell><cell>2.32</cell><cell>1.83</cell><cell>4.87</cell><cell>3.13</cell><cell>0.61</cell><cell>0.22</cell><cell>0.21</cell><cell>0.84</cell><cell>0.38</cell><cell>0.12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6</head><label>6</label><figDesc>Results for no collinearity, machine CPU, phase 1, transient</figDesc><table><row><cell>Flow</cell><cell>λ</cell><cell></cell><cell>α</cell><cell></cell><cell></cell><cell>Power</cell><cell></cell><cell>Power err.</cell></row><row><cell></cell><cell>min.</cell><cell>max.</cell><cell>min. est.</cell><cell>max. est.</cell><cell>profiled</cell><cell>min. est.</cell><cell>max. est.</cell><cell>max.</cell></row><row><cell>A</cell><cell>31.890</cell><cell>39.168</cell><cell>7.2</cell><cell>9.4</cell><cell>6.3</cell><cell>233.102</cell><cell>365.139</cell><cell>121.548</cell></row><row><cell>B</cell><cell>24.592</cell><cell>28.533</cell><cell>10.3</cell><cell>14.2</cell><cell>11.1</cell><cell>259.229</cell><cell>395.639</cell><cell>87.068</cell></row><row><cell>E</cell><cell>1.261</cell><cell>1.694</cell><cell>1.0</cell><cell>1.0</cell><cell>3.3</cell><cell>1.261</cell><cell>1.694</cell><cell>3.897</cell></row><row><cell>F</cell><cell>1.022</cell><cell>1.430</cell><cell>1.0</cell><cell>4.6</cell><cell>13.5</cell><cell>1.022</cell><cell>5.314</cell><cell>17.872</cell></row><row><cell>G</cell><cell>0.522</cell><cell>0.755</cell><cell>1.0</cell><cell>1.0</cell><cell>3.8</cell><cell>0.522</cell><cell>0.755</cell><cell>2.115</cell></row><row><cell>H</cell><cell>0.211</cell><cell>0.339</cell><cell>1.0</cell><cell>1.0</cell><cell>5.0</cell><cell>0.211</cell><cell>0.339</cell><cell>1.356</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 11</head><label>11</label><figDesc>Request kind by phase and flow, first collinearity experiments</figDesc><table><row><cell></cell><cell cols="3">Request kind for flow</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>A</cell><cell>B</cell><cell>C</cell><cell>D</cell><cell>E</cell><cell>F</cell><cell>G</cell><cell>H</cell><cell>I</cell><cell>J</cell><cell>K</cell><cell>L</cell><cell>M</cell><cell>N</cell><cell>O</cell><cell>P</cell></row><row><cell>Phase 1</cell><cell>4</cell><cell>3</cell><cell>11</cell><cell>9</cell><cell>10</cell><cell>6</cell><cell>2</cell><cell>1</cell><cell>8</cell><cell>7</cell><cell>5</cell><cell>2</cell><cell>4</cell><cell>5</cell><cell>3</cell><cell>1</cell></row><row><cell>Phase 2</cell><cell>5</cell><cell>11</cell><cell>6</cell><cell>2</cell><cell>3</cell><cell>7</cell><cell>8</cell><cell>10</cell><cell>1</cell><cell>4</cell><cell>9</cell><cell>2</cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>4</cell></row><row><cell>Phase 3</cell><cell>8</cell><cell>1</cell><cell>9</cell><cell>3</cell><cell>5</cell><cell>2</cell><cell>11</cell><cell>7</cell><cell>10</cell><cell>4</cell><cell>6</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>1</cell></row><row><cell>Phase 4</cell><cell>10</cell><cell>6</cell><cell>5</cell><cell>11</cell><cell>7</cell><cell>2</cell><cell>8</cell><cell>3</cell><cell>4</cell><cell>9</cell><cell>1</cell><cell>3</cell><cell>2</cell><cell>4</cell><cell>1</cell><cell>5</cell></row><row><cell>Phase 5</cell><cell>1</cell><cell>11</cell><cell>6</cell><cell>7</cell><cell>10</cell><cell>3</cell><cell>4</cell><cell>2</cell><cell>9</cell><cell>8</cell><cell>5</cell><cell>2</cell><cell>1</cell><cell>5</cell><cell>4</cell><cell>3</cell></row><row><cell>Table 12</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Placement for second experiments with collinearity</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>xd008</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>xd009</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>xd010</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">xd011</cell></row><row><cell>C1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>C1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>C3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>C3</cell><cell></cell></row><row><cell>C2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>C2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>C5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>C4</cell><cell></cell></row><row><cell>C7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>C8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>C9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>C6</cell><cell></cell></row><row><cell>Table 13</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">Flow/request binding highlights for second experiments with collinearity</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Flow</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Request kind</cell></row><row><cell>A</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>4</cell><cell></cell><cell></cell></row><row><cell>B</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>3</cell><cell></cell><cell></cell></row><row><cell>C</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2</cell><cell></cell><cell></cell></row><row><cell>D</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell></row></table><note><p>Fig. 11. Work factor estimate (std. MC) traces for collinearity, machine CPU.</p></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>for the tail of phase 1. Among the five phases, phase 1 had the smallest power errors. Phase 4 had the worst power errors in its tail. Tables <ref type="table">8</ref> and<ref type="table">9</ref> show the results from the transient and tail stages of that phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.">Introducing per-process CPU readings</head><p>Our second experiment was the same as the first, except that the work profiler was configured to use perprocess CPU utilization readings. In general, we expected this would allow the profiler to produce more accurate estimates. Table <ref type="table">10</ref> shows this did not happen in our system (cf Table <ref type="table">5</ref>). In that respect, we make two important observations. In our system monitors, there was no synchronization between the throughput and utilization readings for the per-process utilization readings. In other words, the values of throughput and utilization for a data point do not necessarily completely overlap. Throughput measures are collected periodically by a node agent. Process CPU utilization measures (on Linux) are collected by using /proc/pid/task/tid/stat and summing over all tid in pid (process id), whereas in the node utilization case, the collection of throughput and utilization readings is synchronized. The other observation concerns the hardness of the problems. The first collinearity experiment was not really much harder than the whole-machine utilization-reading experiment because all the high-power flows (these were at most A, B, and E) had different placements. Inhomogeneous placement produces samples from different configurations, making it easier to disentangle the effects of multiple flows. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://www.opengroup.org/tech/management/arm/" />
		<title level="m">Application Resource Measurement -ARM</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="http://www.ibm.com/software/webservers/appserv/extend/" />
		<title level="m">IBM WebSphere Extended Deployment</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Performance criteria and measurement for a time-sharing system</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Systems Journal</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="193" to="216" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Using regression splines for software performance analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Courtois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Woodside</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WOSP&apos;00: Proceedings of the 2nd International Workshop on Software and Performance</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Web server workload characterization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dilley</surname></persName>
		</author>
		<idno>96-160</idno>
		<imprint>
			<date type="published" when="1996-12">December 1996</date>
		</imprint>
		<respStmt>
			<orgName>Hewlett-Packard Laboratories</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The elusive goal of workload characterization, Perf</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Feitelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eval. Rev</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="14" to="29" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Capacity management and demand prediction for next generation data centers</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gmach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rolia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cherkasova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kemper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWS &apos;07: Proceedings of the International IEEE Conference on Web Services</title>
		<meeting><address><addrLine>Salt Lake City, Utah</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Gmach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rolia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cherkasova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kemper</surname></persName>
		</author>
		<title level="m">Workload analysis and demand prediction of enterprise data center applications, in: IISWC &apos;07: Proceedings of the 2007 IEEE International Symposium on Workload Characterization</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ridge regression: Biased estimation for non-orthogonal problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hoerl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kennard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="55" to="67" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Parameter inference of queueing models for it systems using end-to-end measurements</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wynter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perf. Eval</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="60" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Performance management for cluster based web services</title>
		<author>
			<persName><forename type="first">G</forename><surname>Pacifici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Spreitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tantawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Youssef</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Selected Areas Commun</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O</forename><surname>Rawlings</surname></persName>
		</author>
		<title level="m">Applied Regression Analysis: A Research Tool</title>
		<meeting><address><addrLine>Pacific Grove, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Wadsworth &amp; Brooks, Cole Advanced Books &amp; Software</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Parameter estimation for performance models of distributed application systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rolia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vetland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CASCON &apos;95: Proceedings of the 1995 Conference of the Centre for Advanced Studies on Collaborative Research</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Correlating resource demand information with arm data for application services</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rolia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vetland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WOSP &apos;98: Proceedings of the 1st International Workshop on Software and Performance</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Resource access management for a utility hosting enterprise applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rolia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arlitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IFIP/IEEE International Symposium on Integrated Network Management</title>
		<meeting>the IFIP/IEEE International Symposium on Integrated Network Management</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The method of layers</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Rolia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Sevcik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="689" to="700" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Leroy</surname></persName>
		</author>
		<title level="m">Robust Regression and Outlier Detection</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley and Sons</publisher>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Load distribution for heterogeneous and non-dedicated clusters based on dynamic monitoring and differentiated services</title>
		<author>
			<persName><forename type="first">H</forename><surname>Senger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Sato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Cluster Computing</title>
		<meeting>the IEEE International Conference on Cluster Computing</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Non-parametric modelling of time-varying customer service times at a bank call centre</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Stoch. Models Bus. Ind</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="297" to="311" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sharc: Managing cpu and network bandwidth in shared clusters</title>
		<author>
			<persName><forename type="first">B</forename><surname>Urgaonkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shenoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Distributed Syst</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Resource Overbooking and Application Profiling in Shared Hosting Platforms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Urgaonkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shenoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roscoe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Workload service requirements analysis: a queueing network optimization approach</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Squillante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">W N</forename><surname>Mills</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MASCOTS &apos;02: Proceedings of 10th IEEE International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunications Systems</title>
		<meeting><address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A regression-based analytic model for dynamic resource provisioning of multi-tier applications</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cherkasova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Smirni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICAC &apos;07: Proceedings of the 4th IEEE International Conference on Autonomic Computing</title>
		<meeting><address><addrLine>Jacksonville, Florida</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Giovanni Pacifici joined IBM Research in 1995, and he is currently a Senior Manager of the Distributed Middleware Department. His research focuses on the design, prototype, and evaluation of management systems for cluster-based Web applications. Dr. Pacifici led the research team that pioneered the distributed resource management technology of IBM WebSphere Extended Deployment. Before joining IBM, Dr. Pacifici was a Research Scientist at the Center for Telecommunications Research at the Columbia University. He received the &quot;Laurea&quot; in Electrical Engineering and the &quot;Research Doctorate&quot; in Information Science and Telecommunications from the University of Rome</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Woodside</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Litoiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Iszlai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">La Sapienza&quot; in 1984 and 1989 respectively. Dr. Pacifici was the Technical Program Co-Chair for IEEE Infocom 2001 and the Technical Program Co-Chair for the Fourth IFIP/IEEE International Conference on Management of Multimedia Networks and Services</title>
		<meeting><address><addrLine>Toronto, Ontario; Yorktown Heights, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>Lately he has been working on performance management of clustered services. in the context of the WebSphere Application Server product line. He previously worked at the Xerox Palo Alto Research Center; notable projects there included the Bayou peer-to-peer database and Inter-Language Unification (ILU). He completed his Computer Science Ph.D. at Stanford in 1989, on the subject of VLSI design aids</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">He received his Ph.D. degree in computer science from Rutgers University in 1982. His fields of interest include performance modeling and analysis, multimedia systems, mobile computing and communications, telecommunication services, and high-speed networking. He is a senior member of IEEE and a member of ACM, IFIP WG 6.7 and IFIP WG 7.3, and served as an ACM national lecturer</title>
		<imprint>
			<publisher>Watson Research Center</publisher>
			<pubPlace>Yorktown Heights, NY</pubPlace>
		</imprint>
	</monogr>
	<note>Asser Tantawi is a research staff member at the IBM Thomas J. and an associate editor of the International Journal of Computers and Their Applications</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
