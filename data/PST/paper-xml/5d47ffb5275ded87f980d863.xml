<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pervasive and Mobile Computing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-06-04">4 June 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Elena</forename><surname>Vildjiounaite</surname></persName>
							<email>elena.vildjiounite@vtt.fi</email>
							<affiliation key="aff0">
								<orgName type="institution">VTT Technical Research Centre of Finland</orgName>
								<address>
									<addrLine>K?itov?yl? 1</addrLine>
									<postCode>90570</postCode>
									<settlement>Oulu</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ville</forename><surname>Huotari</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">VTT Technical Research Centre of Finland</orgName>
								<address>
									<addrLine>K?itov?yl? 1</addrLine>
									<postCode>90570</postCode>
									<settlement>Oulu</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Johanna</forename><surname>Kallio</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">VTT Technical Research Centre of Finland</orgName>
								<address>
									<addrLine>K?itov?yl? 1</addrLine>
									<postCode>90570</postCode>
									<settlement>Oulu</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vesa</forename><surname>Kyll?nen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">VTT Technical Research Centre of Finland</orgName>
								<address>
									<addrLine>K?itov?yl? 1</addrLine>
									<postCode>90570</postCode>
									<settlement>Oulu</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marja</forename><surname>M?kel?</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">VTT Technical Research Centre of Finland</orgName>
								<address>
									<addrLine>K?itov?yl? 1</addrLine>
									<postCode>90570</postCode>
									<settlement>Oulu</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Georgy</forename><surname>Gimel'farb</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The University of Auckland</orgName>
								<address>
									<addrLine>Private Bag 92019</addrLine>
									<postCode>1149</postCode>
									<settlement>Auckland</settlement>
									<country key="NZ">New Zealand</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pervasive and Mobile Computing</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-06-04">4 June 2019</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1016/j.pmcj.2019.05.009</idno>
					<note type="submission">Received 20 September 2017 Received in revised form 20 March 2019 Accepted 30 May 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Stress is the second most frequent work-related health problem in Europe, and it is important to assess stress risks relatively early to diminish negative consequences. Automatic detection of everyday stress is a challenging problem, however, as both stress perception and stress manifestation notably vary between individuals. Therefore stress detectors, trained on data of each person separately, usually achieve notably higher accuracies than non-personalised ones. Unfortunately, this accuracy gain requires collecting too large sets of labelled training data to realistically obtain from end users. In addition, the majority of current stress detectors exploit physiological or mobile phone data: the latter approach increases battery consumption compare with normal phone use, and the former requires to wear additional devices and to charge their batteries. Unlike previous work, this work proposes genuinely unobtrusive personalised stress detection system, based on use of environmental sensors and unsupervised training of hidden Markov models (HMM) classifier and hence requiring neither sensor maintenance nor data labelling efforts from end users. In the experiments with real life behavioural data of office workers, collected during 10 months, the proposed system achieved 67% accuracy of classifying each day as stressful vs. normal and 95% accuracy in classifying months, thanks to discovery of novel characteristics of motion trajectories, indicative of stress.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Stress is the reason for at least half of lost working days in European enterprises, and it is important to detect stress relatively early <ref type="bibr">[1]</ref>. Then certain preventive measures could be taken, for example, a stressed person may be offered a relaxation programme, or some of his/ her tasks may be delegated to less busy colleagues. Hence recently development of stress detection methods, suitable for real life settings, became an active research area. Two main research directions are analysis of physiological data (e.g., heart rate, skin conductance, respiration, pupil diameter etc.) and analysis of behavioural data (e.g., mobile phone usage, posture, facial expressions, computer keyboard/ mouse usage, motion, social communications etc.) <ref type="bibr">[1]</ref>. To date, main sources of behavioural data in field studies were mobile phones and microphones, whereas use of cameras and other environmental sensors was mainly studied in the labs. Methods, developed for lab data, cannot be directly used in real life, though. Lab studies typically last a few hours and thus mainly aim at detecting short periods of intense mental work, whereas in real life stress can be caused, among other factors, by insufficient variety of work <ref type="bibr" target="#b1">[2]</ref>, which is closer to lack of intense mental work than to its excess. In addition, in the labs test subjects are always positioned conveniently for the cameras, but in real life sensors should be positioned conveniently for the users, which inevitably results in occlusions.</p><p>Methods to use physiological data for stress detection cannot be directly transferred from the labs to real life settings either. Various daily life activities (eating, drinking, caffeine intake, conversation, motion etc.) influence physiological parameters <ref type="bibr" target="#b2">[3]</ref>; physical motion causes also device shifts, notably deteriorating data quality. For example, in a recent study each test subject was wearing two wrist devices during one month, but collected physiological data only allowed to classify test subjects into two groups: more and less stress-prone individuals <ref type="bibr" target="#b3">[4]</ref>. One more real life challenge is the fact that stress perception is highly subjective <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref> and stress manifestation in physiological and behavioural data is also distinct to every individual <ref type="bibr">[1]</ref>, that's why in many lab tests <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref> and field studies <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref> person-specific stress recognition models achieved significantly higher accuracy than general models (i.e., models, trained on data of many subjects and not adapted to each individual). In case of using behavioural data average differences between accuracies of personal and general models may exceed 20%, but to date, such accuracy gains were achieved by fully supervised training, requiring fairly large sets of labelled data (nearly 100 self-reports were obtained from each subject in <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12]</ref>). This is quite big effort considering that human behaviour evolves with time and thus stress detection models should be periodically updated to adapt to such changes. Test subjects rarely provide large numbers of self-reports even once: for example, Adams et al. <ref type="bibr" target="#b15">[16]</ref> observed that test subjects on average respond to less than one third of system prompts. Thus realistic stress detectors should not require end users to provide self-reports in large quantities, but the majority of existing studies nevertheless employed fully supervised machine learning methods.</p><p>As it is hardly possible to train ''one-fits-all'' model of normal behaviour and ''one-fits-all'' model of stressed behaviour, behaviour-based stress detectors should be person-specific, but should be trained using little or no labelled data, in contrast to the current practice to employ fully supervised classifiers. To date, however, only a few works proposed methods to reduce the need in labelled data of each target user. The majority of them use labelled data of similar persons to obtain stress detector for the target user, but this approach does not work well if a target user is insufficiently similar to other persons or if chosen number of similar subjects is not optimal <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b14">15]</ref>. Unsupervised stress detection was studied in <ref type="bibr" target="#b16">[17]</ref>: stress was detected as temporal deviation from normal HRV (heart rate variability) data, and periods of high physical activity were excluded on the basis of accelerometer data. Vildjiounaite et al. <ref type="bibr" target="#b17">[18]</ref> proposed unsupervised method to detect stress as anomaly, but only high intensity stress was recognised this way. As long-lasting stress of low intensity may have equal or greater impact on health as a short-term high stress <ref type="bibr" target="#b18">[19]</ref>, recognition of just high stress does not suffice for long-term wellbeing monitoring.</p><p>The main contribution of this work is the following: first, it suggests a realistic setup of depth cameras for real offices, where workers do not sit all the time near a single computer and where furniture obstructs view on a whole body. This setup is also fairly privacy-safe because depth cameras do not point at faces of the test subjects; instead, depth cameras are positioned in the offices under the ceiling so that they have top-view side-view of the monitored subjects and detect nothing but head trajectories. Second, this work compares various characteristics of motion trajectories and suggests novel features, indicative of stress. Then this work confirms the feasibility of the proposed unsupervised method to learn person-specific stress recognition models by presenting results of ten-month-long monitoring of three different offices: a single-occupancy one and two double-occupancy offices. In one of these double-occupancy offices only one person was monitored, whereas in another office both occupants were monitored by a single depth camera. Experimental results demonstrate the ability of the proposed approach to detect stress of individuals with different work duties (senior researchers and organisational managers) and different stress perceptions (percentage of stressful days ranged from 23% to 51% for different subjects despite they all had challenging tasks). To the best of our knowledge, this is the first long-term real life study into unsupervised stress recognition using motion trajectories, acquired from depth cameras.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Although physiological sensors have a potential for just-in-time stress detection, existing devices are not yet mature for long-term everyday use <ref type="bibr">[1]</ref>. Hence the majority of real life studies, performed to date, employed mobile phone as the only sensor <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref>. This approach does not bother end users with any extra gadgets, but data collection may quickly drain phone battery <ref type="bibr" target="#b22">[23]</ref>. Use of environmental sensors instead of, or in addition to, mobile phones would help to reduce phone battery consumption and/ or to increase stress detection accuracy. To date, however, only studies into stress detection using audio <ref type="bibr" target="#b5">[6]</ref> and keyboard/ mouse <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b23">24]</ref> modalities collected real life data, but audio analysis would not work for the users who talk only occasionally. In addition, both audio analysis and keyboard/ mouse usage logging may be perceived as privacy-threatening. Other behavioural modalities were studied only in the labs: postures <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b24">25]</ref>, gestures <ref type="bibr" target="#b6">[7]</ref>, facial expressions and eye gaze <ref type="bibr" target="#b7">[8]</ref> etc. In lab studies stress is usually induced by giving test subjects relatively short tasks that are preceded by a relaxation phase; hence, lab conditions do not well represent long strenuous days at work. Furthermore, in real life humans behave in greater varieties of ways than during lab tests.</p><p>Obtaining stress labels in real life is also more difficult than in a lab, but nevertheless the majority of existing stress detectors are trained in fully supervised way <ref type="bibr">[1]</ref>. Even studies, employing minimally invasive devices -mobile phones alone -employed supervised algorithms, most popular being SVM (Support Vector Machine) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">26]</ref>, Na?ve Bayes <ref type="bibr" target="#b12">[13]</ref> and decision trees <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b25">26]</ref>. Only a few methods to reduce the need in labelled data of each target user were proposed to date, and the majority of them use labelled data of non-target individuals for this purpose. One proposed approach is to cluster similar persons and to train a separate model for each cluster. Then a small quantity of labelled or unlabelled data of each target person is used to determine the most appropriate cluster. Studies into analysis of audio <ref type="bibr" target="#b5">[6]</ref> and physiological data <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref> used unlabelled data of a target individual for this purpose, whereas behavioural data-based clustering <ref type="bibr" target="#b12">[13]</ref> required also a fairly large set of labelled data of a target individual: self-reports were collected three times per workday during approximately four weeks. In <ref type="bibr" target="#b12">[13]</ref> number of clusters was selected by assessing clustering quality, whereas Xu et al. <ref type="bibr" target="#b10">[11]</ref> compared accuracies, achieved with different numbers of clusters, and reported that similaritybased approach outperformed general model only in case of using two clusters; use of larger number of clusters resulted in lower accuracies.</p><p>Maxhumi et al. <ref type="bibr" target="#b14">[15]</ref> compared three other ways to reduce the need in labelled data of the target individual: (1) training using only a small set of labelled data of the target person; (2) training using a mixture of the target person data and data of similar individuals; (3) combining outputs of models of similar individuals. Training sets, used in the former case, were not so small, however: they contained self-reports, collected three times per workday during approximately four weeks. Nevertheless this labelling effort appeared insufficient for supervised training: on average, this approach achieved 62% accuracy in distinguishing between three stress levels (low, medium, high). Training on a mixed dataset (second approach) allowed to increase accuracy by 1% in one case: when data of just one nearest neighbour were used in training, and these data were sampled according to the similarity to the target person. Use of all data of the nearest neighbour, as well as use of greater number of nearest neighbours, resulted in decreased accuracy. Third way (combining outputs of models of similar individuals) allowed to increase an average accuracy by 10%, but only when outputs of models of three most similar persons were combined via weighted sum rule, weights being dependent on distances from the target person. Using other numbers of similar persons resulted in lower accuracy, and combination of outputs of similar models via voting rule resulted in only 50% accuracy.</p><p>One more way to reduce the need in labelled data of a target person is to train a general model using data of other persons and to adapt it to the target person using relatively small number of his/ her labelled samples <ref type="bibr" target="#b26">[27]</ref>. To date, suitability of this approach to the stress detection task was studied only for audio and physiological data in case of supervised training of general models. Hernandez et al. <ref type="bibr" target="#b5">[6]</ref> proposed to incorporate into SVM class priors, reflecting individual tendency to report more or less stressful events. Shi et al. <ref type="bibr" target="#b9">[10]</ref> instead trained SVM on data, normalised in person-specific way. This normalisation was performed by subtracting from raw physiological data of each individual his/ her average values in neutral state.</p><p>To summarise, none of the proposed to date approaches to reduce the need in labelled data of a target person eliminated the need to obtain labelled data of many other persons in large quantities. Methods to reuse behavioural data of other individuals, proposed to date, additionally required to collect labelled data of a target person for about one month.</p><p>Unsupervised stress detection approaches, proposed to date, detect stress as a deviation from normal condition. For example, in <ref type="bibr" target="#b16">[17]</ref> current heart rate was considered as indicator of arousal onset if difference between the current heart rate and heart rate average over last three minutes exceeded certain threshold, calculated dynamically on the basis of accelerometer data in order to take into account influence of physical activities. Our algorithm also estimates deviations between current and usual behavioural patterns; however, as human behaviour varies a lot, building a model of ''normal human behaviour'' is trickier task than calculating an average heart rate. Hence in this initial study we detected stress on daily basis, moreover that office workers in our study spent a lot of time in meetings outside of their offices.</p><p>Our approach is built upon method, proposed for unsupervised detection of illnesses of the elderly in <ref type="bibr" target="#b27">[28]</ref>: to train HMM (Hidden Markov Model) classifier to map motion features, extracted from depth camera data, into hidden states of the model, and to classify the obtained sequence of states as normal vs. anomalous. A similar approach was employed for detecting high intensity stress on the basis of accelerometer, physiological and mobile phone data in <ref type="bibr" target="#b17">[18]</ref>. Both works <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b27">28]</ref> looked for anomalies in the data as neither illnesses nor high intensity stress occur as frequently as normal conditions, whereas our current work aims at detecting stress both in cases when it occurs rarely and often. In addition, choice of data features in <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b27">28]</ref> was based on reports of multiple previous studies, stating that illnesses of the elderly display themselves in lower physical activity levels of the subjects and that stress manifests itself in lower physical activity level and HRV values, as well as in decreased usage of mobile phones. As this work is the first study into stress detection on the basis of motion trajectories in real offices, no recommendations regarding possible differences between trajectories of stressed and non-stressed humans were available, and we had to find appropriate trajectory features.</p><p>Previous studies provided just a few hints regarding choice of features. Posture data were collected in a lab, where test subjects performed relatively short-term cognitive tasks. In <ref type="bibr" target="#b6">[7]</ref> test subjects were standing during data collection, the subjects in <ref type="bibr" target="#b24">[25]</ref> were sitting, but both works reported that for the majority of subjects stress is characterised by increased quantity of motion, such as posture changes. Koldijk et al. <ref type="bibr" target="#b7">[8]</ref> recorded test subjects, performing typical knowledge work (making presentations, reading e-mail, searching for information etc.) for about three hours and observed that body motion changes during more difficult tasks, but in person-dependent way: for example, some persons sit still during difficult tasks. Garcia-Ceja et al. <ref type="bibr" target="#b12">[13]</ref> detected stress using accelerometer data, collected during normal course of office work, and listed entropy of acceleration magnitude among other features, having a good potential for stress recognition. These results suggest that features, related to quantity of motion, may be indicative of stress.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">System overview</head><p>In real offices furniture and visitors may obstruct camera view on the bodies of the monitored persons, whereas pointing cameras at a face may be perceived as privacy-threatening; besides, pointing cameras at a face would not help if the monitored subject moves away from the computer to read a document or to talk to visitors. Therefore we placed depth cameras near the ceiling so that their fields of view cover not only parts of offices where the monitored persons sit, but also parts where they walk and receive visitors. Fig. <ref type="figure" target="#fig_0">1</ref> demonstrates camera view in an office where two subjects were monitored by a single depth camera; it shows that the subjects' bodies are largely obstructed by the furniture; frequent visitors to this office obstructed the view even more. Therefore we decided against detailed analysis of postures and acquired only head trajectories because the top-view cameras detect heads more reliably than any other body parts.</p><p>A framework of data flow and services, developed for depth camera-based office monitoring, is presented in Fig. <ref type="figure" target="#fig_1">2</ref>. The main blocks are described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Depth sensor-based object detection service</head><p>Depth cameras: as offices in our study were fairly small, it was sufficient to monitor each office by a single depth camera: Orbbec Astra Pro depth sensor [29] that provides tracking range up to 8 m. In each office depth cameras were attached to the ceiling.</p><p>Tracker platform: can be a laptop or a low-cost computing device; in this study we used laptops.</p><p>Tracking software: analyses depth data and outputs locations of detected objects along with timestamps. When tracking software is started for the first time, it creates a detection plane, so that objects of interest can be differentiated from this plane. In this installation the detection plane was created automatically: the tracker was searching for the largest rectangle of points of approximately the same height and then was marking that rectangle as the floor. After that the tracking software can calculate distances between depth cloud points, located in the detection plane (the floor), and heights of humans and office equipment. This process is called calibration.</p><p>After calibration the tracking software creates a background model. The background model allows to differentiate between static objects and humans; it is built by accumulating several frames (usually, 20 frames) to get a 3D point cloud of a scene and to produce its height map. The background model is adaptive in order to accommodate added or removed static objects, for example, to separate movable office chairs from humans. Adaptation of the background model is performed dynamically as follows: each new object is initially treated as object of interest, but if a tracker detects that this object was stationary for a specific period, it accumulates a new 3D point cloud in object region during several frames, updates the background model of this region and smooth the overall background model. Background model is updated in the same way when some object is removed.</p><p>Object detection is performed by converting each depth frame into a height map and then subtracting the background model from it. Clusters of points, differing from the background, are further processed by locating their local height maxima and removing pixels which height is not sufficiently close to the maxima. As a result, the detection time and location is saved. These timestamped detection data are then output to the Human Tracking data service.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Human tracking data service</head><p>Detection processing is done as follows: timestamped detection data are processed in time sequences in order to produce trajectories of different persons, handle occlusions (i.e., to re-identify a lost track) and to discard false detections (e.g., due to light reflections). First, large blobs of detection data are divided into several smaller ones, which helps to separate people standing very close to each other, but may also result in dividing a person with an extended arm into separate objects. Then, Kalman filter is applied to ensure the best matches between objects, detected in consecutive frames, and eliminate new false objects. Matching objects is performed as follows: if an object is detected within a pre-defined distance from existing track in a previous frame/field of view, its position is assumed to be continuation of the same track. If a track was recently lost (a pre-defined time threshold is used for deciding whether to discard lost tracks or to attempt at their re-identification), its continuation is searched for within a larger distance. In case of multiple possible matches, height from detection plane and Kalman filter-based estimation of the tracks' states is used for their re-identification. Other tracks are labelled as newly detected. As a result, detection processing module constructs track objects with unique identifier (ID of the track object) and current spatial information (position (x, y), height (z) and velocity) for each detection frame. Detection processing module outputs track objects 10 frames per second.</p><p>Database: provides storage and filtering of track objects. Track objects are stored along with predefined metadata, such as Object Detection Service location. Location name can be chosen arbitrarily, therefore allowing for data anonymisation. Database allows to easily filter track objects using various filters, such as length of the track, movement area of the track, track age, track date, Object Detection Service location etc. Filtering by track length and movement area, for example, helps to discard tracks that are caused by light reflections, if such tracks were not discarded at the earlier processing stages. Filtering by time and location allows to build context-and person-specific behavioural models.</p><p>Web server: allows to request tracking data over HTTP to analyse it and to monitor data quality and system maintenance needs (e.g., to check whether depth cameras were accidentally dislocated or disconnected) unobtrusively for the monitored subjects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Analysis service</head><p>Client software: allows to retrieve the data from the Web server. There can be any number of client software for one Human Tracking Data Service, providing for interchangeable use of different analysis and visualisation methods, as well as plugins, allowing system administrators to check current system status remotely. In this study two types of client software were used:</p><p>? to check whether all components of the framework are working properly;</p><p>? to input track data to the analysis software.</p><p>Analysis software consists of two main components:</p><p>? algorithms for processing track data (in this study, algorithms for stress assessment, described in the Stress Detection Algorithm section below) ? visualisation software (software for visualising track data, e.g., for producing heatmaps, and software for visualising results of stress detection algorithms).</p><p>For visualisation of track data we employed a 2D histogram heatmap with visualised X and Y locations for all tracks for one day. Visualisation of track data is very helpful for algorithm developers: for example, if some normal day was erroneously classified as a stressful day, heatmaps might allow to understand the reason. More details about usefulness of heatmaps are provided in ''Differences between Test Persons'' section. Results of stress detection algorithms were visualised in a form of graphs of stress scores and stress labels, see Experimental Results section.</p><p>The main benefit of this architecture is the loose coupling of the software components. In this way, each part can be developed individually, as long as data interfaces remain unchanged. This allows to monitor multiple spaces with multiple depth cameras and to employ multiple analysis services, but in this study it was sufficient to monitor each of three offices with a single depth camera and to use a single data analysis machine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Stress detection algorithm</head><p>All studies into stress recognition on the basis of behavioural data, comparing person-specific and general models, reported that the former achieved notably higher accuracies; hence, we also train person-specific stress detection models. As in real offices activities of human beings vary more notably than in the lab studies (for example, office workers may have many informal meetings in own offices or spend a lot of time in meetings outside their offices), in this study we only aim at evaluating the whole day as stressful vs. normal. Following the work <ref type="bibr" target="#b27">[28]</ref>, we model human behaviour during a day with HMM, and we represent each day by a sequence of overlapping time windows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Unsupervised hidden Markov model training</head><p>We model each working day as a sequence of time windows W. Features, extracted from each window, serve as HMM observations. Fig. <ref type="figure" target="#fig_2">3</ref> illustrates how one observation for feature Fi is created. Features are described below in the Section ''Trajectory-Based Behavioural Features''. Chair of User1: Location of the office chair of user User1, estimated from the ''hot spots'' of the office. In order to find hot spots, we divide monitored area into cells and count number of trajectories passing through each cell, as Fig. <ref type="figure" target="#fig_4">4</ref> illustrates; cells with the largest numbers of tracks are called ''hot spots''. First, ''hot spots'' are found using all recorded trajectories of all days (Dj, DL, DM etc.). Then we find groups of the co-located ''hottest spots''. In case of single-user office, we assume that the ''hottest area'' denotes location of his/ her office chair. In case of two users sharing the same office, we take two topmost ''hot areas'', separated by a distance over two metres (in our offices, individuals are not sitting very close to each other). These areas are assumed to be locations of Chair of User1 and Chair of User2. Thus we assume that office chair of each user is located in the area, visited by this user more often than other areas in the office.</p><p>Data of User1 from Day j: Trajectories, obtained in the monitored office during day Dj and selected as belonging to user User1. In order to distinguish trajectories of User1 from trajectories of his/ her room-mates and visitors, we first find location of the Chair of User1 as described above. Then we discard all tracks, not starting and not ending around the chair. We have to select trajectories of each monitored user this way because the employed depth camera-based tracker does not recognise faces. Differentiating by height is not possible either because heights of the monitored subjects do not necessarily differ from the heights of the visitors and neighbours. The employed selection of trajectories is not very accurate, but this inaccuracy facilitates user acceptance, as the main worry of the monitored subjects was whether the system is able to identify each person or not. In other words, a reference model for window W1 is a model of average behaviour of the monitored individual during this time of the day. The main motivation for building reference models is an assumption that behaviour of an individual in a stressed state deviates from his/ her behaviour in normal state and thus a model of normal behaviour should help to detect such deviations. As we employ unsupervised learning, we cannot use only normal days for building a model of normal behaviour; thus, we build a model of an average behaviour instead. If number of normal days in the data notably exceeds number of stressful days, such model is close to model of normal behaviour. If this is not the case, performance of this approach should deteriorate, but as our test results show, it nevertheless works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data of User1 from</head><p>Let V W :i,j be normalised (by min-max normalisation) value of behavioural feature i, obtained for window W at day j: for example, normalised value of Fi-Dj-W1. Then a reference value V RWi of behavioural feature number i for time window W is calculated according to formula <ref type="bibr">(1)</ref>, where m is number of days in the training dataset.</p><formula xml:id="formula_0">V RWi = 1 m m ? j=1 V W:i,j<label>(1)</label></formula><p>After creating reference models, for each value V W :i,j we calculate its deviation D W :i from the corresponding reference model according to formula (2):</p><formula xml:id="formula_1">D W :i = V W:i -V RWi (2)</formula><p>Then we discretise each value D W:i by dividing an interval [-1, 1] into several sub-intervals and use the sub-interval's number as an observation in the HMM. The discretised value of feature Fi, obtained for day Dj and window W1, is represented in Fig. <ref type="figure" target="#fig_2">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>as D-Fi-Dj-W1.</head><p>Then this process is repeated for all windows of the same day, and the obtained sequence of the discretised deviations of window features from the corresponding reference values is used a sequence of the HMM observations for this day. Then this process is repeated for all other days in the training dataset, and HMM model is trained on the obtained sequences. Training is unsupervised, by applying the conventional Baum-Welch forward-backward algorithm <ref type="bibr">[Rabiner 1986</ref>]. In other words, we do not use any labels in training, and mapping of deviations from usual behaviour into output classes does not require defining any thresholds: it is learned from training data. Baum-Welch algorithm, however, allows to assign initial probabilities to different states. Training process modifies initial probabilities, and the change can be very notable, but nevertheless swapping of probabilities does not happen very often. Therefore if initial probabilities of observing a feature value O 1 in states S 1 and S 3 were set to 0 and 1 respectively, usually after training the probability of observing feature value O 1 in the state S 1 will be lower than that in the state S 3 .</p><p>We employed HMM with three hidden states in this work and assigned initial probabilities as follows: the highest probabilities of observing large positive deviations of current features from reference models were assigned to the state S 1 ; the highest probabilities of observing large negative deviations of current features from reference models were assigned to the state S 3 ; and medium probabilities were assigned to the state S 2 . This initial assignment was done in order to allow consistent calculation of stress scores (described in ''Inference with Hidden Markov Models'' Section) and to facilitate understanding of correlations between features and stress.</p><p>In these initial study into stress detection from motion trajectories we trained a separate HMM model for each feature. HMM model for feature i is named HMM-Fi in Fig. <ref type="figure" target="#fig_2">3</ref>. As features are extracted from data of each user separately, all reference models and all HMM models are person-specific. HMM-Fi is the trained HMM model for feature Fi. To answer research question Q1, we compared HMM models, trained on various features (features are described in ''Trajectory-Based Behavioural Features'' Section).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Inference with hidden Markov models</head><p>Based on a sequence of observations, calculated for this day, we obtain a sequence of the hidden states from each model HMM-Fi. We employ the Bayesian MPM (maximum posterior marginal) decision rule that selects for each time moment the hidden state with the maximum posterior marginal probability. An alternative, more conventional, approach would be to employ the Bayesian maximum a posteriori (MAP) decision rule using the well-known Viterbi dynamic programming algorithm <ref type="bibr">[Rabiner 1986</ref>] for inferring a sequence of the hidden with. The MAP approach to minimising the error probability assumes that the cost of errors for a given sequence of observation is just the same, irrespectively of their number (i.e., a single erroneous state is as bad as any other number of errors), whereas the MPM approach minimises the expected number of errors. MPM rule was shown to suit better to human behaviour analysis in three studies comparing accuracies of MPM and MAP rules: (1) detection of emotions of the show audience <ref type="bibr" target="#b28">[30]</ref>; (2) detection of illnesses of the elderly <ref type="bibr" target="#b27">[28]</ref> and (3) stress detection on the basis of mobile phone and wrist device data <ref type="bibr" target="#b17">[18]</ref>.</p><p>Day Score: Calculation of a ''stress score'' A of the day, based on the obtained sequence of hidden states. Typically, when HMM are employed for anomaly detection, a score of a sequence of hidden states is assumed to be proportional to the likelihood of this sequence (the lower the likelihood, the less normal the sequence). Hence in this conventional method the order of recovered hidden states strongly affects the score. In real work, however, human tasks vary a lot (e.g., meetings are not scheduled every day at the same time), and whether a morning is more hectic than the afternoon, or vice versa, should not necessarily matter. Therefore we calculate a stress score of each day by assigning numerical scores A W to the recovered hidden states of time windows W. For HMM with three hidden states we assigned numerical scores according to formula (3):</p><formula xml:id="formula_2">A W = ? ? ? 1, if time window W is classified as S 1 0, if time window W is classified as S 2 -1, if time window W is classified as S 3 (3)</formula><p>Then the day score A is calculated according to formula (4), where L is number of day windows:</p><formula xml:id="formula_3">A = 1 L L ? W =1 A W (4)</formula><p>For example, the stress score of a sequence ''S 2 S 2 S 3 S 1 '' is</p><formula xml:id="formula_4">A = 0 + 0 -1 + 1 4 = 0.</formula><p>Due to assignment of initial probabilities so that state S 1 was a state with the highest probabilities of observing large positive deviations of current features from reference models, positive day score means that values of input features notably exceeded the corresponding reference values during the majority of day windows. Similarly, as state S 3 was a state with the highest probabilities of observing large negative deviations of current features from reference values, negative day score means that values of input features were notably lower than the corresponding reference values during the majority of day windows.</p><p>For example, let feature Fi be a cumulative presence time in the office. Then calculation of day score according to formulas (2) and ( <ref type="formula">4</ref>) would allow to differentiate between stressful and normal days if during the former the monitored persons were staying longer or shorter in their offices than during the latter. Days vary also by distributions of presence times between day windows: if a user has private appointments or work meetings, during some windows he/ she will be present in the office for shorter time periods than during other windows. Hence another method to calculate day score is to assign numerical scores A W +1,W to transitions between recovered hidden state W+1 and the previous state W as follows:</p><p>A W +1,W = abs (kj) if window W + 1 is classified as S k and window W is classified as S j <ref type="bibr" target="#b4">(5)</ref> Then a day score is calculated according to formula (6):</p><formula xml:id="formula_5">A = 1 L -1 L-1 ? W =1 A W +1,W<label>(6)</label></formula><p>In this case the stress score of a sequence ''S 3 S 1 S 1 S 2 '' is</p><formula xml:id="formula_6">A = (3 -1) + (1 -1) + (2 -1) 3 = 1 .</formula><p>Comparison between different ways to calculate stress scores was performed in order to answer research question Q2, especially the following aspect: whether stress displays itself more prominently in increase/ decrease of feature values, or in increase/ decrease in variations of feature values? In the former case, formula (4) should work better, while in the latter case formula (6) should work better.</p><p>Decision: Calculation of decision threshold TA as a borderline between ''stressful'' and ''normal'' days and making classification decision. Although in the proposed method all HMM model parameters are learned from the data, we need decision threshold to classify a day score as ''stressful'' vs. ''normal''. We experimented with two types of thresholds:</p><formula xml:id="formula_7">TA 1 = Mean A + w * SD A (7) TA 2 = Mean A -w * SD A (8)</formula><p>where Mean A and SD A are mean and standard deviation of days scores A respectively, and w is a weight, specifying to which degree a day score should be an outlier to denote stress.</p><p>Comparison of these two thresholds was performed to answer research question Q3, namely, two aspects:</p><p>are stressful days prominent outliers in the data, or not? If they were prominent outliers, greater w values would work better.</p><p>are stressful days characterised by higher or lower day scores? For example, let feature Fi be a cumulative presence time in the office. Then, are stressful days characterised by longer presence in the office (e.g., a person had to stay late because of a deadline), or by shorter presence (e.g., a person had to work very intensely because he/ she had to leave early)? In the former case, threshold TA 1 would work better, while in the latter case threshold TA 2 would work better. Alternatively, if stress score is calculated according to formula <ref type="bibr" target="#b5">(6)</ref>, are stressful days more often characterised by high variations of presence times between day windows, or by low variations (e.g., sitting in the office all the time)?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Trajectory-based behavioural features</head><p>Previous long-term stress detection studies in offices only collected acceleration data, whereas depth camera data based stress detection studies evaluated posture changes during fairly short-term lab experiments, when the monitored subjects were bound to stay in the same place all the time. The lab studies observed that quantity of motion, e.g., number of posture changes, is correlated with stress <ref type="bibr" target="#b6">[7]</ref>, but the found correlation was not the same for everybody: some subjects moved more during difficult tasks, whereas some other subjects moved less <ref type="bibr" target="#b24">[25]</ref>. Whether stress causes the monitored subjects to walk around a lab or a corridor, was not studied.</p><p>Therefore we studied which motion features may indicate stress in real life. For example, stress may be caused by the need to attend many physical meetings, by the need to deal with several problems simultaneously (e.g., to check installation progress on several computers), by intense discussions (e.g., using both a computer and a blackboard) etc., and all these activities imply quite a lot of physical motion. On the other hand, stress, caused by some other reasons (e.g., waiting for an important call or thinking about a difficult problem) may display itself in restlessness, e.g., a person may frequently visit coffee room, yard or colleagues' offices, fetch candies from a closet or ride around in the office chair. Therefore we extracted for each time window various trajectory features that could possibly reflect such behaviours. As explained in the Section ''Unsupervised Hidden Markov Model Training'', we extract features from trajectories of each user separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Time domain features Motion time</head><formula xml:id="formula_8">Mt = ? R 1m,2kph,T</formula><p>Mt R 1m,2kph,T , where Mt R 1m,2kph,T are durations of all track parts (or whole tracks) in time window T, provided that their ranges R exceed 1 metre and average speeds exceed 2 km per hour (track range R is the maximum distance between any two of trajectory points).</p><p>This feature is calculated because on a stressful day a user may move more or less than during normal days (at least during certain time windows): for example, if a person has many meetings, he/ she will walk to and from the office more often than usually.</p><p>Maximum presence time Pt_max = max (Mt T ), where Mt T are durations of all tracks in time window T. This feature is calculated because on a stressful day a user may have longer or shorter breaks out of the office. For example, if stress is caused by the need to finish some computer work, a user may stay in the office practically without breaks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Spatial domain features</head><p>Track spread TS = max k (dist (T c , T k )), where T c is a track centre, i.e., mean of coordinates of all track points, T k is a track point, and dist is Euclidian distance between XY coordinates.</p><p>Track spread measures, how much space in the office the user occupies. For example, if a user is practically motionless near his/ her computer, track spread value will be very small, but if a user is fidgeting or moving erratically (e.g., rides around in a chair or moves between two computers), track spread grows.</p><p>Wandering style TR = 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ntr</head><p>? Ntr n=1 Cn Rn , where N tr is number of tracks in time window T; C n is number of cells, traversed by each track; and R n is track range (the maximum distance between any two of trajectory points).</p><p>Wandering style also measures, how much space in the office the user occupies, but in a coarser way that track spread. Wandering style measure ignores small movements within the same cell, whereas track spread measure treats small and big moves in the same way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spread of hot spots SHS = SHS move + SHS presence</head><p>, where SHS move and SHS presence are spreads of hot spots, extracted from moving parts of tracks and other parts respectively; moving parts are determined in a same way as for calculation of motion time Mt, and each spread is calculated as follows: <ref type="bibr">(HSn, HSj)</ref>, where N hs is number of topmost hot spots in the respective track part; HS n are XY coordinates of these hot spots (i.e., cell centres), and dist is Euclidian distance between XY coordinates Hot spots are cells with the largest numbers of trajectories of the office owner for the current time window; their extraction is described in ''Unsupervised Hidden Markov Model Training'' Section. As all features are extracted for each user separately, SHS values are calculated using only trajectories of the target user. Similarly to other spatial features, SHS measures, how much space the user occupies, but SHS takes into account only users' favourite locations, whereas other spatial features consider all locations.</p><formula xml:id="formula_9">SHS track part = 1 Nhs ? Nhs n=1 ? Nhs j=1 dist</formula><p>In addition to the features, described above, we tested many other features, e.g., motion speed, travelled distance, total presence time in the office etc., but in the tests these features appeared to be less useful for discriminating between stressful and normal days than the features described above, and we are not describing them here in detail. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name</head><p>Input feature Stress score</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HMM-Mt</head><p>Mt (motion time) Formula ((3), ( <ref type="formula">4</ref>)) HMM-Mt-scatter Mt (motion time) Formula ((5), ( <ref type="formula" target="#formula_5">6</ref>))</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HMM-Pt_max</head><p>Pt-max (maximum presence time) Formula ((3), ( <ref type="formula">4</ref>))</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HMM-Pt_max-scatter</head><p>Pt-max (maximum presence time) Formula ((5), ( <ref type="formula" target="#formula_5">6</ref>)) HMM-TS TS (track spread) Formula ((3), ( <ref type="formula">4</ref>)) HMM-TS-scatter TS (track spread) Formula ((5), ( <ref type="formula" target="#formula_5">6</ref>)) HMM-TR TR (wandering style) Formula ((3), ( <ref type="formula">4</ref>)) HMM-TR-scatter TR (wandering style) Formula ((5), ( <ref type="formula" target="#formula_5">6</ref>)) HMM-SHS SHS (spread of hot spots) Formula ((3), ( <ref type="formula">4</ref>)) HMM-SHS-scatter SHS (spread of hot spots) Formula ((5), ( <ref type="formula" target="#formula_5">6</ref>))</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Data collection</head><p>Data were collected in three offices; these offices will be referred below as offices A, B and C. Office A was occupied by just one person, and its occupant will be referred to as ''person A'' below. Office B was occupied by two people, but only one of them was monitored because the second occupant did not volunteer to provide stress labels; the test subject in the office B will be referred to as ''person B'' below. Office C was also occupied by two subjects, and both of them were monitored by the same depth camera; we will call them as ''person C'' and ''person D'' below. Test subjects A and B were males in management positions; person C and person D were females, senior researchers. Monitoring lasted 10 months, but during this time the test subjects had holidays, business trips, telework and sick leaves, so on average we collected 95 working days of data per person.</p><p>In all offices depth cameras were positioned near the ceiling close to the entrance door, so that cameras' fields of view included as large parts of the offices as possible (camera view in the office C is presented in Fig. <ref type="figure" target="#fig_0">1</ref>). Therefore for each subject we monitored approximately 3 by 5 metres of his/ her office space, and his/ her office table was located in the far end of the monitored area.</p><p>Stress labels were acquired by asking the subjects to report each day as ''very stressful'', ''stressful'' or ''normal''. Person B labelled only one day as ''very stressful'', while each of the other subjects labelled 9-10 days as ''very stressful''. Percentages of days, labelled as ''normal'' by different subjects, ranged from 49% to 77%; normal days constitute 64% of the whole dataset. In addition, test subjects voluntarily accompanied part of self-reports by explanations why they labelled this or that day as stressful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Experimental protocol</head><p>Experiments were performed using data of each target person separately, i.e., all models were person-specific. Sections ''Unsupervised Hidden Markov Model Training'' and ''Inference with Hidden Markov Models'' describe the process and the research questions and explain, how trajectories of each target user were differentiated from trajectories of others.</p><p>In this study we employ ''leave-one-day-out'' protocol: each day in turn serves as a test day, and all other days constitute training data. We trained separate HMM models for each feature, described in ''Trajectory-Based Behavioural Features'' Section, and for each model we tested two approaches to calculate stress score of a day: using formulas ((3), ( <ref type="formula">4</ref>)) and using formulas (( <ref type="formula">5</ref>), ( <ref type="formula" target="#formula_5">6</ref>)). Below we name these system configurations as ''HMM -Feature Name -Score Calculation Way''. For brevity, when stress score is calculated using formulas ((3), ( <ref type="formula">4</ref>)), ''Score Calculation Way'' part is omitted. When stress score is calculated using formulas (( <ref type="formula">5</ref>), ( <ref type="formula" target="#formula_5">6</ref>)), ''Score Calculation Way'' part is ''scatter'', as formula (6) measures dispersion of the recovered hidden states. Table <ref type="table" target="#tab_0">1</ref> lists these configurations.</p><p>Decision thresholds were calculated according to formulas ( <ref type="formula">7</ref>) and ( <ref type="formula">8</ref>), and we experimented with the following values of weight w: 1/10; 1/6; 1/5; 1/4; 1/3; 1/2. We have chosen time window W = 3 h because meetings often last two hours and hence shorter window length would result in many windows containing too little data or no data at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Experimental results</head><p>Since the majority of the studies into real life stress detection present results in terms of accuracy, we also calculated accuracies of the tested configurations as follows: where NstressOK is the number of correctly classified stressful days; NnormalOK is the number of correctly classified normal days, Nstress is the number of stressful days in the dataset, and Nnormal is the number of normal days. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1.">Stress detection on daily basis: Single modalities</head><p>Table <ref type="table" target="#tab_1">2</ref> presents accuracies of different configurations, described in Table <ref type="table" target="#tab_0">1</ref>, with relatively small weight w = 1/10 and with relatively high weight w = 1 /4: smaller weight allows to check whether the majority of stressful days lie above or below decision boundary, and greater weight allows to check how many stressful days lie close to the decision boundary.</p><p>Table <ref type="table" target="#tab_1">2</ref> shows that in the majority of cases threshold TA 1 allows to differentiate between stressful and normal days with higher accuracy than threshold TA 2 ; hence, feature values on stressful days are typically greater than that on normal days. Both HMM-TS and HMM-SHS employ spatial features, and these features are quite similar to each other as they measure spreads of visited office locations. Their results at different thresholds suggest that during stressful days our test subjects occupied more space than during normal days. HMM-Pt_max classifier is based on calculation of maximum presence time in the office, and its higher accuracy with threshold TA 1 than with TA 2 suggests that on stressful days our test subjects spent more time in the offices continuously than on normal days. Results of HMM-Mt-scatter classifiers, that measures dispersion of motion times between time windows, and HMM-Pt_max-scatter classifier, that measures dispersion of presence times between the windows, suggest that both dispersions increase on stressful days. Therefore our test subjects left their offices less regularly during stressful days.</p><p>Table <ref type="table" target="#tab_1">2</ref> also shows that three individual classifiers (HMM-Pt_max, HMM-TS and HMM-SHS) achieved reasonably good (for unsupervised learning) accuracy 63%-64%. As recent studies reported results also in terms of F-score, we present below F-scores of the best single modalities in comparison with Zero-R classifier. Zero-R is a classifier that assigns each test sample to the class that has the most observations in the training dataset. Since all our classifiers were trained in person-specific ways, F-score of Zero-R classifier was also calculated in the person-specific way, i.e., Zero-R classified each test day of the target user using only his/ her training data (see Table <ref type="table">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2.">Stress detection on daily basis: Combined modalities</head><p>Table <ref type="table" target="#tab_2">4</ref> presents accuracies of combined (via ''sum'' rule) modalities with threshold TA 1 , as their accuracies with threshold TA 2 were lower.</p><p>Table <ref type="table" target="#tab_2">4</ref> shows that certain combinations of two individual classifiers achieved reasonably high (for unsupervised learning) accuracies of 65%-67%. Combinations of three classifiers were not better, probably because our classifiers were not sufficiently complimentary (fusion of complementary classifiers usually allows to achieve higher accuracies than fusion of similar classifiers). F-score of the best combined classifier, HMM-SHS + HMM-SHS-scatter, is 0.52 (at threshold TA 1 and weight w = 0.1).</p><p>Fig. <ref type="figure" target="#fig_9">6</ref> presents stress scores of the best combined classifier HMM-SHS + HMM-SHS-scatter and of its individual components for the four test subjects for about 70 days. In addition, Fig. <ref type="figure" target="#fig_9">6</ref> displays graphs of presence time (cumulative time of being in own office) and gap time (maximum interval between two visits to own office), normalised (we used min-max normalisation) to fit the screen. Y values of each ''presence time'' and ''gap time'' graphs range from 0 to 1.</p><p>HMM models can output values from -1 to 1, but in practice maximum and minimum are rarely reached. Fig. <ref type="figure" target="#fig_9">6</ref> does not present Y scales for each graph because the graphs are shifted along Y axis for better visibility and because relative positions of values of different graphs on the same day are more important than absolute values.</p><p>Only days when the corresponding subject was present in the office are counted because no data of this person were recorded on days when he/ she was sick, travelling or on holidays. Hence for example day 50 of the person C is not the 50th day of monitoring office C; it is 50th day in the line of days when person C was present in the office (thus 50th day of the person C may not be the 50th day of her roommate person D). It shows that small presence times and long gap times may hinder stress detection: e.g., stress on day 34 of person A was probably missed because his presence time on this day was close to minimum among all test days, while gap time was close to maximum. Not all such stressful days were missed, however: for example, stress of person A on days 35 and 63, stress of person D on day 8 and stress of person C on day 64 were correctly recognised despite that presence times and gap times on these days were close to the minimum and maximum respectively. Therefore the chosen data features are not too sensitive to variations in presence and gap times. Fig. <ref type="figure" target="#fig_9">6</ref> shows that ''very stressful'' days did not necessarily receive the highest scores; the only exception were scores of the person B, but it might be because he has labelled as ''very stressful'' just one day, and generally has not labelled many days as stressful. Nevertheless ''very stressful'' days of all subjects were correctly recognised in many cases. Two subjects, person C and person D, accompanied their labels by more comments than other subjects and also indicated when stress did not last for the whole day and when they were not present in their office for the whole day. These days did not necessarily receive lower scores than ''stressful'' days, but this should not be seen as classifier failure because short stress can be quite notable: for example, person D stated that day 14 was so stressful that she had to leave her office early. Fig. <ref type="figure" target="#fig_9">6</ref> shows that this day correctly received rather high stress score. According to the comments of the test subjects, perception that the ''whole day is stressful'', on the other hand, can be caused by tiredness (e.g. when a person has not recovered from previous day) or by several non-stressing events, e.g., by a greater than usual number of emails, so the stress may be not so prominent.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3.">Differences between test persons</head><p>As many previous studies observed, stress perception is highly individual, and stress-induced behavioural changes also depend on a person. Our study confirmed this finding once again. First of all, percentage of stress labels notably differed between the test subjects, although objectively work tasks of person B, who labelled 23% of days as ''stressful'', were not less demanding during monitoring period than work tasks of other subjects, who labelled up to half of the days as ''stressful'' and ''very stressful''. Second, when we asked the subjects which days they perceive as stressful, they provided different explanations. One subject perceived approaching deadlines and public presentations as fairly stressful, while other subjects took them easier. All subjects stated that they perceive as stressful times when they cannot concentrate on their work, but inability to concentrate was mainly attributed to external interruptions (visitors and phone calls) by two subjects and to internal state (inability to focus) by one subject. The fourth subject mentioned both these problems, as well as lack of inspiration and tiredness. Last but not least, the test subjects differed also in their everyday behaviour: one subject is described by the colleagues as quite vivid person, another subject -as a quiet and reserved individual, and two subjects as somewhat in between. Thus although HMM-SHS and HMM-SHS + HMM-SHS-scatter classifiers achieved the highest accuracies on average, they were not the best individual classifiers for all subjects. Table <ref type="table" target="#tab_3">5</ref> presents, which classifiers achieved the highest accuracies for each subject, in comparison with accuracies of HMM-SHS and HMM-SHS + HMM-SHS-scatter classifiers. Table <ref type="table" target="#tab_3">5</ref> shows that spatial domain features HMM-SHS, HMM-TR and HMM-TS worked better than time domain ones (HMM-Mt-scatter, HMM-Pt_max and HMM-Pt_max-scatter). This result suggests that although in a stressed state human beings tend to move more, their tendency to occupy more space is more prominent. An individual classifier HMM-SHS, that achieved the highest average accuracy for all subjects and was also the best classifier for two female subjects, (person C and person D), is based on the assumption that spread of locations notably increases on stressful days. Accuracy of HMM-SHS for person D was fairly high: 70%. Top accuracy for person A was also close to 70%, and it was achieved by HMM-TS classifier which is very similar to HMM-SHS in that it also evaluates spread of locations, but in a different way: in case of HMM-SHS spread calculation takes into account only hot spots, i.e., locations, visited most often by the test subject, whereas in case of HMM-TS spread calculation takes into account all trajectory points (i.e., including points visited just once). Fig. <ref type="figure">7</ref> displays examples of heatmaps for each office for several days, and these heatmaps explain why taking into account all trajectory points worked better for person A. Fig. <ref type="figure">7</ref> shows that person A was present in his office much less than other subjects (maximum numbers of detections in his office rarely exceed 10, whereas maximum numbers of detections in heatmaps of other offices are close to 100). Therefore number of trajectories in office A was simply too small for robust calculations of hot spots and hence another way to calculate spread of locations, employed by HMM-TS, succeeded better. For other subjects HMM-TS did not succeed as well as HMM-SHS because HMM-TS way to evaluate spread of locations is more sensitive to variations of motion on different days, which were notably greater in offices B and C than in office A.</p><p>For person B none of the ways to evaluate spread of locations succeeded very well alone. The best single classifier for this person, HMM-TR-scatter, however, is also related to the size of occupied area because HMM-TR is a measure of trajectory curvature or zigzagging. Hence success of HMM-TR-scatter classifier means that on stressful days at least some of trajectories of person B were less straight than on normal days. Nevertheless a combined classifier HMM-SHS + HMM-SHS-scatter, evaluating spread of locations, achieved in office B reasonable accuracy 70% despite an important problem, revealed by the heatmap of Day 57. This heatmap consists of two parts, and the border of the larger part is unnaturally straight, which suggests a possible shift of depth camera during this day. As we could not drill into the office walls, we attached the cameras to the poles, and these poles could be accidentally turned, for example, during cleaning. Therefore it is possible that during the last one-third of the monitoring period depth camera in the office B was not Fig. <ref type="figure">7</ref>. Heatmaps for different rooms and days. Bar in the right side of each heatmap displays colour-coding of numbers of detections; day numbering corresponds to that in Fig. <ref type="figure" target="#fig_9">6</ref>; stress labels: N -normal, S -stressful, VS -very stressful, PS -part-day stress, PP -part-day presence in the office. positioned in the same way as prior to day 57, and this shift affected all results because of the chosen leave-one-day-out experimental protocol. (Although a temporal occlusion would result in a very similar heatmap, this could not be the case because of the high position of depth camera: it is not easy to cover it.)</p><p>For person C all classifiers achieved notably lower accuracies than for the other subjects. One reason might be that reference model of normal behaviour is built using all training samples. As subject C reported 51% of stressful days, her reference model is an equal mixture of normal and stressful days, whereas reference models of other test subjects are closer to normal behaviour. Stress of person D, however, was recognised with higher accuracy despite she also reported quite many stressful days (nearly 40%). Hence we believe that accuracy depends rather on subjects' personalities than on percentage of stress samples in the data. Person C is very reserved, whereas body language of person D is quite expressive, and changes in her motion on stressful days are more prominent. For example, heatmap of very stressful day of person D is much more ''hot'' (the rightmost one) than heatmap of very stressful day of person C (the middle one). This is because numbers of detections in heatmaps do not depend only on time spent in the monitored area; they also depend on motion of the monitored person. Depth data analysis employs adaptive background model, which helps to separate human beings from movable office objects, but unfortunately results in losing trajectories of subjects who move very little or are occluded for certain time. In such cases the tracking algorithm decides that the subject belongs to a background, adapts the background model of the office and ''forgets'' the subject. This happens fairly often when the subjects' heads are occluded by high headrests of their chairs and when the subjects are highly concentrated on computer screen, but it is more likely to happen with reserved persons than with vivid ones.</p><p>Relatively high detection accuracies for person D also suggest that monitoring works not only in single occupancy offices or when each subject is tracked by a separate depth camera; it is sufficient to install one camera per office. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.5.">Cold-start problem</head><p>Accuracies, presented in previous sections, were obtained in leave-one-day-out experimental protocol, i.e., we used for system training data, collected during nearly 10 months (95 days of being present in the office per test subject on average). It is generally beneficial to train unsupervised methods using large datasets, and in our case acquisition of such sets does not require any efforts from the test subjects, but nevertheless human beings may be impatient and to get results sooner. Therefore we studied what kind of results the proposed system could deliver one month after its installation. Due to frequent business trips and teleworking of our test subjects, during one month the system would collect about 12 days of data per subject. We evaluated system accuracies in two experimental protocols:</p><p>? personal models using scarce data: for each target subject, we create a reference model using 12 randomly selected days of his/ her data, create sequences of observations using the same 12 days and train HMM models on this very small dataset;</p><p>? general models, adapted using scarce data: for each target subject, we create a reference model using 12 randomly selected days of his/ her data and create sequences of observations using these data; then for each of the remaining subjects we create a reference model using all his/ her data and create sequences of observations using these data; and then we train HMM using observational sequences of all subjects.</p><p>In the former protocol training dataset is person-specific, but far too small for unsupervised learning compare with typical practices; in the latter case the dataset is sufficiently large, but not so person-specific. Table <ref type="table" target="#tab_5">7</ref> presents average accuracies of best single and combined modalities for evaluating days and months with w = 1/5 (accuracies with other weights followed same trends as in previous sections).</p><p>Table <ref type="table" target="#tab_5">7</ref> suggests that the proposed system can achieve on average 63% accuracy of evaluating days and 78% accuracy of evaluating months and hence provide useful hints already after one month data collection (F-scores are 0.5 and 0.65 respectively). Table <ref type="table" target="#tab_5">7</ref> shows that personal models and general models achieved similar accuracies in cases when individual modalities were employed for evaluating days, but the best combined classifier (HMM-SHS + HMM-SHS-scatter) achieved more balanced results when training utilised only person-specific data, despite very small data size. This result once again confirms that personal differences are important. Table <ref type="table" target="#tab_5">7</ref> also shows that general models suit better for stress detection on monthly basis than personal models, probably because training on large datasets makes HMM more robust to small changes in input values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>Studies into causes of stress at work listed as main reasons the following factors: long hours, work overload, time pressure, difficult or complex tasks, lack of breaks, lack of variety, and poor environmental conditions (for example, space, temperature, light) <ref type="bibr" target="#b1">[2]</ref>. To date, however, the majority of studies into stress detection by environmental sensors were performed in the labs, where most of above-listed stressors were not modelled. Instead, induced stress was usually a short-term condition: test subjects were assigned difficult tasks, and researchers attempted at recognising their immediate reactions. Field studies often aimed at detecting short-term arousal <ref type="bibr" target="#b16">[17]</ref> or evaluating mental workload during short time intervals <ref type="bibr" target="#b33">[35]</ref> too. Voluntarily provided by our test subjects explanations regarding their stress labels confirm that in real life stress is often a prolonged condition, and suggest that variety of reasons for stress is greater than listed above. For example, some of ''stressful'' and ''very stressful'' labels were explained as follows:</p><p>? ''I tried to write, but I wasn't inspired.'' Inability to recover from the previous day can be attributed to work overload or to having difficult tasks yesterday, but lack of inspiration can be caused by multitude of other reasons too. Unfortunately, we could not ask the subjects about the reasons for all stressful days, so we cannot estimate accuracies of evaluating different stress types separately, but analysis of days, accompanied by explanations, suggests that the proposed method is capable of detecting at least some of such uneasy conditions. For example, days 35, 36, 68, 70 and 71 of person C belong to ''nothing special happened'' type of stress, and Fig. <ref type="figure" target="#fig_9">6</ref> shows that days 36, 68 and 71 indeed received stress scores above the decision threshold. Similarly, person D commented that on day 36 she was feeling ''very-very tired'', and this day received fairly high score. On the other hand, several days when person C stated that stress was relatively short received low stress scores, but it might be because this happened in the meetings outside of her office.</p><p>Naturally ''stressful'' and ''very stressful'' labels were also often explained as ''Very busy day''. Examples of other comments, accompanying this stress type, are the following:</p><p>? ''The day was really busy with several meetings'' ? ''Several work related things came with a very short notice'' ? ''The work day was normal, but there was one busy task in the afternoon and I felt immediately stressed because I needed to go home early''.</p><p>? ''I tried to finish two tasks, but I had a lot of urgent emails taking my attention'' ? ''I had several tasks to finalise'' This stress type is quite similar to conditions, induced in lab studies, except that at work such conditions last longer and output (e.g., how well the tasks are performed) is more important for the career of the monitored subjects. We observed, however, that ''normal'' labels were also often accompanied by explanations that subjects had to perform difficult tasks on these days. Examples of such comments for normal days are:</p><p>? ''Good and busy day'' ? ''Normal, but busy day'' ? ''Morning was stressing, but I managed quickly to complete several tasks and relaxed'' ? ''Quite productive day at the work, I felt busy but not stressed'' ? ''I felt really effective'' ? ''I was inspired and did a lot'' This type of conditions, to the best of our knowledge, is not often explored because real life studies cannot burden the subjects with the requirement to explain their stress labels, whereas lab studies are typically conducted under assumption that the need to quickly complete several tasks inevitably implies stress. Comments of our subjects suggest that this assumption does not hold always, though.</p><p>Fig. <ref type="figure" target="#fig_9">6</ref> shows that the proposed method assigned to ''good and busy'' days rather low scores in many cases: for example, day 5 of person D and days 37, 41 and 61 of person C received low scores. Overwhelmingly busy days, on the contrary, often received high scores, such as day 31 of person C, that was described as follows: ''The work day was normal, but there was one busy task in the afternoon and I felt immediately stressed because I needed to go home early'', as well as days 64-66 of person C. Day 67, on the other hand, received fairly low score, but it might be because person C was highly concentrated on her work: ''I woke up at 5 o'clock and started working''. Therefore the proposed method might be capable of distinguishing between being ''a busy winner'' and being overwhelmed, but evaluating this capability quantitatively would require collecting more detailed self-reports for all days, which would be too tiring for test subjects in so long data collection. To the best of our knowledge, however, distinguishing between positive and negative stress is an open research problem. For example, Kusserow et al. <ref type="bibr" target="#b16">[17]</ref> reported detection of positive arousal (happiness) of one study participant and negative arousal (anger) of another one, but have not suggested methods to distinguish between positive and negative feelings on the basis of physiological data.</p><p>Average accuracy of unsupervised classification of days into two classes (''stressful'' vs. ''normal''), achieved in our work, is 67% (F-score 0.52), and this result is obtained in a fairly long-term real life study: data were collected during 10 months, so variety of tasks and personal conditions of the test subjects during this time was probably greater than in other real life study to date. To the best of our knowledge, two real life data collections lasted 7 months <ref type="bibr" target="#b34">[36]</ref> and 4 months <ref type="bibr" target="#b22">[23]</ref>, whereas durations of data collection in other studies ranged between few hours <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b23">24]</ref>/ few days <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b35">37]</ref>, one month <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b21">22]</ref> and six-eight weeks <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20]</ref>.</p><p>Works, employing real life data for classifying days into two classes, reported higher accuracies, but not much higher than that achieved in our work, especially considering employed fully supervised classifiers: Bogomolov et al. <ref type="bibr" target="#b19">[20]</ref> achieved 72% accuracy, and Sysoev et al. <ref type="bibr" target="#b20">[21]</ref> achieved 73% accuracy (both works detected stress on the basis of mobile phone data). Achieving similar accuracy in a longer (7 months) study requited to use weather information and Big Five personality traits (the latter were acquired via questionnaires) in addition to mobile phone data <ref type="bibr" target="#b34">[36]</ref>.</p><p>Sano et al. <ref type="bibr" target="#b3">[4]</ref>, on the other hand, have not reported accuracies of stress detection on daily basis; instead, they used data, collected during one month, to classify test subjects into two classes: High Perceived Stress group vs. Low Perceived Stress group (in other words, more and less stress-prone subjects). Ground truth for classifying the subjects into these groups was obtained via pre-study and post-study questionnaires. During data collection each subject was wearing mobile phone and two wrist devices, and fully supervised classifiers were employed to process the collected sensor data and to assign each subject to one of the above-described groups. The best classifier achieved 64% accuracy when only phone data were used (F score 0.67); and 78% accuracy when data from two wearables were used (F-score 0.8). We did not classify subjects into two groups; instead, we classified months as stressful vs. normal. Our best classifiers achieved similar accuracy (63%) and F-score (0.65) when we trained the system on data, collected during one month, and notably higher accuracy (95% accuracy, F-score 0.9) when we trained the system on 10-month data.</p><p>Other studies into stress detection on the basis of phone data <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b22">23]</ref> evaluated stress on three-level scale (low, medium and high stress) and detected whether stress occurred in the morning, afternoon or evening. Accuracies of personal models, trained in fully supervised way on not-so-small datasets, ranged from 60% to 75%. Maxhuni et al. <ref type="bibr" target="#b14">[15]</ref> reported also F-score 0.66, obtained in the tests with the initial dataset. Ciman and Wac <ref type="bibr" target="#b21">[22]</ref> reported higher accuracies for fully supervised classification into three classes (relaxed, neutral and stressed conditions): general models achieved F-score 0.70, while person-specific models achieved F-score 0.88. In this study, however, the majority of the test subjects were males, and cases of self-reported stress constitute less than 5% of all reports in this dataset. Thus high detection accuracy might be due to reporting only prominent stress cases. As test subjects tend to provide notably less quantities of labels than requested <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b21">22]</ref>, from practical point of view recognition of several stress classes might be not worth data collection efforts. Furthermore, collecting data once in a life may not suffice because human behaviour evolves with time, and classifiers might need periodic re-training.</p><p>Gjoreski et al. <ref type="bibr" target="#b25">[26]</ref> achieved F-score 0.9 in the study into classifying physiological data, collected from wrist device, into two classes. The goal was to detect every self-reported stress period (self-reports were requested 4-6 times per day; stress periods constituted less than 10% of the data). This accuracy was obtained using a dataset of 55 days, but 48 days were provided by one person only, and the main data provider, as well as other 4 subjects, were all healthy young men. In addition, this required a dedicated lab session from the test subjects, as classifiers were trained on the lab data.</p><p>Recent large-scale (1002 subjects) <ref type="bibr" target="#b35">[37]</ref> experiments with physiological data reported lower accuracy for three-class problem. In <ref type="bibr" target="#b35">[37]</ref> each subject was wearing 2 devices and was prompted to provide self-report 12 times per day; the goal was to detect every stress occurrence too. Data of 43% of subjects appeared unsuitable for stress detection; in leave-onesubject-out tests on the remaining dataset a fully supervised classifier (Random Forest) achieved an average F-score 0.43, whereas F-score of ZeroR classifier was 0.36. This study observed that the highest classification accuracies (F-scores above 0.66) were achieved for the test subjects who did not experience stress very often: on average, they reported 86% of ''no stress'', 12% of ''light stress'' and 2% of ''high stress'' cases. On the other hand, F-scores for the most stress-prone subjects (who reported 26% of ''no stress'', 45% of ''light stress'' and 29% of ''high stress'' conditions on average) were below 0.33, i.e., performance as good as random. Smets et al. also reported that test subjects in the first group were on average few years older, had healthier lifestyles and better sleep quality, but which of these factors influenced detection rates most of all, is not yet known. In our study the most stress-prone subjects reported 40% and 51% of stressful days, and accuracies of evaluating conditions of all subjects in long term (on monthly basis) were fairly close to each other.</p><p>Although detecting every stress occurrence may help to find reasons for stress, such fine-grain stress detection is not necessary for overall assessment of workers' conditions. Several studies reported that chronic stress is the most dangerous stress type; it may badly affect performance and increase risks of cardiovascular diseases, depression and insomnia among others <ref type="bibr" target="#b29">[31]</ref><ref type="bibr" target="#b30">[32]</ref><ref type="bibr" target="#b31">[33]</ref>. It was also observed that long-lasting stress of low intensity may have equal or greater health impact than short-term high intensity stress <ref type="bibr" target="#b18">[19]</ref>. Hence recognition of long-lasting stress may be more important for wellbeing than fine-grain stress classification. The proposed method suits to this purpose very well because it achieved fairly high accuracy of 95% (F-score 0.9) in classifying months despite being truly unobtrusive. In this study it did not require any maintenance during 10 months, and depth cameras were located far enough from the monitored subjects to forget about them. Other sensors, employed for real life data collections in other studies, were more obtrusive: existing physiological sensors require frequent charging and may be inconvenient to wear, and mobile phones also require more frequent charging when they collect data than during normal use. The drawback of using environmental sensors is their inability to detect anything if the subjects are travelling or teleworking for the whole day, but in these cases mobile phones can be used. Part-day presence in the office, however, already allows to classify a day, as our study demonstrated: all our study participants spent a lot of time in meetings outside their offices.</p><p>Unobtrusive monitoring of offices may serve as a tool to improve human resource management and to prevent stressrelated illnesses if its results are used, for example, to improve workload distribution or to offer relaxation coaching. Also more fine-grain monitoring may be offered, to increase awareness of a stressed individual regarding main stressors. Unobtrusive monitoring of offices may also facilitate studies into effects of long-term exposures to various indoor environmental factors on individual's stress and cognitive performance. Energy efficiency requirements and greater use of synthetic building materials are causing higher indoor air contaminant concentrations than those typically encountered outside. Poor indoor air quality has several harmful effects on human health and welfare <ref type="bibr" target="#b18">[19]</ref>. Other environmental factors, such as crowding, temperature, humidity, noise and lighting can directly influence individual's mental wellbeing by altering psychosocial processes <ref type="bibr" target="#b36">[38]</ref>. However, it is also known that psychosocial factors may influence the individual responses to chemical, physical and biological indoor pollutants <ref type="bibr" target="#b37">[39]</ref>. This implies the need to better understand influence of indoor environmental factors on productivity and wellbeing of office workers, and in future we plan to develop a reliable indoor conditions monitoring system and to study this issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>This work proposed an unobtrusive method for detecting stress via analysis of motion trajectories, obtained from depth cameras in a fairly privacy-safe way: unlike previous studies, depth cameras in our setup do not point at faces of the monitored subjects, and we only extract fairly coarse-grain motion features instead of fine-grain tracking of facial or body features. As this system requires neither maintenance nor labelling efforts, unlike many others that required test subjects to frequently charge wearable devices and/ or to provide stress labels in large quantities, it suits well to long-term wellbeing monitoring. The feasibility of the proposed approach is confirmed by experiments with real life data, collected during 10 months in three offices, and to the best of our knowledge, this is the first study into long-term real life stress detection by environmental sensors. Furthermore, this is the first long-term real life study in which a single environmental sensor monitored wellbeing of two subjects: as single occupancy offices are not the most common case, we included only one such office in our study; two other offices were occupied by two persons each. In one of these offices we monitored one subject, while in another office we monitored both subjects by a single depth camera. Test results demonstrated that all three setups are feasible and that recognition accuracy depends rather on subject personality than on office occupancy: the highest accuracies were achieved in two-person offices.</p><p>The proposed method employs HMM classifier, utilising motion patterns of the subjects. As previous studies have not provided many recommendations regarding choice of motion features, in this work we studied, which features of motion trajectories allow to detect stress more accurately (research question Q1). Test results demonstrated that time-based features are not as good indicators of stress as location-based features, such as increases in spread of trajectory points, spread of most frequently visited office locations and zigzagging. This finding suggests that human beings rather tend to occupy more space in stressed states than to move more, and it is an interesting finding because previous studies only suggested features, measuring quantity of motion. Location-based features were not proposed, probably because other studies with depth cameras were performed in labs, where test subjects behave differently than in real life. We also studied, whether change in feature values or change in variations of feature values is a better indicator of stress (research question Q2), and which kind of change (increase or decrease) of respective values indicates stress (research question Q3). We found that stress displays itself in increase of values and their variations for the majority of features. We also found that on average, increase in feature values is better stress indicator than increase in variations, but we also found that it is beneficial to combine both indicators as they are complementary to each other: often, when increased feature values failed to detect stress, increased variations detected it.</p><p>Our study once again confirmed importance of collecting behavioural data in real life settings. In real life stress is often long-lasting, e.g., our subjects reported that tiredness after trips or difficult work periods may cause them to feel stressed during next day or a few days even if nothing special happens. To the best of our knowledge, this stress type is rarely studied, but our results suggest that it deserves more attention. According to free-from comments of the test subjects, the proposed algorithm recognised at least some of such days. How many exactly, we unfortunately cannot say because we did not obtain detailed labels for all days: it would be too burdening for the test subjects to do it in so long data collection, and probably they would be reluctant to describe stress reasons in detail. Therefore we could only compare free-form comments with the algorithm output on the days when such comments were available. The same free-form comments suggested that, on the other hand, short-term stress was often missed and hence the proposed method seems to better detect long-lasting not-so-prominent stress than nasty short-term surprises, which is probably natural because we evaluated each day as a whole. Based on free-form comments, we also observed that the proposed algorithm succeeded, to some extent, not to misclassify feelings of being very busy in a positive way (i.e., when subjects successfully solve multiple problems) as stress (i.e., cases when subjects feel overwhelmed). To the best of our knowledge, this is an open, but rarely studied problem in stress research despite that feelings of being overwhelmed are much more dangerous for health than successfully overcome challenges. This problem definitely deserves further studies, and we need to find a way to obtain more detailed self-reports from the test subjects without causing their withdrawals from data collections.</p><p>The main drawback of the proposed method is its inability to constantly evaluate subjects' conditions; however, it does not require constant presence of subjects in their offices. In our study all subjects spent a lot of time in the meeting rooms, and nevertheless the proposed method achieved 67% overall accuracy of classifying days into ''stressful'' vs. ''normal'' classes and 95% accuracy of classifying months. We consider this result good for unsupervised classification of behavioural data, acquired from environmental sensors, because even accuracies of fully supervised classifiers, trained on fairly large sets of mobile phone usage data (and phones usually accompany the subjects everywhere), did not exceed 75% in real life studies. In future we plan to collect data of greater number of subjects and to make stress detection more contextand person-adaptive, for example, to personalise choice of features and hyper-parameters, such as stress threshold and time window. In this study we found that choice of features should depend on time, spent in the office, and on user personality. The former kind of feature selection can be done automatically, by analysing data densities, but generally it may be worth developing active learning methods for selecting best features and hyper-parameters -provided that active learning would not add up to the stressors. To this end, we plan to study, how to integrate presentation of stress detection results and/ or recommendations to the test subjects with obtaining their opinions regarding relevance of this information in engaging ways. We also plan to study how to combine depth camera data with other data types, e.g., mobile phone usage data.</p><p>Our system achieved best results when it was trained on large datasets. When we used for system training as little as 12 days of data per office, it achieved 63% accuracy in classifying days and 78% accuracy in classifying months, which suggests that the proposed system may become useable quite soon after installation. Therefore we consider results, reported in this work, encouraging for further studies into unobtrusive stress detection.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Depth image of the monitored area in one of the offices.</figDesc><graphic url="image-3.png" coords="4,162.54,55.59,222.26,171.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Framework for depth camera-based office monitoring.</figDesc><graphic url="image-4.png" coords="4,47.51,273.78,452.30,225.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Obtaining observations for HMM models during training.</figDesc><graphic url="image-5.png" coords="6,48.62,55.59,450.02,201.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3</head><label>3</label><figDesc>illustrates the process of obtaining an observation of behaviour of User1 from data, collected within time window W1 of Day j in the office where User1 is located. At two stages of this process ((1) finding location of the office chair Chair of User1 and (2) building reference model R-Fi-W1) we use data of all days in the training dataset; hence, we included days DL and DM to illustrate these stages. Notations and processes in Fig. 3 are as follows: Data Day j, Data Day L, Data Day M : Databases of all trajectories, obtained in the monitored office during days Dj, DL and DM respectively. Time window W1: Certain time window (for example, from 15.00 until 18.00).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Area cells, three tracks and five topmost hot spots (highlighted).</figDesc><graphic url="image-6.png" coords="7,198.63,55.59,144.00,112.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Day L and Data of User1 from Day M: Trajectories, obtained in the monitored office during days DL and DM respectively and selected as belonging to user User1, as described above. Fi-Dj-W1, Fi-DL-W1 and Fi-DM-W1: Feature Fi, extracted from trajectories, obtained within window W1 of days Dj, DL and DM respectively. Features are person-specific as they are extracted from Data of User1. R-Fi-W1: Reference values of feature Fi within window W1. We calculate reference values separately for each time window in order to account for possible time-dependency of user behaviour. We use all days in the training dataset (Dj, DL, DM etc.) to calculate reference values. Vector of reference values of different features constitutes a reference model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Calculating day scores at the inference stage.</figDesc><graphic url="image-7.png" coords="8,51.62,55.59,444.18,115.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5 illustrates, how classification of each test day is performed. Grey blocks denote sub-questions of the main research question of this work: in which ways stress displays itself in motion trajectories (if at all)? Q1: which trajectory features (separately or in combinations) allow to detect stress more accurately? Q2: how to calculate stress score of the day from recovered hidden states of HMM? Q3: how to calculate decision threshold for stress score: for example, are stressful days prominent outliers or not? Notations and processes in Fig. 5 are as follows: Data Day k: Database of all trajectories, obtained in the monitored office during day Dk. Time windows W1 and W2: Certain time windows (for example, W1 is from 15.00 until 18.00 and W2 is from 16.00 until 19.00). Chair of User1: Location of the office chair of user User1, obtained during training. Data of User1 from Day k: Trajectories, obtained in the monitored office during day Dk and selected as belonging to user User1, in a same way as described in previous section. Fi-Dk-W1 and Fi-Dk-W2: Feature Fi, extracted from trajectories, obtained within windows W1 and W2 respectively. R-Fi-W1 and R-Fi-W2: Reference models for feature Fi, obtained during training for windows W1 and W2 respectively. D-Fi-Dk-W1 and D-Fi-Dk-W2 are discretised deviations of values of feature Fi, obtained for day Dk and windows W1 and W2, from the reference values R-Fi-W1 and R-Fi-W2 respectively. They are calculated as described in the previous section. These features are calculated for every window of the day Dk, and the sequence of discretised window features serves as HMM observations.HMM-Fi is the trained HMM model for feature Fi. To answer research question Q1, we compared HMM models, trained on various features (features are described in ''Trajectory-Based Behavioural Features'' Section).Based on a sequence of observations, calculated for this day, we obtain a sequence of the hidden states from each model HMM-Fi. We employ the Bayesian MPM (maximum posterior marginal) decision rule that selects for each time moment the hidden state with the maximum posterior marginal probability. An alternative, more conventional, approach would be to employ the Bayesian maximum a posteriori (MAP) decision rule using the well-known Viterbi dynamic programming algorithm[Rabiner 1986] for inferring a sequence of the hidden with. The MAP approach to minimising the error probability assumes that the cost of errors for a given sequence of observation is just the same, irrespectively of their number (i.e., a single erroneous state is as bad as any other number of errors), whereas the MPM approach minimises the expected number of errors. MPM rule was shown to suit better to human behaviour analysis in three studies comparing accuracies of MPM and MAP rules: (1) detection of emotions of the show audience<ref type="bibr" target="#b28">[30]</ref>; (2) detection of illnesses of the elderly<ref type="bibr" target="#b27">[28]</ref> and (3) stress detection on the basis of mobile phone and wrist device data<ref type="bibr" target="#b17">[18]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>;;</head><label></label><figDesc>True normal = NnormalOK Nnormal Total accuracy = NnormalOK + NstressOK Nnormal + Nstress ;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. Stress scores for the four subjects of the best combined classifier HMM-SHS + HMM-SHS-scatter and its components; decision threshold is calculated for w = 1/6; day numbers are consecutive for the days when each subject was present.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 6</head><label>6</label><figDesc>Fig.6also shows that although HMM-SHS-scatter alone fails to detect the majority of stressful days, it is clearly complementary to the HMM-SHS classifier: often, when HMM-SHS classifier fails to assign high stress score to the stressful days, HMM-SHS-scatter assigns high score. On the other hand, often, when HMM-SHS classifier erroneously assigns high score to a normal day, HMM-SHS-scatter assigns low score to this day, allowing to compensate for errors of HMM-SHSscatter. This trend is visible in scores of all subjects, and it explains why the combined classifier achieved higher accuracy than HMM-SHS alone.</figDesc><graphic url="image-8.png" coords="14,51.62,55.59,444.09,468.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-9.png" coords="16,51.62,55.59,444.15,381.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Model configurations.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Accuracies of single modalities at different thresholds and with different weights; best results are highlighted by the bold font.</figDesc><table><row><cell></cell><cell cols="2">Threshold TA 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Threshold TA 2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>w = 1/10</cell><cell></cell><cell></cell><cell>w = 1/4</cell><cell></cell><cell></cell><cell>w = 1/10</cell><cell></cell><cell></cell><cell>w = 1/4</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Total</cell><cell>True</cell><cell>True</cell><cell>Total</cell><cell>True</cell><cell>True</cell><cell>Total</cell><cell>True</cell><cell>True</cell><cell>Total</cell><cell>True</cell><cell>True</cell></row><row><cell></cell><cell></cell><cell>stress</cell><cell>norm.</cell><cell></cell><cell>stress</cell><cell>norm.</cell><cell></cell><cell>stress</cell><cell>norm.</cell><cell></cell><cell>stress</cell><cell>norm.</cell></row><row><cell>HMM-Mt</cell><cell>0.54</cell><cell>0.38</cell><cell>0.63</cell><cell>0.55</cell><cell>0.35</cell><cell>0.66</cell><cell>0.49</cell><cell>0.56</cell><cell>0.45</cell><cell>0.49</cell><cell>0.50</cell><cell>0.49</cell></row><row><cell>HMM-Mt-scatter</cell><cell>0.59</cell><cell>0.56</cell><cell>0.61</cell><cell>0.58</cell><cell>0.43</cell><cell>0.67</cell><cell>0.43</cell><cell>0.38</cell><cell>0.45</cell><cell>0.53</cell><cell>0.32</cell><cell>0.65</cell></row><row><cell>HMM-Pt_max</cell><cell>0.63</cell><cell>0.47</cell><cell>0.72</cell><cell>0.63</cell><cell>0.36</cell><cell>0.78</cell><cell>0.38</cell><cell>0.50</cell><cell>0.32</cell><cell>0.40</cell><cell>0.42</cell><cell>0.38</cell></row><row><cell>HMM-Pt_max-scatter</cell><cell>0.56</cell><cell>0.56</cell><cell>0.56</cell><cell>0.56</cell><cell>0.47</cell><cell>0.61</cell><cell>0.44</cell><cell>0.44</cell><cell>0.45</cell><cell>0.47</cell><cell>0.36</cell><cell>0.53</cell></row><row><cell>HMM-TS</cell><cell>0.63</cell><cell>0.41</cell><cell>0.75</cell><cell>0.64</cell><cell>0.36</cell><cell>0.80</cell><cell>0.40</cell><cell>0.56</cell><cell>0.31</cell><cell>0.43</cell><cell>0.53</cell><cell>0.37</cell></row><row><cell>HMM-TS-scatter</cell><cell>0.50</cell><cell>0.44</cell><cell>0.53</cell><cell>0.50</cell><cell>0.43</cell><cell>0.55</cell><cell>0.50</cell><cell>0.40</cell><cell>0.55</cell><cell>0.51</cell><cell>0.33</cell><cell>0.61</cell></row><row><cell>HMM-TR</cell><cell>0.56</cell><cell>0.40</cell><cell>0.65</cell><cell>0.57</cell><cell>0.39</cell><cell>0.66</cell><cell>0.46</cell><cell>0.56</cell><cell>0.41</cell><cell>0.47</cell><cell>0.47</cell><cell>0.47</cell></row><row><cell>HMM-TR-scatter</cell><cell>0.56</cell><cell>0.56</cell><cell>0.57</cell><cell>0.61</cell><cell>0.35</cell><cell>0.76</cell><cell>0.45</cell><cell>0.32</cell><cell>0.53</cell><cell>0.45</cell><cell>0.32</cell><cell>0.53</cell></row><row><cell>HMM-SHS</cell><cell>0.63</cell><cell>0.54</cell><cell>0.68</cell><cell>0.64</cell><cell>0.49</cell><cell>0.72</cell><cell>0.41</cell><cell>0.41</cell><cell>0.41</cell><cell>0.48</cell><cell>0.15</cell><cell>0.66</cell></row><row><cell>HMM-SHS-scatter</cell><cell>0.44</cell><cell>0.31</cell><cell>0.51</cell><cell>0.60</cell><cell>0.08</cell><cell>0.89</cell><cell>0.60</cell><cell>0.20</cell><cell>0.83</cell><cell>0.60</cell><cell>0.20</cell><cell>0.83</cell></row><row><cell></cell><cell>Table 3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="10">F-scores of the best single classifiers at threshold TA 1 and weight w = 0.1 in comparison with</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Zero-R classifier.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">HMM-Pt_max</cell><cell></cell><cell cols="2">HMM-TS</cell><cell></cell><cell>HMM-SHS</cell><cell></cell><cell></cell><cell>Zero-R</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.47</cell><cell></cell><cell></cell><cell>0.44</cell><cell></cell><cell></cell><cell>0.51</cell><cell></cell><cell></cell><cell>0.27</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4</head><label>4</label><figDesc>Accuracies of combined modalities at threshold TA 1 with different weights; best results are highlighted by the bold font.</figDesc><table><row><cell></cell><cell>w = 1/10</cell><cell></cell><cell></cell><cell>w = 1/6</cell><cell></cell><cell></cell><cell>w = 1/5</cell><cell></cell><cell></cell><cell>w = 1/4</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Total</cell><cell>True</cell><cell>True</cell><cell>Total</cell><cell>True</cell><cell>True</cell><cell>Total</cell><cell>True</cell><cell>True</cell><cell>Total</cell><cell>True</cell><cell>True</cell></row><row><cell></cell><cell></cell><cell>stress</cell><cell>norm.</cell><cell></cell><cell>stress</cell><cell>norm.</cell><cell></cell><cell>stress</cell><cell>norm.</cell><cell></cell><cell>stress</cell><cell>norm.</cell></row><row><cell>HMM-SHS +</cell><cell>0.66</cell><cell>0.50</cell><cell>0.75</cell><cell>0.67</cell><cell>0.46</cell><cell>0.79</cell><cell>0.66</cell><cell>0.37</cell><cell>0.81</cell><cell>0.64</cell><cell>0.29</cell><cell>0.84</cell></row><row><cell>HMM-SHS-scatter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-TS +</cell><cell>0.65</cell><cell>0.46</cell><cell>0.75</cell><cell>0.64</cell><cell>0.43</cell><cell>0.76</cell><cell>0.64</cell><cell>0.37</cell><cell>0.79</cell><cell>0.64</cell><cell>0.37</cell><cell>0.79</cell></row><row><cell>HMM-Mt-scatter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-TS +</cell><cell>0.62</cell><cell>0.33</cell><cell>0.78</cell><cell>0.63</cell><cell>0.33</cell><cell>0.79</cell><cell>0.63</cell><cell>0.32</cell><cell>0.81</cell><cell>0.63</cell><cell>0.31</cell><cell>0.82</cell></row><row><cell>HMM-SHS-scatter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-SHS +</cell><cell>0.64</cell><cell>0.43</cell><cell>0.76</cell><cell>0.64</cell><cell>0.42</cell><cell>0.76</cell><cell>0.66</cell><cell>0.39</cell><cell>0.81</cell><cell>0.66</cell><cell>0.39</cell><cell>0.81</cell></row><row><cell>HMM-TS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-SHS +</cell><cell>0.63</cell><cell>0.50</cell><cell>0.71</cell><cell>0.63</cell><cell>0.47</cell><cell>0.71</cell><cell>0.62</cell><cell>0.46</cell><cell>0.71</cell><cell>0.62</cell><cell>0.46</cell><cell>0.71</cell></row><row><cell>HMM-TR-scatter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-SHS-scatter +</cell><cell>0.63</cell><cell>0.44</cell><cell>0.74</cell><cell>0.62</cell><cell>0.32</cell><cell>0.79</cell><cell>0.62</cell><cell>0.32</cell><cell>0.79</cell><cell>0.62</cell><cell>0.31</cell><cell>0.79</cell></row><row><cell>HMM-Pt_max</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-SHS +</cell><cell>0.63</cell><cell>0.44</cell><cell>0.74</cell><cell>0.63</cell><cell>0.43</cell><cell>0.75</cell><cell>0.63</cell><cell>0.43</cell><cell>0.75</cell><cell>0.63</cell><cell>0.38</cell><cell>0.76</cell></row><row><cell>HMM-Pt_max</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-SHS +</cell><cell>0.61</cell><cell>0.53</cell><cell>0.65</cell><cell>0.64</cell><cell>0.50</cell><cell>0.72</cell><cell>0.64</cell><cell>0.50</cell><cell>0.72</cell><cell>0.64</cell><cell>0.48</cell><cell>0.73</cell></row><row><cell>HMM-Pt_max-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>scatter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-TS +</cell><cell>0.67</cell><cell>0.48</cell><cell>0.77</cell><cell>0.67</cell><cell>0.46</cell><cell>0.79</cell><cell>0.66</cell><cell>0.43</cell><cell>0.79</cell><cell>0.66</cell><cell>0.40</cell><cell>0.80</cell></row><row><cell>HMM-TR-scatter +</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-Mt-scatter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-TS +</cell><cell>0.67</cell><cell>0.43</cell><cell>0.80</cell><cell>0.67</cell><cell>0.37</cell><cell>0.83</cell><cell>0.66</cell><cell>0.36</cell><cell>0.83</cell><cell>0.66</cell><cell>0.31</cell><cell>0.86</cell></row><row><cell>HMM-Pt_max +</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-Pt_max-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>scatter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-SHS +</cell><cell>0.66</cell><cell>0.42</cell><cell>0.80</cell><cell>0.67</cell><cell>0.41</cell><cell>0.81</cell><cell>0.66</cell><cell>0.38</cell><cell>0.82</cell><cell>0.67</cell><cell>0.38</cell><cell>0.82</cell></row><row><cell>HMM-TS +</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-Pt_max</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-SHS +</cell><cell>0.65</cell><cell>0.45</cell><cell>0.76</cell><cell>0.66</cell><cell>0.42</cell><cell>0.80</cell><cell>0.66</cell><cell>0.40</cell><cell>0.81</cell><cell>0.67</cell><cell>0.39</cell><cell>0.82</cell></row><row><cell>HMM-TS +</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-Pt_max-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>scatter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-TS +</cell><cell>0.65</cell><cell>0.49</cell><cell>0.74</cell><cell>0.66</cell><cell>0.44</cell><cell>0.78</cell><cell>0.66</cell><cell>0.44</cell><cell>0.78</cell><cell>0.64</cell><cell>0.37</cell><cell>0.80</cell></row><row><cell>HMM-TS-scatter +</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-Mt-scatter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5</head><label>5</label><figDesc>Accuracies of best classifiers for different test subjects for w = 1/6.</figDesc><table><row><cell></cell><cell>Person A</cell><cell></cell><cell></cell><cell>Person B</cell><cell></cell><cell></cell><cell>Person C</cell><cell></cell><cell></cell><cell>Person D</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Total</cell><cell>True</cell><cell>True</cell><cell>Total</cell><cell>True</cell><cell>True</cell><cell>Total</cell><cell>True</cell><cell>True</cell><cell>Total</cell><cell>True</cell><cell>True</cell></row><row><cell></cell><cell></cell><cell>stress</cell><cell>norm.</cell><cell></cell><cell>stress</cell><cell>norm.</cell><cell></cell><cell>stress</cell><cell>norm.</cell><cell></cell><cell>stress</cell><cell>norm.</cell></row><row><cell>Best individual</cell><cell>HMM-TS</cell><cell></cell><cell></cell><cell cols="2">HMM-TR-scatter</cell><cell></cell><cell>HMM-SHS</cell><cell></cell><cell></cell><cell>HMM-SHS</cell><cell></cell><cell></cell></row><row><cell>modality</cell><cell>0.68</cell><cell>0.68</cell><cell>0.68</cell><cell>0.72</cell><cell>0.75</cell><cell>0.72</cell><cell>0.63</cell><cell>0.47</cell><cell>0.81</cell><cell>0.70</cell><cell>0.65</cell><cell>0.73</cell></row><row><cell>Next individual</cell><cell>HMM-TR</cell><cell></cell><cell></cell><cell cols="2">HMM-Mt-scatter</cell><cell></cell><cell cols="2">HMM-Pt_max</cell><cell></cell><cell cols="2">HMM-Pt_max-scatter</cell><cell></cell></row><row><cell>modality</cell><cell>0.63</cell><cell>0.57</cell><cell>0.66</cell><cell>0.65</cell><cell>0.75</cell><cell>0.62</cell><cell>0.57</cell><cell>0.41</cell><cell>0.72</cell><cell>0.66</cell><cell>0.65</cell><cell>0.73</cell></row><row><cell>Average best</cell><cell>HMM-SHS</cell><cell></cell><cell></cell><cell>HMM-SHS</cell><cell></cell><cell></cell><cell>HMM-SHS</cell><cell></cell><cell></cell><cell>HMM-SHS</cell><cell></cell><cell></cell></row><row><cell>individual</cell><cell>0.62</cell><cell>0.52</cell><cell>0.66</cell><cell>0.54</cell><cell>0.50</cell><cell>0.55</cell><cell>0.63</cell><cell>0.47</cell><cell>0.81</cell><cell>0.70</cell><cell>0.65</cell><cell>0.73</cell></row><row><cell>Best combined</cell><cell>HMM-TS +</cell><cell></cell><cell></cell><cell cols="2">HMM-TR-scatter +</cell><cell></cell><cell cols="2">HMM-SHS +</cell><cell></cell><cell cols="2">HMM-SHS +</cell><cell></cell></row><row><cell>modality</cell><cell cols="2">HMM-Mt-scatter</cell><cell></cell><cell cols="2">HMM-Mt-scatter</cell><cell></cell><cell cols="2">HMM-Pt_max-SD</cell><cell></cell><cell cols="2">HMM-SHS-scatter</cell><cell></cell></row><row><cell></cell><cell>0.72</cell><cell>0.68</cell><cell>0.74</cell><cell>0.77</cell><cell>0.69</cell><cell>0.79</cell><cell>0.62</cell><cell>0.52</cell><cell>0.72</cell><cell>0.75</cell><cell>0.65</cell><cell>0.81</cell></row><row><cell>Next combined</cell><cell cols="3">HMM-SHS + HMM-TS</cell><cell cols="3">HMM-Pt_max-scatter +</cell><cell cols="2">HMM-SHS +</cell><cell></cell><cell cols="2">HMM-SHS +</cell><cell></cell></row><row><cell>modality</cell><cell></cell><cell></cell><cell></cell><cell cols="2">HMM-Mt-scatter</cell><cell></cell><cell cols="2">HMM-Pt_max-scatter</cell><cell></cell><cell cols="2">HMM-Pt_max-scatter</cell><cell></cell></row><row><cell></cell><cell>0.69</cell><cell>0.68</cell><cell>0.70</cell><cell>0.71</cell><cell>0.63</cell><cell>0.74</cell><cell>0.59</cell><cell>0.45</cell><cell>0.74</cell><cell>0.72</cell><cell>0.61</cell><cell>0.79</cell></row><row><cell>Average best</cell><cell cols="2">HMM-SHS +</cell><cell></cell><cell cols="2">HMM-SHS +</cell><cell></cell><cell cols="2">HMM-SHS +</cell><cell></cell><cell cols="2">HMM-SHS +</cell><cell></cell></row><row><cell>combined</cell><cell cols="2">HMM-SHS-scatter</cell><cell></cell><cell cols="2">HMM-SHS-scatter</cell><cell></cell><cell cols="2">HMM-SHS-scatter</cell><cell></cell><cell cols="2">HMM-SHS-scatter</cell><cell></cell></row><row><cell></cell><cell>0.65</cell><cell>0.57</cell><cell>0.68</cell><cell>0.70</cell><cell>0.56</cell><cell>0.74</cell><cell>0.59</cell><cell>0.40</cell><cell>0.79</cell><cell>0.75</cell><cell>0.65</cell><cell>0.81</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6</head><label>6</label><figDesc>Accuracies of two best single and one best combined modality at threshold TA 1 with different weights.</figDesc><table><row><cell>Classifier</cell><cell>Data</cell><cell cols="2">w = 1/10</cell><cell></cell><cell>w = 1/6</cell><cell></cell><cell></cell><cell>w = 1/5</cell><cell></cell><cell></cell><cell>w = 1/4</cell></row><row><cell></cell><cell></cell><cell>Total</cell><cell>True</cell><cell>True</cell><cell>Total</cell><cell>True</cell><cell>True</cell><cell>Total</cell><cell>True</cell><cell>True</cell><cell>Total</cell><cell>True</cell><cell>True</cell></row><row><cell></cell><cell></cell><cell></cell><cell>stress</cell><cell>norm.</cell><cell></cell><cell>stress</cell><cell>norm.</cell><cell></cell><cell>stress</cell><cell>norm.</cell><cell></cell><cell>stress</cell><cell>norm.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7</head><label>7</label><figDesc>Accuracies of best single and combined modalities, trained on scarce data, with weight = 1/5.</figDesc><table><row><cell></cell><cell cols="4">Personal models using scarce data</cell><cell></cell><cell></cell><cell cols="5">General models, adapted using scarce data</cell><cell></cell></row><row><cell></cell><cell cols="2">Evaluation of days</cell><cell></cell><cell cols="3">Evaluation of months</cell><cell cols="2">Evaluation of days</cell><cell></cell><cell cols="3">Evaluation of months</cell></row><row><cell></cell><cell>Total</cell><cell>True</cell><cell>True</cell><cell>Total</cell><cell>True</cell><cell>True</cell><cell>Total</cell><cell>True</cell><cell>True</cell><cell>Total</cell><cell>True</cell><cell>True</cell></row><row><cell></cell><cell></cell><cell>stress</cell><cell>norm.</cell><cell></cell><cell>stress</cell><cell>norm.</cell><cell></cell><cell>stress</cell><cell>norm.</cell><cell></cell><cell>stress</cell><cell>norm.</cell></row><row><cell>HMM-SHS</cell><cell>0.62</cell><cell>0.50</cell><cell>0.68</cell><cell>0.68</cell><cell>0.75</cell><cell>0.67</cell><cell>0.63</cell><cell>0.50</cell><cell>0.71</cell><cell>0.71</cell><cell>0.85</cell><cell>0.70</cell></row><row><cell>HMM-TS</cell><cell>0.57</cell><cell>0.40</cell><cell>0.67</cell><cell>0.64</cell><cell>0.65</cell><cell>0.62</cell><cell>0.54</cell><cell>0.55</cell><cell>0.54</cell><cell>0.74</cell><cell>0.95</cell><cell>0.63</cell></row><row><cell>HMM-SHS +</cell><cell>0.63</cell><cell>0.49</cell><cell>0.71</cell><cell>0.68</cell><cell>0.80</cell><cell>0.70</cell><cell>0.62</cell><cell>0.38</cell><cell>0.76</cell><cell>0.53</cell><cell>0.63</cell><cell>0.59</cell></row><row><cell>HMM-SHS-scatter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HMM-TS +</cell><cell>0.55</cell><cell>0.31</cell><cell>0.68</cell><cell>0.69</cell><cell>0.48</cell><cell>0.75</cell><cell>0.55</cell><cell>0.54</cell><cell>0.55</cell><cell>0.78</cell><cell>0.70</cell><cell>0.74</cell></row><row><cell>HMM-SHS-scatter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>? ''I had a lot of work stuff to do, but I wasn't very productive'' ? ''Nothing special happened but I didn't feel fully recovered from yesterday.'' ? ''This day should not have been stressful, but I still felt stressed.'' ? ''I felt myself really tired because of the stressing work week and travelling'' ? ''No idea where to start and what are the expectations. . . '' [about project work]</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>We thank test subjects for their invaluable help in experimental investigations presented in this work.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HMM-TS</head><note type="other">All</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.4.">Stress detection on monthly basis</head><p>Fig. <ref type="figure">6</ref> shows that stressful days of all subjects were not evenly distributed between normal days; rather, stressful periods alternated with normal periods. One of the reasons for long-lasting stress is approaching deadlines, such as ending projects, submissions of project proposals, sales deadlines etc. Another reason is that all subjects in our study perceived inability to focus on their work as stressful, and tiredness after a hardworking day hinders concentration. This phenomenon is very well visible in comments of one of the subjects, who added to several ''stressful day'' labels notes stating that ''this should not have been stressful day, but somehow I still felt stressed or not fully recovered from yesterday''.</p><p>Some stressful days occurred also during normal periods, but a single stressful day is less dangerous than long-lasting stress <ref type="bibr" target="#b29">[31]</ref><ref type="bibr" target="#b30">[32]</ref><ref type="bibr" target="#b31">[33]</ref><ref type="bibr" target="#b32">[34]</ref>. Therefore we studied whether the proposed method could accurately detect difficult periods. As all test subjects in our study had many business trips, the data did not allow us to evaluate many consecutive days in a row. As test subjects fairly often spent only one-two days in a week in their offices and other days travelling or teleworking, evaluating calendar weeks did not make much sense either. Hence we evaluated accuracy of classifying each calendar month as stressful or not as follows. First, each HMM model evaluated each day of a calendar month, for which the subject's trajectories were obtained (i.e., when this subject was present in his/ her office), as stressful or not. Then, if number of days of this calendar month, classified as stressful, exceeded number of days, classified as normal, we considered classification result as ''stressful month''; otherwise we considered classification result as ''normal month''. Then we checked labels of these days. If number of days of this calendar month, labelled as stressful, exceeded number of days, labelled as normal, we considered that label of this month was ''stressful month''; otherwise we considered month label ''normal'', and compared month label with the classification result.</p><p>Table <ref type="table">6</ref> presents accuracies of two best single modalities and one combined modality for evaluating stress on monthly basis. The best combined modality was HMM-TS + HMM-SHS-scatter, and several other combinations of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HMM-TS with different modalities achieved similar accuracies, for example, HMM-TS + HMM-Pt_max-scatter, HMM-TS + HMM-Mt-scatter and HMM-TS + HMM-TR-scatter, but none of them outperformed the best single modality HMM-TS.</head><p>Table <ref type="table">6</ref> shows that spread of locations appeared to be the best data feature also for evaluating stress on monthly basis, although in this case HMM-TS outperformed HMM-SHS for the majority of the subjects. This happened because in many cases HMM-TS did not assign a high score to a day labelled as ''stressful'', but assigned a high score to the following day instead. Such tendency reduced accuracy of classifying days, but appeared to be beneficial for classifying months, and we believe that HMM-TS behaviour in this respect reflects real life trends: test subjects in our study confirmed that they often could not work efficiently on a day following a difficult day.</p><p>Evaluation of months could be useful, for example, for improving distribution of workloads of different persons or for detecting deterioration of personal conditions (e.g., due to organisational changes or age). In the latter scenario the system might be able to build a model of normal behaviour on the basis of quite normal data. In the former scenario there is a high probability that the system would build a reference model of normal behaviour from data, containing equal amounts of normal and stressful days, which would be less reliable model. Table <ref type="table">6</ref> shows that HMM-TS classifier achieved high accuracy for all subjects despite notable differences in ratios between stressful and normal days, reported by them. This result suggests that the proposed method could be useable in both scenarios.</p><p>According to the self-reports, person C had 5 stressful months and 5 normal months, while all other subjects had notably fewer stressful months than normal ones. Therefore Zero-R classifier misclassifies all stressful months of all subjects, i.e., its recall is zero. In addition, Zero-R misclassifies all normal months of person C. On the contrary, F-score of the best model HMM-TS for threshold TA 1 and weight w = 1 /4 equals to 0.9, while for weight w = 1/5 F-score for HMM-TS equals to 0.82.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards an automatic early stress recognition system for office environments based on multimodal measurements: a review</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alberdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aztiria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basarab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="49" to="75" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Causes and management of stress at work</title>
		<author>
			<persName><forename type="first">S</forename><surname>Michie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Occup. Environ. Med</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="67" to="72" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Plarre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nakajima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Absi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ertin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kamarck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Siewiorek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smailagic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Wittmers</surname></persName>
		</author>
		<title level="m">Continuous inference of psychological stress from sensory measurements collected in the natural environment, in: Information Processing in Sensor Networks (IPSN), 10th International Conference on</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="97" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Identifying objective physiological markers and modifiable behaviors for self-reported stress and mental health status using wearable sensors and mobile phones: Observational study</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Mchill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Barger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Klerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Med. Internet Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatic detection of perceived stress in campus students using smartphones</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gjoreski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gjoreski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lutrek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Environments (IE), 2015 International Conference on</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="132" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Call center stress recognition with person-specific models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Affective Computing and Intelligent Interaction</title>
		<meeting>the 4th International Conference on Affective Computing and Intelligent Interaction</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="125" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Person-specific behavioural features for automatic stress detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aigrain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dubuisson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Detyniecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chetouani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Face and Gesture Recognition, 2015 11th IEEE International Conference and Workshops on</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Detecting work stress in offices by combining unobtrusive sensors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Koldijk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Neerincx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Affect. Comput</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Nakashima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Flutura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seiderer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Andr?</surname></persName>
		</author>
		<title level="m">Stress recognition in daily work</title>
		<editor>
			<persName><surname>Mindcare</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2015">2015. 2016</date>
			<biblScope unit="volume">604</biblScope>
			<biblScope unit="page" from="23" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Personalized stress detection from physiological measurements</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Blitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Frisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smailagic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Siewiorek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Absi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kamarck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Symposium on Quality of Life Technology</title>
		<meeting>the 2nd International Symposium on Quality of Life Technology</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cluster-based analysis for personalized stress evaluation using physiological signals</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Nwe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inf</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="275" to="281" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Ferdous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Osmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mayora</surname></persName>
		</author>
		<title level="m">Smartphone app usage as a predictor of perceived stress levels at workplace, in: 9th International Conference on Pervasive Computing Technologies for Healthcare</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic stress detection in working environments from smartphones&apos; accelerometer data: A first step</title>
		<author>
			<persName><forename type="first">E</forename><surname>Garcia-Ceja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Osmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mayora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inf</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Using mouse dynamics to assess stress during online exams</title>
		<author>
			<persName><forename type="first">D</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Novais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>P?go</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sousa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Hybrid Artificial Intelligence Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="345" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Stress modelling and prediction in presence of scarce data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Maxhuni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hernandez-Leal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Sucar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Osmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mayora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="344" to="356" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rabbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Voida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Voida</surname></persName>
		</author>
		<title level="m">Towards personal stress informatics: comparing minimally invasive techniques for measuring daily stress in the wild, in: 8th International Conference on Pervasive Computing Technologies for Healthcare</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="72" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Modeling arousal phases in daily living using wearable sensors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kusserow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Amft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Troster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Affect. Comput</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="93" to="105" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gimel&apos;farb, Unsupervised stress detection algorithm and experiments with real life data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vildjiounaite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kallio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>M?ntyj?rvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kyll?nen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lindholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Progress in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="page" from="95" to="107" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A longitudinal investigation of work environment stressors on the performance and wellbeing of office workers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C S</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Ergon</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="104" to="111" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Pervasive stress recognition for sustainable living</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bogomolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lepri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pianesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pervasive Computing and Communications Workshops (PERCOM Workshops)</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="345" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Noninvasive stress recognition considering the current activity</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sysoev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Matevz</forename><surname>Pogacnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pers. Ubiquitous Comput</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1045" to="1052" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Individuals&apos; stress assessment using human-smartphone interaction analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ciman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Affect. Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Towards measuring stress with smartphones and wearable devices during workday and sleep</title>
		<author>
			<persName><forename type="first">A</forename><surname>Muaremi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Arnrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tr?ster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioNanoScience</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="172" to="183" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Detection of distraction and fatigue in groups through the analysis of interaction patterns with computers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pimenta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Novais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intell. Distrib. Comput</title>
		<imprint>
			<biblScope unit="page" from="29" to="39" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">What does your chair know about your stress level?</title>
		<author>
			<persName><forename type="first">B</forename><surname>Arnrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Setz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>La</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Marca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Tr?ster</surname></persName>
		</author>
		<author>
			<persName><surname>Ehlert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Technol. Biomed</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="214" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Monitoring stress with a wrist device using context</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gjoreski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lu?trek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gjoreski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="159" to="170" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Lightweight adaptation of classifiers to users and contexts: Trends of the emerging domain</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vildjiounaite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gimel'farb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kyll?nen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peltola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. World J</title>
		<imprint>
			<biblScope unit="page">29</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Gimel&apos;farb, Unsupervised illness recognition via in-home monitoring by depth cameras</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vildjiounaite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-M</forename><surname>M?kel?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ker?nen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kyll?nen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Huotari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>J?rvinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pervasive Mob. Comput</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="166" to="187" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Gimel&apos;farb, Semi-supervised context adaptation: case study of audience excitement recognition</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vildjiounaite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kyll?nen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-M</forename><surname>M?kel?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vuorinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ker?nen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peltola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia Syst</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="231" to="250" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Brain on stress: how the social environment gets under the skin</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Mcewen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">.2</biblScope>
			<biblScope unit="page" from="17180" to="17185" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Suppl</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Chronic psychosocial stress at work and risk of depression: evidence from prospective studies</title>
		<author>
			<persName><forename type="first">J</forename><surname>Siegrist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. Arch. Psychiatry Clin. Neurosci</title>
		<imprint>
			<biblScope unit="volume">258</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">115</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Impact of chronic psychosocial stress on autonomic cardiovascular regulation in otherwise healthy subjects</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lucini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Di Fede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Parati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pagani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hypertension</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1201" to="1206" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Chronic psychological stress and the regulation of pro-inflammatory cytokines: a glucocorticoid-resistance model</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Ritchey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Health Psychol</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">531</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Monitoring of mental workload levels during an everyday life office-work scenario</title>
		<author>
			<persName><forename type="first">B</forename><surname>Cinaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Arnrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>La Marca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tr?ster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pers. Ubiquitous Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="229" to="239" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Daily stress recognition from mobile phone data, weather conditions and individual traits</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bogomolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lepri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pianesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM International Conference on Multimedia</title>
		<meeting>the 22nd ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Large-scale wearable data reveal digital phenotypes for daily-life stress detection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Smets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Velazquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schiavone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Chakroun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>D'hondt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>De Raedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Janssens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Van Hoecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Claes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Van Diest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hoof</forename><surname>Van</surname></persName>
		</author>
		<author>
			<persName><surname>Ch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">67</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The built environment and mental health</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Urban Health</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="536" to="555" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The associations of indoor environment and psychosocial factors on the subjective evaluation of indoor air quality among lower secondary school students: a multilevel analysis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Finell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Indoor Air</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="329" to="337" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Further reading</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Using smart offices to predict occupational stress</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alberdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aztiria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basarab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Ind. Ergon</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="13" to="26" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
